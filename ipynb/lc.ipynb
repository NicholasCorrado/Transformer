{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aac0ac12-c8ae-4944-a88c-2e3bcdc4c6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set_context(context=\"talk\")\n",
    "%matplotlib inline\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture. Base for this and many \n",
    "    other models.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "        \n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        return self.decode(self.encode(src, src_mask), src_mask,\n",
    "                            tgt, tgt_mask)\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "    \n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"Define standard linear + softmax generation step.\"\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)\n",
    "\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        \"Pass the input (and mask) through each layer in turn.\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)\n",
    "    \n",
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "\n",
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "    \n",
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    \"Generic N layer decoder with masking.\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return self.norm(x)\n",
    "    \n",
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    " \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        \"Follow Figure 1 (right) for connections.\"\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)\n",
    "    \n",
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0\n",
    "\n",
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x, self.attn = attention(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)\n",
    "        \n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)\n",
    "    \n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)\n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], \n",
    "                         requires_grad=False)\n",
    "        return self.dropout(x)\n",
    "    \n",
    "class Batch:\n",
    "    \"Object for holding a batch of data with mask during training.\"\n",
    "    def __init__(self, src, trg=None, pad=0):\n",
    "        self.src = src\n",
    "        self.src_mask = (src != pad).unsqueeze(-2)\n",
    "        if trg is not None:\n",
    "            self.trg = trg[:, :-1]\n",
    "            self.trg_y = trg[:, 1:]\n",
    "            self.trg_mask = \\\n",
    "                self.make_std_mask(self.trg, pad)\n",
    "            self.ntokens = (self.trg_y != pad).data.sum()\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_std_mask(tgt, pad):\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "        tgt_mask = tgt_mask & Variable(\n",
    "            subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data))\n",
    "        return tgt_mask\n",
    "    \n",
    "def run_epoch(data_iter, model, loss_compute, log_f, step_loss_f):\n",
    "    \"Standard Training and Logging Function\"\n",
    "    start = time.time()\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    tokens = 0\n",
    "    for i, batch in enumerate(data_iter):\n",
    "        out = model.forward(batch.src, batch.trg, \n",
    "                            batch.src_mask, batch.trg_mask)\n",
    "        loss = loss_compute(out, batch.trg_y, batch.ntokens)\n",
    "        total_loss += loss\n",
    "        total_tokens += batch.ntokens\n",
    "        tokens += batch.ntokens\n",
    "        if i % 50 == 1:\n",
    "            elapsed = time.time() - start\n",
    "            log_str = \"Epoch Step: %d Loss: %f Tokens per Sec: %f\\n\" % (i, loss / batch.ntokens, tokens / elapsed)\n",
    "            print(log_str)\n",
    "            log_f.write(log_str)\n",
    "            log_f.flush()\n",
    "            step_loss_f.write(\"%f\\n\" % (loss / batch.ntokens))\n",
    "            step_loss_f.flush()\n",
    "            start = time.time()\n",
    "            tokens = 0\n",
    "    return total_loss / total_tokens\n",
    "\n",
    "global max_src_in_batch, max_tgt_in_batch\n",
    "def batch_size_fn(new, count, sofar):\n",
    "    \"Keep augmenting batch and calculate total number of tokens + padding.\"\n",
    "    global max_src_in_batch, max_tgt_in_batch\n",
    "    if count == 1:\n",
    "        max_src_in_batch = 0\n",
    "        max_tgt_in_batch = 0\n",
    "    max_src_in_batch = max(max_src_in_batch,  len(new.src))\n",
    "    max_tgt_in_batch = max(max_tgt_in_batch,  len(new.trg) + 2)\n",
    "    src_elements = count * max_src_in_batch\n",
    "    tgt_elements = count * max_tgt_in_batch\n",
    "    return max(src_elements, tgt_elements)\n",
    "\n",
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "        \n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def rate(self, step = None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * \\\n",
    "            (self.model_size ** (-0.5) *\n",
    "            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
    "        \n",
    "def get_std_opt(model):\n",
    "    return NoamOpt(model.src_embed[0].d_model, 2, 4000,\n",
    "            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "\n",
    "class LabelSmoothing(nn.Module):\n",
    "    \"Implement label smoothing.\"\n",
    "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(size_average=False)\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        self.true_dist = None\n",
    "        \n",
    "    def forward(self, x, target):\n",
    "        assert x.size(1) == self.size\n",
    "        true_dist = x.data.clone()\n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        true_dist[:, self.padding_idx] = 0\n",
    "        mask = torch.nonzero(target.data == self.padding_idx)\n",
    "        if mask.dim() > 0:\n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        self.true_dist = true_dist\n",
    "        return self.criterion(x, Variable(true_dist, requires_grad=False))\n",
    "    \n",
    "class Batch:\n",
    "    \"Object for holding a batch of data with mask during training.\"\n",
    "    def __init__(self, src, trg=None, pad=0):\n",
    "        self.src = src\n",
    "        self.src_mask = (src != pad).unsqueeze(-2)\n",
    "        if trg is not None:\n",
    "            self.trg = trg[:, :-1]\n",
    "            self.trg_y = trg[:, 1:]\n",
    "            self.trg_mask = \\\n",
    "                self.make_std_mask(self.trg, pad)\n",
    "            self.ntokens = (self.trg_y != pad).data.sum()\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_std_mask(tgt, pad):\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "        tgt_mask = tgt_mask & Variable(\n",
    "            subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data))\n",
    "        return tgt_mask\n",
    "\n",
    "class PositionalEncoding_v2(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self,\n",
    "                 d_model,\n",
    "                 dropout,\n",
    "                 encoding_mode = 'sinusoidal',\n",
    "                 combining_mode = 'add',\n",
    "                 base=10_000.0,\n",
    "                 max_len=5000):\n",
    "        super(PositionalEncoding_v2, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.encoding_mode = encoding_mode\n",
    "        self.combining_mode = combining_mode\n",
    "        self.de = nn.Linear(d_model * 2, d_model)\n",
    "        self.at = nn.Tanh()\n",
    "        if encoding_mode == 'sinusoidal':\n",
    "            # Compute the positional encodings once in log space.\n",
    "            self.pe = torch.zeros(max_len, d_model)\n",
    "            position = torch.arange(0, max_len).unsqueeze(1)\n",
    "            div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
    "                                 -(math.log(base) / d_model))\n",
    "            self.pe[:, 0::2] = torch.sin(position * div_term)\n",
    "            self.pe[:, 1::2] = torch.cos(position * div_term)\n",
    "            self.pe = self.pe.unsqueeze(0)\n",
    "        elif encoding_mode == 'learnable':\n",
    "            self.pe = nn.Parameter(torch.zeros(max_len, d_model).unsqueeze(0),\n",
    "                              requires_grad=True)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "    def forward(self, x):\n",
    "        if self.combining_mode == 'add':\n",
    "            if self.encoding_mode == 'sinusoidal':\n",
    "                x = x + Variable(self.pe[:, :x.size(1)],\n",
    "                                 requires_grad=False)\n",
    "                return self.dropout(x)\n",
    "            else:\n",
    "                x = x + self.pe[:, :x.size(1)]\n",
    "                return self.dropout(x)\n",
    "        elif self.combining_mode == 'concat':\n",
    "            if self.encoding_mode == 'sinusoidal':\n",
    "                x = torch.cat([x,Variable(self.pe[:, :x.size(1)].repeat(x.size(0),1,1),\n",
    "                                 requires_grad=False)],axis=2)\n",
    "                x = self.at(self.de(x))\n",
    "                return self.dropout(x)\n",
    "            else:\n",
    "                x = torch.cat([x,self.pe[:, :x.size(1)].repeat(x.size(0),1,1)\n",
    "                              ],axis=2)\n",
    "                x = self.at(self.de(x))\n",
    "                return self.dropout(x)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "            \n",
    "from torchtext.legacy import data, datasets\n",
    "import spacy\n",
    "\n",
    "if True:\n",
    "    spacy_de = spacy.load('de')\n",
    "    spacy_en = spacy.load('en')\n",
    "\n",
    "    def tokenize_de(text):\n",
    "        return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "    def tokenize_en(text):\n",
    "        return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "    BOS_WORD = '<s>'\n",
    "    EOS_WORD = '</s>'\n",
    "    BLANK_WORD = \"<blank>\"\n",
    "    SRC = data.Field(tokenize=tokenize_de, pad_token=BLANK_WORD)\n",
    "    TGT = data.Field(tokenize=tokenize_en, init_token = BOS_WORD, \n",
    "                     eos_token = EOS_WORD, pad_token=BLANK_WORD)\n",
    "\n",
    "    MAX_LEN = 100\n",
    "    train, val, test = datasets.IWSLT.splits(\n",
    "        exts=('.de', '.en'), fields=(SRC, TGT), \n",
    "        filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and \n",
    "            len(vars(x)['trg']) <= MAX_LEN)\n",
    "    MIN_FREQ = 2\n",
    "    SRC.build_vocab(train.src, min_freq=MIN_FREQ)\n",
    "    TGT.build_vocab(train.trg, min_freq=MIN_FREQ)\n",
    "\n",
    "class MyIterator(data.Iterator):\n",
    "    def create_batches(self):\n",
    "        if self.train:\n",
    "            def pool(d, random_shuffler):\n",
    "                for p in data.batch(d, self.batch_size * 100):\n",
    "                    p_batch = data.batch(\n",
    "                        sorted(p, key=self.sort_key),\n",
    "                        self.batch_size, self.batch_size_fn)\n",
    "                    for b in random_shuffler(list(p_batch)):\n",
    "                        yield b\n",
    "            self.batches = pool(self.data(), self.random_shuffler)\n",
    "            \n",
    "        else:\n",
    "            self.batches = []\n",
    "            for b in data.batch(self.data(), self.batch_size,\n",
    "                                          self.batch_size_fn):\n",
    "                self.batches.append(sorted(b, key=self.sort_key))\n",
    "\n",
    "def rebatch(pad_idx, batch):\n",
    "    \"Fix order in torchtext to match ours\"\n",
    "    src, trg = batch.src.transpose(0, 1), batch.trg.transpose(0, 1)\n",
    "    return Batch(src, trg, pad_idx)\n",
    "\n",
    "class SimpleLossCompute:\n",
    "    \"A simple loss compute and train function.\"\n",
    "    def __init__(self, generator, criterion, opt=None):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        self.opt = opt\n",
    "        \n",
    "    def __call__(self, x, y, norm):\n",
    "        x = self.generator(x)\n",
    "        loss = self.criterion(x.contiguous().view(-1, x.size(-1)), \n",
    "                              y.contiguous().view(-1)) / norm\n",
    "        loss.backward()\n",
    "        if self.opt is not None:\n",
    "            self.opt.step()\n",
    "            self.opt.optimizer.zero_grad()\n",
    "        return loss.data * norm\n",
    "    \n",
    "def make_model(src_vocab, tgt_vocab, N=6, \n",
    "               d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    # position = PositionalEncoding(d_model, dropout)\n",
    "    position = PositionalEncoding_v2(d_model,\n",
    "                                     dropout,\n",
    "                                     encoding_mode = 'learnable',\n",
    "                                     combining_mode = 'concat')\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), \n",
    "                             c(ff), dropout), N),\n",
    "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
    "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
    "        Generator(d_model, tgt_vocab))\n",
    "    \n",
    "    # This was important from their code. \n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ce27a5-bab1-441d-a64f-77b5c6fdee8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-251df58449d6>:499: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  nn.init.xavier_uniform(p)\n",
      "/u/j/r/jrao/anaconda3/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Step: 1 Loss: 9.134890 Tokens per Sec: 2181.850098\n",
      "\n",
      "Epoch Step: 51 Loss: 8.487757 Tokens per Sec: 13479.582031\n",
      "\n",
      "Epoch Step: 101 Loss: 7.411554 Tokens per Sec: 13774.832031\n",
      "\n",
      "Epoch Step: 151 Loss: 6.212725 Tokens per Sec: 13944.889648\n",
      "\n",
      "Epoch Step: 201 Loss: 5.442780 Tokens per Sec: 14243.290039\n",
      "\n",
      "Epoch Step: 251 Loss: 5.322976 Tokens per Sec: 13988.221680\n",
      "\n",
      "Epoch Step: 301 Loss: 5.159096 Tokens per Sec: 14058.199219\n",
      "\n",
      "Epoch Step: 351 Loss: 4.602458 Tokens per Sec: 13902.151367\n",
      "\n",
      "Epoch Step: 401 Loss: 4.801884 Tokens per Sec: 13958.515625\n",
      "\n",
      "Epoch Step: 451 Loss: 4.844650 Tokens per Sec: 13939.373047\n",
      "\n",
      "Epoch Step: 501 Loss: 3.950102 Tokens per Sec: 13861.451172\n",
      "\n",
      "Epoch Step: 551 Loss: 4.445776 Tokens per Sec: 13803.502930\n",
      "\n",
      "Epoch Step: 601 Loss: 4.240252 Tokens per Sec: 13782.530273\n",
      "\n",
      "Epoch Step: 651 Loss: 4.138153 Tokens per Sec: 13693.177734\n",
      "\n",
      "Epoch Step: 701 Loss: 3.202625 Tokens per Sec: 13728.853516\n",
      "\n",
      "Epoch Step: 751 Loss: 3.948592 Tokens per Sec: 13048.410156\n",
      "\n",
      "Epoch Step: 801 Loss: 4.127745 Tokens per Sec: 13561.376953\n",
      "\n",
      "Epoch Step: 851 Loss: 4.183083 Tokens per Sec: 13409.193359\n",
      "\n",
      "Epoch Step: 901 Loss: 3.310338 Tokens per Sec: 13172.137695\n",
      "\n",
      "Epoch Step: 951 Loss: 3.941468 Tokens per Sec: 13427.957031\n",
      "\n",
      "Epoch Step: 1001 Loss: 4.106622 Tokens per Sec: 13202.522461\n",
      "\n",
      "Epoch Step: 1051 Loss: 3.789356 Tokens per Sec: 12646.220703\n",
      "\n",
      "Epoch Step: 1101 Loss: 4.107100 Tokens per Sec: 12993.480469\n",
      "\n",
      "Epoch Step: 1151 Loss: 3.947072 Tokens per Sec: 13001.773438\n",
      "\n",
      "Epoch Step: 1201 Loss: 3.281697 Tokens per Sec: 12859.272461\n",
      "\n",
      "Epoch Step: 1251 Loss: 4.214055 Tokens per Sec: 12916.913086\n",
      "\n",
      "Epoch Step: 1301 Loss: 2.967645 Tokens per Sec: 13651.682617\n",
      "\n",
      "Epoch Step: 1351 Loss: 3.971083 Tokens per Sec: 13304.166992\n",
      "\n",
      "Epoch Step: 1401 Loss: 3.521572 Tokens per Sec: 11861.008789\n",
      "\n",
      "Epoch Step: 1451 Loss: 4.001181 Tokens per Sec: 12110.891602\n",
      "\n",
      "Epoch Step: 1501 Loss: 3.639755 Tokens per Sec: 11692.923828\n",
      "\n",
      "Epoch Step: 1551 Loss: 3.848206 Tokens per Sec: 12340.135742\n",
      "\n",
      "Epoch Step: 1601 Loss: 3.841170 Tokens per Sec: 13813.180664\n",
      "\n",
      "Epoch Step: 1651 Loss: 2.831732 Tokens per Sec: 14009.431641\n",
      "\n",
      "Epoch Step: 1701 Loss: 2.837643 Tokens per Sec: 13967.393555\n",
      "\n",
      "Epoch Step: 1751 Loss: 3.096692 Tokens per Sec: 13804.137695\n",
      "\n",
      "Epoch Step: 1801 Loss: 3.205964 Tokens per Sec: 13752.490234\n",
      "\n",
      "Epoch Step: 1851 Loss: 3.491684 Tokens per Sec: 13569.820312\n",
      "\n",
      "Epoch Step: 1901 Loss: 3.683706 Tokens per Sec: 13071.974609\n",
      "\n",
      "Epoch Step: 1951 Loss: 4.062535 Tokens per Sec: 12673.547852\n",
      "\n",
      "Epoch Step: 2001 Loss: 3.555751 Tokens per Sec: 12986.510742\n",
      "\n",
      "Epoch Step: 2051 Loss: 3.645703 Tokens per Sec: 12463.371094\n",
      "\n",
      "Epoch Step: 2101 Loss: 2.873146 Tokens per Sec: 13044.144531\n",
      "\n",
      "Epoch Step: 2151 Loss: 3.083848 Tokens per Sec: 13137.913086\n",
      "\n",
      "Epoch Step: 1 Loss: 2.546812 Tokens per Sec: 9411.930664\n",
      "\n",
      "tensor(3.1978, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 2.608685 Tokens per Sec: 2319.744629\n",
      "\n",
      "Epoch Step: 51 Loss: 3.123526 Tokens per Sec: 12878.456055\n",
      "\n",
      "Epoch Step: 101 Loss: 3.273321 Tokens per Sec: 12773.615234\n",
      "\n",
      "Epoch Step: 151 Loss: 3.375623 Tokens per Sec: 13017.915039\n",
      "\n",
      "Epoch Step: 201 Loss: 3.154773 Tokens per Sec: 13053.086914\n",
      "\n",
      "Epoch Step: 251 Loss: 3.516619 Tokens per Sec: 12723.723633\n",
      "\n",
      "Epoch Step: 301 Loss: 2.402449 Tokens per Sec: 12615.899414\n",
      "\n",
      "Epoch Step: 351 Loss: 3.084970 Tokens per Sec: 12959.605469\n",
      "\n",
      "Epoch Step: 401 Loss: 4.187109 Tokens per Sec: 12791.279297\n",
      "\n",
      "Epoch Step: 451 Loss: 3.530700 Tokens per Sec: 12943.196289\n",
      "\n",
      "Epoch Step: 501 Loss: 3.445934 Tokens per Sec: 12678.175781\n",
      "\n",
      "Epoch Step: 551 Loss: 3.162117 Tokens per Sec: 12965.765625\n",
      "\n",
      "Epoch Step: 601 Loss: 3.407272 Tokens per Sec: 13311.541016\n",
      "\n",
      "Epoch Step: 651 Loss: 3.047083 Tokens per Sec: 13241.250977\n",
      "\n",
      "Epoch Step: 701 Loss: 2.874487 Tokens per Sec: 12820.833008\n",
      "\n",
      "Epoch Step: 751 Loss: 3.431770 Tokens per Sec: 12975.120117\n",
      "\n",
      "Epoch Step: 801 Loss: 3.463086 Tokens per Sec: 12863.442383\n",
      "\n",
      "Epoch Step: 851 Loss: 2.749958 Tokens per Sec: 12918.034180\n",
      "\n",
      "Epoch Step: 901 Loss: 2.527444 Tokens per Sec: 13255.637695\n",
      "\n",
      "Epoch Step: 951 Loss: 2.805976 Tokens per Sec: 13050.884766\n",
      "\n",
      "Epoch Step: 1001 Loss: 3.365174 Tokens per Sec: 13235.208008\n",
      "\n",
      "Epoch Step: 1051 Loss: 3.768951 Tokens per Sec: 13162.196289\n",
      "\n",
      "Epoch Step: 1101 Loss: 2.930058 Tokens per Sec: 13045.833984\n",
      "\n",
      "Epoch Step: 1151 Loss: 3.588587 Tokens per Sec: 12631.590820\n",
      "\n",
      "Epoch Step: 1201 Loss: 3.310894 Tokens per Sec: 12607.789062\n",
      "\n",
      "Epoch Step: 1251 Loss: 2.415807 Tokens per Sec: 12916.948242\n",
      "\n",
      "Epoch Step: 1301 Loss: 2.978036 Tokens per Sec: 12497.327148\n",
      "\n",
      "Epoch Step: 1351 Loss: 3.103786 Tokens per Sec: 12636.563477\n",
      "\n",
      "Epoch Step: 1401 Loss: 2.800752 Tokens per Sec: 13234.870117\n",
      "\n",
      "Epoch Step: 1451 Loss: 3.342382 Tokens per Sec: 12869.720703\n",
      "\n",
      "Epoch Step: 1501 Loss: 3.460357 Tokens per Sec: 13097.361328\n",
      "\n",
      "Epoch Step: 1551 Loss: 3.183066 Tokens per Sec: 12722.645508\n",
      "\n",
      "Epoch Step: 1601 Loss: 3.269531 Tokens per Sec: 13618.029297\n",
      "\n",
      "Epoch Step: 1651 Loss: 2.660788 Tokens per Sec: 13183.240234\n",
      "\n",
      "Epoch Step: 1701 Loss: 3.647604 Tokens per Sec: 11531.932617\n",
      "\n",
      "Epoch Step: 1751 Loss: 2.584438 Tokens per Sec: 11388.094727\n",
      "\n",
      "Epoch Step: 1801 Loss: 3.636607 Tokens per Sec: 11595.837891\n",
      "\n",
      "Epoch Step: 1851 Loss: 2.180483 Tokens per Sec: 13174.264648\n",
      "\n",
      "Epoch Step: 1901 Loss: 2.951249 Tokens per Sec: 12793.640625\n",
      "\n",
      "Epoch Step: 1951 Loss: 2.797115 Tokens per Sec: 13418.258789\n",
      "\n",
      "Epoch Step: 2001 Loss: 3.468218 Tokens per Sec: 13274.308594\n",
      "\n",
      "Epoch Step: 2051 Loss: 3.160570 Tokens per Sec: 13771.542969\n",
      "\n",
      "Epoch Step: 2101 Loss: 3.319884 Tokens per Sec: 13751.474609\n",
      "\n",
      "Epoch Step: 2151 Loss: 3.696445 Tokens per Sec: 13419.917969\n",
      "\n",
      "Epoch Step: 1 Loss: 2.175030 Tokens per Sec: 10277.628906\n",
      "\n",
      "tensor(2.7260, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 2.796557 Tokens per Sec: 2736.033203\n",
      "\n",
      "Epoch Step: 51 Loss: 3.382167 Tokens per Sec: 13046.604492\n",
      "\n",
      "Epoch Step: 101 Loss: 2.701590 Tokens per Sec: 13209.490234\n",
      "\n",
      "Epoch Step: 151 Loss: 2.535470 Tokens per Sec: 12697.654297\n",
      "\n",
      "Epoch Step: 201 Loss: 3.013047 Tokens per Sec: 13021.098633\n",
      "\n",
      "Epoch Step: 251 Loss: 2.577318 Tokens per Sec: 12697.222656\n",
      "\n",
      "Epoch Step: 301 Loss: 2.501523 Tokens per Sec: 12902.699219\n",
      "\n",
      "Epoch Step: 351 Loss: 2.410053 Tokens per Sec: 12755.169922\n",
      "\n",
      "Epoch Step: 401 Loss: 1.646777 Tokens per Sec: 13083.620117\n",
      "\n",
      "Epoch Step: 451 Loss: 3.165490 Tokens per Sec: 13048.293945\n",
      "\n",
      "Epoch Step: 501 Loss: 1.738679 Tokens per Sec: 12454.361328\n",
      "\n",
      "Epoch Step: 551 Loss: 2.646760 Tokens per Sec: 12992.543945\n",
      "\n",
      "Epoch Step: 601 Loss: 2.846379 Tokens per Sec: 12828.531250\n",
      "\n",
      "Epoch Step: 651 Loss: 2.435176 Tokens per Sec: 12871.244141\n",
      "\n",
      "Epoch Step: 701 Loss: 2.366792 Tokens per Sec: 12740.998047\n",
      "\n",
      "Epoch Step: 751 Loss: 2.787233 Tokens per Sec: 13268.054688\n",
      "\n",
      "Epoch Step: 801 Loss: 1.926152 Tokens per Sec: 13098.394531\n",
      "\n",
      "Epoch Step: 851 Loss: 2.793087 Tokens per Sec: 13034.102539\n",
      "\n",
      "Epoch Step: 901 Loss: 2.695823 Tokens per Sec: 13129.911133\n",
      "\n",
      "Epoch Step: 951 Loss: 2.515595 Tokens per Sec: 13343.874023\n",
      "\n",
      "Epoch Step: 1001 Loss: 2.431388 Tokens per Sec: 13058.510742\n",
      "\n",
      "Epoch Step: 1051 Loss: 3.168074 Tokens per Sec: 12696.616211\n",
      "\n",
      "Epoch Step: 1101 Loss: 2.577536 Tokens per Sec: 12598.186523\n",
      "\n",
      "Epoch Step: 1151 Loss: 2.733093 Tokens per Sec: 13074.923828\n",
      "\n",
      "Epoch Step: 1201 Loss: 2.322781 Tokens per Sec: 13238.545898\n",
      "\n",
      "Epoch Step: 1251 Loss: 3.152917 Tokens per Sec: 13123.038086\n",
      "\n",
      "Epoch Step: 1301 Loss: 3.137402 Tokens per Sec: 12668.033203\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.072333 Tokens per Sec: 13146.870117\n",
      "\n",
      "Epoch Step: 1401 Loss: 3.163915 Tokens per Sec: 13201.648438\n",
      "\n",
      "Epoch Step: 1451 Loss: 3.188279 Tokens per Sec: 13227.624023\n",
      "\n",
      "Epoch Step: 1501 Loss: 2.812073 Tokens per Sec: 13211.455078\n",
      "\n",
      "Epoch Step: 1551 Loss: 2.930918 Tokens per Sec: 13015.763672\n",
      "\n",
      "Epoch Step: 1601 Loss: 2.972107 Tokens per Sec: 13177.647461\n",
      "\n",
      "Epoch Step: 1651 Loss: 2.805959 Tokens per Sec: 12937.237305\n",
      "\n",
      "Epoch Step: 1701 Loss: 2.352376 Tokens per Sec: 12897.623047\n",
      "\n",
      "Epoch Step: 1751 Loss: 3.463797 Tokens per Sec: 12769.687500\n",
      "\n",
      "Epoch Step: 1801 Loss: 2.534187 Tokens per Sec: 12915.120117\n",
      "\n",
      "Epoch Step: 1851 Loss: 3.375661 Tokens per Sec: 13133.016602\n",
      "\n",
      "Epoch Step: 1901 Loss: 3.052786 Tokens per Sec: 13567.067383\n",
      "\n",
      "Epoch Step: 1951 Loss: 3.347512 Tokens per Sec: 12271.088867\n",
      "\n",
      "Epoch Step: 2001 Loss: 2.644691 Tokens per Sec: 11893.242188\n",
      "\n",
      "Epoch Step: 2051 Loss: 2.702438 Tokens per Sec: 11443.001953\n",
      "\n",
      "Epoch Step: 2101 Loss: 2.914955 Tokens per Sec: 11465.429688\n",
      "\n",
      "Epoch Step: 2151 Loss: 2.814597 Tokens per Sec: 13755.068359\n",
      "\n",
      "Epoch Step: 1 Loss: 1.919573 Tokens per Sec: 11766.230469\n",
      "\n",
      "tensor(2.4798, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 2.144595 Tokens per Sec: 2323.268066\n",
      "\n",
      "Epoch Step: 51 Loss: 2.201193 Tokens per Sec: 13243.500977\n",
      "\n",
      "Epoch Step: 101 Loss: 2.404953 Tokens per Sec: 13445.861328\n",
      "\n",
      "Epoch Step: 151 Loss: 2.550951 Tokens per Sec: 13748.556641\n",
      "\n",
      "Epoch Step: 201 Loss: 2.832505 Tokens per Sec: 13710.783203\n",
      "\n",
      "Epoch Step: 251 Loss: 2.202229 Tokens per Sec: 12892.844727\n",
      "\n",
      "Epoch Step: 301 Loss: 2.846608 Tokens per Sec: 12990.461914\n",
      "\n",
      "Epoch Step: 351 Loss: 2.663741 Tokens per Sec: 13049.366211\n",
      "\n",
      "Epoch Step: 401 Loss: 2.916634 Tokens per Sec: 13187.460938\n",
      "\n",
      "Epoch Step: 451 Loss: 2.893493 Tokens per Sec: 13160.256836\n",
      "\n",
      "Epoch Step: 501 Loss: 2.948110 Tokens per Sec: 12915.339844\n",
      "\n",
      "Epoch Step: 551 Loss: 2.555897 Tokens per Sec: 12932.076172\n",
      "\n",
      "Epoch Step: 601 Loss: 2.025236 Tokens per Sec: 12604.209961\n",
      "\n",
      "Epoch Step: 651 Loss: 3.040673 Tokens per Sec: 13010.064453\n",
      "\n",
      "Epoch Step: 701 Loss: 2.028682 Tokens per Sec: 12345.507812\n",
      "\n",
      "Epoch Step: 751 Loss: 3.018575 Tokens per Sec: 13018.144531\n",
      "\n",
      "Epoch Step: 801 Loss: 2.626314 Tokens per Sec: 13127.672852\n",
      "\n",
      "Epoch Step: 851 Loss: 3.352213 Tokens per Sec: 13130.111328\n",
      "\n",
      "Epoch Step: 901 Loss: 1.401626 Tokens per Sec: 12788.051758\n",
      "\n",
      "Epoch Step: 951 Loss: 2.439926 Tokens per Sec: 12850.317383\n",
      "\n",
      "Epoch Step: 1001 Loss: 2.504722 Tokens per Sec: 12630.229492\n",
      "\n",
      "Epoch Step: 1051 Loss: 2.758792 Tokens per Sec: 12805.616211\n",
      "\n",
      "Epoch Step: 1101 Loss: 2.459558 Tokens per Sec: 12787.737305\n",
      "\n",
      "Epoch Step: 1151 Loss: 3.051839 Tokens per Sec: 12620.911133\n",
      "\n",
      "Epoch Step: 1201 Loss: 2.974522 Tokens per Sec: 13071.589844\n",
      "\n",
      "Epoch Step: 1251 Loss: 2.355406 Tokens per Sec: 12856.208008\n",
      "\n",
      "Epoch Step: 1301 Loss: 2.439389 Tokens per Sec: 12992.062500\n",
      "\n",
      "Epoch Step: 1351 Loss: 2.806312 Tokens per Sec: 12897.225586\n",
      "\n",
      "Epoch Step: 1401 Loss: 2.660784 Tokens per Sec: 12758.190430\n",
      "\n",
      "Epoch Step: 1451 Loss: 2.442335 Tokens per Sec: 12947.346680\n",
      "\n",
      "Epoch Step: 1501 Loss: 2.083586 Tokens per Sec: 12729.919922\n",
      "\n",
      "Epoch Step: 1551 Loss: 2.730143 Tokens per Sec: 12957.563477\n",
      "\n",
      "Epoch Step: 1601 Loss: 2.862112 Tokens per Sec: 13371.631836\n",
      "\n",
      "Epoch Step: 1651 Loss: 2.967964 Tokens per Sec: 13183.454102\n",
      "\n",
      "Epoch Step: 1701 Loss: 3.095282 Tokens per Sec: 12909.227539\n",
      "\n",
      "Epoch Step: 1751 Loss: 2.194938 Tokens per Sec: 12817.889648\n",
      "\n",
      "Epoch Step: 1801 Loss: 2.632122 Tokens per Sec: 12749.250977\n",
      "\n",
      "Epoch Step: 1851 Loss: 2.075788 Tokens per Sec: 12893.120117\n",
      "\n",
      "Epoch Step: 1901 Loss: 2.838164 Tokens per Sec: 12963.553711\n",
      "\n",
      "Epoch Step: 1951 Loss: 3.029540 Tokens per Sec: 12697.950195\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.972469 Tokens per Sec: 12986.157227\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.747389 Tokens per Sec: 12456.535156\n",
      "\n",
      "Epoch Step: 2101 Loss: 2.513736 Tokens per Sec: 13136.889648\n",
      "\n",
      "Epoch Step: 2151 Loss: 2.460214 Tokens per Sec: 13571.482422\n",
      "\n",
      "Epoch Step: 1 Loss: 1.797477 Tokens per Sec: 8998.610352\n",
      "\n",
      "tensor(2.3704, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 2.970063 Tokens per Sec: 2022.112427\n",
      "\n",
      "Epoch Step: 51 Loss: 2.837696 Tokens per Sec: 11166.101562\n",
      "\n",
      "Epoch Step: 101 Loss: 2.495446 Tokens per Sec: 11657.075195\n",
      "\n",
      "Epoch Step: 151 Loss: 3.026897 Tokens per Sec: 11717.683594\n",
      "\n",
      "Epoch Step: 201 Loss: 3.002229 Tokens per Sec: 13744.968750\n",
      "\n",
      "Epoch Step: 251 Loss: 2.449269 Tokens per Sec: 13645.006836\n",
      "\n",
      "Epoch Step: 301 Loss: 2.700024 Tokens per Sec: 12881.593750\n",
      "\n",
      "Epoch Step: 351 Loss: 1.934552 Tokens per Sec: 13496.668945\n",
      "\n",
      "Epoch Step: 401 Loss: 3.308639 Tokens per Sec: 13590.614258\n",
      "\n",
      "Epoch Step: 451 Loss: 2.512936 Tokens per Sec: 13865.374023\n",
      "\n",
      "Epoch Step: 501 Loss: 2.438754 Tokens per Sec: 13646.544922\n",
      "\n",
      "Epoch Step: 551 Loss: 2.231958 Tokens per Sec: 13120.651367\n",
      "\n",
      "Epoch Step: 601 Loss: 3.177863 Tokens per Sec: 13116.687500\n",
      "\n",
      "Epoch Step: 651 Loss: 2.712406 Tokens per Sec: 12873.556641\n",
      "\n",
      "Epoch Step: 701 Loss: 2.288818 Tokens per Sec: 12825.526367\n",
      "\n",
      "Epoch Step: 751 Loss: 2.188148 Tokens per Sec: 12673.605469\n",
      "\n",
      "Epoch Step: 801 Loss: 2.520184 Tokens per Sec: 12958.533203\n",
      "\n",
      "Epoch Step: 851 Loss: 3.069129 Tokens per Sec: 12375.850586\n",
      "\n",
      "Epoch Step: 901 Loss: 2.200361 Tokens per Sec: 12495.877930\n",
      "\n",
      "Epoch Step: 951 Loss: 2.703701 Tokens per Sec: 12936.766602\n",
      "\n",
      "Epoch Step: 1001 Loss: 3.298886 Tokens per Sec: 12782.032227\n",
      "\n",
      "Epoch Step: 1051 Loss: 2.706264 Tokens per Sec: 12570.894531\n",
      "\n",
      "Epoch Step: 1101 Loss: 2.048933 Tokens per Sec: 12666.907227\n",
      "\n",
      "Epoch Step: 1151 Loss: 2.062007 Tokens per Sec: 13092.114258\n",
      "\n",
      "Epoch Step: 1201 Loss: 2.402152 Tokens per Sec: 12887.177734\n",
      "\n",
      "Epoch Step: 1251 Loss: 2.216372 Tokens per Sec: 12801.801758\n",
      "\n",
      "Epoch Step: 1301 Loss: 2.220828 Tokens per Sec: 13125.050781\n",
      "\n",
      "Epoch Step: 1351 Loss: 2.627067 Tokens per Sec: 13125.975586\n",
      "\n",
      "Epoch Step: 1401 Loss: 2.059372 Tokens per Sec: 12774.308594\n",
      "\n",
      "Epoch Step: 1451 Loss: 2.675714 Tokens per Sec: 12850.187500\n",
      "\n",
      "Epoch Step: 1501 Loss: 2.352673 Tokens per Sec: 12618.710938\n",
      "\n",
      "Epoch Step: 1551 Loss: 2.771910 Tokens per Sec: 13167.902344\n",
      "\n",
      "Epoch Step: 1601 Loss: 2.918504 Tokens per Sec: 13116.262695\n",
      "\n",
      "Epoch Step: 1651 Loss: 2.696841 Tokens per Sec: 12949.441406\n",
      "\n",
      "Epoch Step: 1701 Loss: 2.221332 Tokens per Sec: 12718.249023\n",
      "\n",
      "Epoch Step: 1751 Loss: 2.825421 Tokens per Sec: 12935.480469\n",
      "\n",
      "Epoch Step: 1801 Loss: 2.353412 Tokens per Sec: 12871.464844\n",
      "\n",
      "Epoch Step: 1851 Loss: 2.789479 Tokens per Sec: 12938.677734\n",
      "\n",
      "Epoch Step: 1901 Loss: 2.097258 Tokens per Sec: 12855.060547\n",
      "\n",
      "Epoch Step: 1951 Loss: 2.587488 Tokens per Sec: 13005.788086\n",
      "\n",
      "Epoch Step: 2001 Loss: 2.571472 Tokens per Sec: 13330.031250\n",
      "\n",
      "Epoch Step: 2051 Loss: 2.517916 Tokens per Sec: 12890.666992\n",
      "\n",
      "Epoch Step: 2101 Loss: 2.238649 Tokens per Sec: 12152.302734\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.965434 Tokens per Sec: 13031.069336\n",
      "\n",
      "Epoch Step: 1 Loss: 1.772103 Tokens per Sec: 10462.811523\n",
      "\n",
      "tensor(2.2614, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.879978 Tokens per Sec: 2565.886719\n",
      "\n",
      "Epoch Step: 51 Loss: 2.820015 Tokens per Sec: 12745.771484\n",
      "\n",
      "Epoch Step: 101 Loss: 2.312087 Tokens per Sec: 12702.714844\n",
      "\n",
      "Epoch Step: 151 Loss: 2.382488 Tokens per Sec: 12864.682617\n",
      "\n",
      "Epoch Step: 201 Loss: 2.742219 Tokens per Sec: 13216.976562\n",
      "\n",
      "Epoch Step: 251 Loss: 2.083439 Tokens per Sec: 13634.785156\n",
      "\n",
      "Epoch Step: 301 Loss: 1.884027 Tokens per Sec: 12184.451172\n",
      "\n",
      "Epoch Step: 351 Loss: 2.141696 Tokens per Sec: 11878.703125\n",
      "\n",
      "Epoch Step: 401 Loss: 2.358006 Tokens per Sec: 11864.632812\n",
      "\n",
      "Epoch Step: 451 Loss: 2.166789 Tokens per Sec: 12238.541016\n",
      "\n",
      "Epoch Step: 501 Loss: 2.245682 Tokens per Sec: 13626.669922\n",
      "\n",
      "Epoch Step: 551 Loss: 1.916570 Tokens per Sec: 13265.082031\n",
      "\n",
      "Epoch Step: 601 Loss: 2.195768 Tokens per Sec: 13742.467773\n",
      "\n",
      "Epoch Step: 651 Loss: 2.522525 Tokens per Sec: 13630.257812\n",
      "\n",
      "Epoch Step: 701 Loss: 2.554703 Tokens per Sec: 13883.541992\n",
      "\n",
      "Epoch Step: 751 Loss: 2.148777 Tokens per Sec: 13418.330078\n",
      "\n",
      "Epoch Step: 801 Loss: 1.972848 Tokens per Sec: 12742.705078\n",
      "\n",
      "Epoch Step: 851 Loss: 2.437331 Tokens per Sec: 13113.960938\n",
      "\n",
      "Epoch Step: 901 Loss: 2.792356 Tokens per Sec: 12957.675781\n",
      "\n",
      "Epoch Step: 951 Loss: 2.134521 Tokens per Sec: 12844.270508\n",
      "\n",
      "Epoch Step: 1001 Loss: 2.562842 Tokens per Sec: 12866.801758\n",
      "\n",
      "Epoch Step: 1051 Loss: 2.346995 Tokens per Sec: 13210.985352\n",
      "\n",
      "Epoch Step: 1101 Loss: 2.886257 Tokens per Sec: 12922.941406\n",
      "\n",
      "Epoch Step: 1151 Loss: 2.750852 Tokens per Sec: 13058.582031\n",
      "\n",
      "Epoch Step: 1201 Loss: 2.544811 Tokens per Sec: 12785.748047\n",
      "\n",
      "Epoch Step: 1251 Loss: 2.706714 Tokens per Sec: 13065.659180\n",
      "\n",
      "Epoch Step: 1301 Loss: 2.906324 Tokens per Sec: 12684.030273\n",
      "\n",
      "Epoch Step: 1351 Loss: 2.575962 Tokens per Sec: 13044.840820\n",
      "\n",
      "Epoch Step: 1401 Loss: 2.323296 Tokens per Sec: 12840.894531\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.943048 Tokens per Sec: 12795.500000\n",
      "\n",
      "Epoch Step: 1501 Loss: 2.087280 Tokens per Sec: 12896.857422\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.499810 Tokens per Sec: 12964.676758\n",
      "\n",
      "Epoch Step: 1601 Loss: 2.527240 Tokens per Sec: 13301.472656\n",
      "\n",
      "Epoch Step: 1651 Loss: 2.463249 Tokens per Sec: 13181.937500\n",
      "\n",
      "Epoch Step: 1701 Loss: 2.124671 Tokens per Sec: 12871.513672\n",
      "\n",
      "Epoch Step: 1751 Loss: 2.732703 Tokens per Sec: 12079.653320\n",
      "\n",
      "Epoch Step: 1801 Loss: 2.070095 Tokens per Sec: 12825.780273\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.922475 Tokens per Sec: 12687.124023\n",
      "\n",
      "Epoch Step: 1901 Loss: 2.772179 Tokens per Sec: 13085.721680\n",
      "\n",
      "Epoch Step: 1951 Loss: 2.685914 Tokens per Sec: 12947.185547\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.838589 Tokens per Sec: 12881.916016\n",
      "\n",
      "Epoch Step: 2051 Loss: 2.855065 Tokens per Sec: 13231.352539\n",
      "\n",
      "Epoch Step: 2101 Loss: 2.346489 Tokens per Sec: 12561.543945\n",
      "\n",
      "Epoch Step: 2151 Loss: 3.070251 Tokens per Sec: 13321.001953\n",
      "\n",
      "Epoch Step: 1 Loss: 1.629702 Tokens per Sec: 11683.443359\n",
      "\n",
      "tensor(2.1462, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 2.848671 Tokens per Sec: 2630.837158\n",
      "\n",
      "Epoch Step: 51 Loss: 2.417245 Tokens per Sec: 12964.165039\n",
      "\n",
      "Epoch Step: 101 Loss: 2.098970 Tokens per Sec: 12985.076172\n",
      "\n",
      "Epoch Step: 151 Loss: 2.043347 Tokens per Sec: 12882.362305\n",
      "\n",
      "Epoch Step: 201 Loss: 1.536836 Tokens per Sec: 12895.310547\n",
      "\n",
      "Epoch Step: 251 Loss: 1.740458 Tokens per Sec: 12793.702148\n",
      "\n",
      "Epoch Step: 301 Loss: 2.655873 Tokens per Sec: 13017.132812\n",
      "\n",
      "Epoch Step: 351 Loss: 2.025849 Tokens per Sec: 13012.448242\n",
      "\n",
      "Epoch Step: 401 Loss: 1.896187 Tokens per Sec: 12662.932617\n",
      "\n",
      "Epoch Step: 451 Loss: 2.192947 Tokens per Sec: 12830.805664\n",
      "\n",
      "Epoch Step: 501 Loss: 2.099531 Tokens per Sec: 13504.645508\n",
      "\n",
      "Epoch Step: 551 Loss: 2.882994 Tokens per Sec: 12687.000977\n",
      "\n",
      "Epoch Step: 601 Loss: 2.388516 Tokens per Sec: 11680.095703\n",
      "\n",
      "Epoch Step: 651 Loss: 2.290365 Tokens per Sec: 11581.784180\n",
      "\n",
      "Epoch Step: 701 Loss: 1.524994 Tokens per Sec: 12281.303711\n",
      "\n",
      "Epoch Step: 751 Loss: 2.510767 Tokens per Sec: 13976.189453\n",
      "\n",
      "Epoch Step: 801 Loss: 2.056579 Tokens per Sec: 13777.947266\n",
      "\n",
      "Epoch Step: 851 Loss: 2.167074 Tokens per Sec: 13771.862305\n",
      "\n",
      "Epoch Step: 901 Loss: 2.268559 Tokens per Sec: 13463.123047\n",
      "\n",
      "Epoch Step: 951 Loss: 2.667120 Tokens per Sec: 13705.031250\n",
      "\n",
      "Epoch Step: 1001 Loss: 2.422763 Tokens per Sec: 13502.601562\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.975923 Tokens per Sec: 12938.558594\n",
      "\n",
      "Epoch Step: 1101 Loss: 3.324725 Tokens per Sec: 12792.424805\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.543324 Tokens per Sec: 12880.909180\n",
      "\n",
      "Epoch Step: 1201 Loss: 2.517217 Tokens per Sec: 13001.784180\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.814857 Tokens per Sec: 12698.387695\n",
      "\n",
      "Epoch Step: 1301 Loss: 2.684279 Tokens per Sec: 12815.677734\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.565933 Tokens per Sec: 13085.770508\n",
      "\n",
      "Epoch Step: 1401 Loss: 2.093063 Tokens per Sec: 12914.320312\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.906208 Tokens per Sec: 13053.617188\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.818932 Tokens per Sec: 13038.111328\n",
      "\n",
      "Epoch Step: 1551 Loss: 2.904923 Tokens per Sec: 12720.858398\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.864176 Tokens per Sec: 13034.725586\n",
      "\n",
      "Epoch Step: 1651 Loss: 2.500745 Tokens per Sec: 13071.783203\n",
      "\n",
      "Epoch Step: 1701 Loss: 2.290868 Tokens per Sec: 12602.961914\n",
      "\n",
      "Epoch Step: 1751 Loss: 2.136491 Tokens per Sec: 13296.700195\n",
      "\n",
      "Epoch Step: 1801 Loss: 3.025309 Tokens per Sec: 13236.136719\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.518821 Tokens per Sec: 12815.641602\n",
      "\n",
      "Epoch Step: 1901 Loss: 2.161982 Tokens per Sec: 12671.239258\n",
      "\n",
      "Epoch Step: 1951 Loss: 2.519053 Tokens per Sec: 12888.674805\n",
      "\n",
      "Epoch Step: 2001 Loss: 2.109975 Tokens per Sec: 12430.346680\n",
      "\n",
      "Epoch Step: 2051 Loss: 2.238562 Tokens per Sec: 12821.529297\n",
      "\n",
      "Epoch Step: 2101 Loss: 2.213830 Tokens per Sec: 13078.779297\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.881411 Tokens per Sec: 12968.217773\n",
      "\n",
      "Epoch Step: 1 Loss: 1.553063 Tokens per Sec: 10821.506836\n",
      "\n",
      "tensor(2.0362, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 2.436119 Tokens per Sec: 2541.457031\n",
      "\n",
      "Epoch Step: 51 Loss: 1.700255 Tokens per Sec: 13377.922852\n",
      "\n",
      "Epoch Step: 101 Loss: 1.990352 Tokens per Sec: 11327.458984\n",
      "\n",
      "Epoch Step: 151 Loss: 2.077748 Tokens per Sec: 12406.497070\n",
      "\n",
      "Epoch Step: 201 Loss: 2.674870 Tokens per Sec: 12659.236328\n",
      "\n",
      "Epoch Step: 251 Loss: 2.317910 Tokens per Sec: 12768.468750\n",
      "\n",
      "Epoch Step: 301 Loss: 1.947294 Tokens per Sec: 12838.374023\n",
      "\n",
      "Epoch Step: 351 Loss: 2.026203 Tokens per Sec: 12687.893555\n",
      "\n",
      "Epoch Step: 401 Loss: 3.009550 Tokens per Sec: 12891.508789\n",
      "\n",
      "Epoch Step: 451 Loss: 1.779057 Tokens per Sec: 13384.882812\n",
      "\n",
      "Epoch Step: 501 Loss: 1.638288 Tokens per Sec: 12948.772461\n",
      "\n",
      "Epoch Step: 551 Loss: 1.925077 Tokens per Sec: 13035.560547\n",
      "\n",
      "Epoch Step: 601 Loss: 2.165742 Tokens per Sec: 12576.109375\n",
      "\n",
      "Epoch Step: 651 Loss: 1.383448 Tokens per Sec: 13228.162109\n",
      "\n",
      "Epoch Step: 701 Loss: 2.685112 Tokens per Sec: 13068.533203\n",
      "\n",
      "Epoch Step: 751 Loss: 2.433601 Tokens per Sec: 13410.770508\n",
      "\n",
      "Epoch Step: 801 Loss: 1.880837 Tokens per Sec: 11933.843750\n",
      "\n",
      "Epoch Step: 851 Loss: 1.966017 Tokens per Sec: 12189.339844\n",
      "\n",
      "Epoch Step: 901 Loss: 1.845806 Tokens per Sec: 11355.317383\n",
      "\n",
      "Epoch Step: 951 Loss: 2.404160 Tokens per Sec: 12351.377930\n",
      "\n",
      "Epoch Step: 1001 Loss: 2.145494 Tokens per Sec: 13879.385742\n",
      "\n",
      "Epoch Step: 1051 Loss: 2.829070 Tokens per Sec: 13507.833984\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.673604 Tokens per Sec: 13817.779297\n",
      "\n",
      "Epoch Step: 1151 Loss: 2.177790 Tokens per Sec: 13212.444336\n",
      "\n",
      "Epoch Step: 1201 Loss: 3.128568 Tokens per Sec: 12863.246094\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.945544 Tokens per Sec: 12964.676758\n",
      "\n",
      "Epoch Step: 1301 Loss: 2.167837 Tokens per Sec: 12984.954102\n",
      "\n",
      "Epoch Step: 1351 Loss: 3.187543 Tokens per Sec: 12764.633789\n",
      "\n",
      "Epoch Step: 1401 Loss: 2.138003 Tokens per Sec: 13047.633789\n",
      "\n",
      "Epoch Step: 1451 Loss: 2.546232 Tokens per Sec: 13152.165039\n",
      "\n",
      "Epoch Step: 1501 Loss: 2.252718 Tokens per Sec: 13258.751953\n",
      "\n",
      "Epoch Step: 1551 Loss: 2.708036 Tokens per Sec: 13071.020508\n",
      "\n",
      "Epoch Step: 1601 Loss: 2.620257 Tokens per Sec: 12839.070312\n",
      "\n",
      "Epoch Step: 1651 Loss: 2.558878 Tokens per Sec: 12627.747070\n",
      "\n",
      "Epoch Step: 1701 Loss: 2.147503 Tokens per Sec: 12355.382812\n",
      "\n",
      "Epoch Step: 1751 Loss: 2.352410 Tokens per Sec: 13267.399414\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.503176 Tokens per Sec: 12871.564453\n",
      "\n",
      "Epoch Step: 1851 Loss: 2.852568 Tokens per Sec: 13305.283203\n",
      "\n",
      "Epoch Step: 1901 Loss: 2.337625 Tokens per Sec: 12578.250977\n",
      "\n",
      "Epoch Step: 1951 Loss: 2.496031 Tokens per Sec: 13132.462891\n",
      "\n",
      "Epoch Step: 2001 Loss: 2.104652 Tokens per Sec: 12658.600586\n",
      "\n",
      "Epoch Step: 2051 Loss: 2.398213 Tokens per Sec: 12989.171875\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.705070 Tokens per Sec: 12711.957031\n",
      "\n",
      "Epoch Step: 2151 Loss: 2.195339 Tokens per Sec: 12770.287109\n",
      "\n",
      "Epoch Step: 1 Loss: 1.552927 Tokens per Sec: 11686.027344\n",
      "\n",
      "tensor(1.9665, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 2.263878 Tokens per Sec: 2618.114502\n",
      "\n",
      "Epoch Step: 51 Loss: 2.488476 Tokens per Sec: 12974.276367\n",
      "\n",
      "Epoch Step: 101 Loss: 2.092072 Tokens per Sec: 13031.579102\n",
      "\n",
      "Epoch Step: 151 Loss: 1.713893 Tokens per Sec: 12489.199219\n",
      "\n",
      "Epoch Step: 201 Loss: 2.144804 Tokens per Sec: 13074.918945\n",
      "\n",
      "Epoch Step: 251 Loss: 2.206327 Tokens per Sec: 12804.539062\n",
      "\n",
      "Epoch Step: 301 Loss: 1.788286 Tokens per Sec: 13166.119141\n",
      "\n",
      "Epoch Step: 351 Loss: 2.293554 Tokens per Sec: 13152.876953\n",
      "\n",
      "Epoch Step: 401 Loss: 2.332870 Tokens per Sec: 13226.584961\n",
      "\n",
      "Epoch Step: 451 Loss: 2.506326 Tokens per Sec: 13592.070312\n",
      "\n",
      "Epoch Step: 501 Loss: 1.943435 Tokens per Sec: 13051.083008\n",
      "\n",
      "Epoch Step: 551 Loss: 2.147903 Tokens per Sec: 12820.580078\n",
      "\n",
      "Epoch Step: 601 Loss: 2.071916 Tokens per Sec: 13171.092773\n",
      "\n",
      "Epoch Step: 651 Loss: 1.455350 Tokens per Sec: 13093.432617\n",
      "\n",
      "Epoch Step: 701 Loss: 2.122365 Tokens per Sec: 13455.137695\n",
      "\n",
      "Epoch Step: 751 Loss: 2.067902 Tokens per Sec: 13241.429688\n",
      "\n",
      "Epoch Step: 801 Loss: 1.880195 Tokens per Sec: 13285.367188\n",
      "\n",
      "Epoch Step: 851 Loss: 2.266349 Tokens per Sec: 13301.958984\n",
      "\n",
      "Epoch Step: 901 Loss: 2.448283 Tokens per Sec: 13127.575195\n",
      "\n",
      "Epoch Step: 951 Loss: 1.857154 Tokens per Sec: 13608.211914\n",
      "\n",
      "Epoch Step: 1001 Loss: 2.465444 Tokens per Sec: 13235.283203\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.578608 Tokens per Sec: 12295.254883\n",
      "\n",
      "Epoch Step: 1101 Loss: 2.330110 Tokens per Sec: 12263.304688\n",
      "\n",
      "Epoch Step: 1151 Loss: 2.026870 Tokens per Sec: 11901.721680\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.989412 Tokens per Sec: 13391.493164\n",
      "\n",
      "Epoch Step: 1251 Loss: 3.061003 Tokens per Sec: 13551.207031\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.909749 Tokens per Sec: 12726.309570\n",
      "\n",
      "Epoch Step: 1351 Loss: 2.171386 Tokens per Sec: 13437.364258\n",
      "\n",
      "Epoch Step: 1401 Loss: 2.159699 Tokens per Sec: 13102.088867\n",
      "\n",
      "Epoch Step: 1451 Loss: 2.197910 Tokens per Sec: 13145.173828\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.563389 Tokens per Sec: 13086.763672\n",
      "\n",
      "Epoch Step: 1551 Loss: 2.247483 Tokens per Sec: 12557.612305\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.724494 Tokens per Sec: 13229.102539\n",
      "\n",
      "Epoch Step: 1651 Loss: 2.799330 Tokens per Sec: 12984.938477\n",
      "\n",
      "Epoch Step: 1701 Loss: 2.366059 Tokens per Sec: 13312.147461\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.701789 Tokens per Sec: 13022.591797\n",
      "\n",
      "Epoch Step: 1801 Loss: 2.283732 Tokens per Sec: 12866.672852\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.831396 Tokens per Sec: 13050.318359\n",
      "\n",
      "Epoch Step: 1901 Loss: 2.266294 Tokens per Sec: 13441.025391\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.905604 Tokens per Sec: 13152.879883\n",
      "\n",
      "Epoch Step: 2001 Loss: 2.332577 Tokens per Sec: 13136.948242\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.892483 Tokens per Sec: 12951.591797\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.860505 Tokens per Sec: 13468.843750\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.813515 Tokens per Sec: 13174.572266\n",
      "\n",
      "Epoch Step: 1 Loss: 1.481365 Tokens per Sec: 10757.171875\n",
      "\n",
      "tensor(1.8857, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 2.403347 Tokens per Sec: 2090.128418\n",
      "\n",
      "Epoch Step: 51 Loss: 2.381539 Tokens per Sec: 13110.431641\n",
      "\n",
      "Epoch Step: 101 Loss: 1.912194 Tokens per Sec: 13010.715820\n",
      "\n",
      "Epoch Step: 151 Loss: 1.781722 Tokens per Sec: 13288.305664\n",
      "\n",
      "Epoch Step: 201 Loss: 2.737409 Tokens per Sec: 13102.802734\n",
      "\n",
      "Epoch Step: 251 Loss: 2.305976 Tokens per Sec: 13022.656250\n",
      "\n",
      "Epoch Step: 301 Loss: 2.936986 Tokens per Sec: 13238.659180\n",
      "\n",
      "Epoch Step: 351 Loss: 1.791891 Tokens per Sec: 12787.707031\n",
      "\n",
      "Epoch Step: 401 Loss: 2.340105 Tokens per Sec: 13110.815430\n",
      "\n",
      "Epoch Step: 451 Loss: 2.430831 Tokens per Sec: 12960.118164\n",
      "\n",
      "Epoch Step: 501 Loss: 1.705675 Tokens per Sec: 12966.423828\n",
      "\n",
      "Epoch Step: 551 Loss: 1.908506 Tokens per Sec: 13027.825195\n",
      "\n",
      "Epoch Step: 601 Loss: 1.671836 Tokens per Sec: 13250.125977\n",
      "\n",
      "Epoch Step: 651 Loss: 1.889552 Tokens per Sec: 13242.932617\n",
      "\n",
      "Epoch Step: 701 Loss: 2.134151 Tokens per Sec: 13423.162109\n",
      "\n",
      "Epoch Step: 751 Loss: 2.497572 Tokens per Sec: 12953.736328\n",
      "\n",
      "Epoch Step: 801 Loss: 1.861719 Tokens per Sec: 13293.948242\n",
      "\n",
      "Epoch Step: 851 Loss: 2.060240 Tokens per Sec: 13167.558594\n",
      "\n",
      "Epoch Step: 901 Loss: 2.600042 Tokens per Sec: 12889.335938\n",
      "\n",
      "Epoch Step: 951 Loss: 2.842718 Tokens per Sec: 13300.773438\n",
      "\n",
      "Epoch Step: 1001 Loss: 2.011730 Tokens per Sec: 12866.862305\n",
      "\n",
      "Epoch Step: 1051 Loss: 2.248945 Tokens per Sec: 13166.243164\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.926849 Tokens per Sec: 13071.089844\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.635453 Tokens per Sec: 13381.604492\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.441377 Tokens per Sec: 13489.022461\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.677699 Tokens per Sec: 12645.539062\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.798378 Tokens per Sec: 12414.293945\n",
      "\n",
      "Epoch Step: 1351 Loss: 2.036372 Tokens per Sec: 12324.459961\n",
      "\n",
      "Epoch Step: 1401 Loss: 2.327974 Tokens per Sec: 13456.165039\n",
      "\n",
      "Epoch Step: 1451 Loss: 2.139807 Tokens per Sec: 13311.210938\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.908323 Tokens per Sec: 14109.967773\n",
      "\n",
      "Epoch Step: 1551 Loss: 2.090924 Tokens per Sec: 13870.136719\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.965474 Tokens per Sec: 13715.407227\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.375731 Tokens per Sec: 13987.784180\n",
      "\n",
      "Epoch Step: 1701 Loss: 2.182116 Tokens per Sec: 13310.257812\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.618440 Tokens per Sec: 13328.957031\n",
      "\n",
      "Epoch Step: 1801 Loss: 2.167402 Tokens per Sec: 12846.414062\n",
      "\n",
      "Epoch Step: 1851 Loss: 2.568481 Tokens per Sec: 13273.565430\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.734307 Tokens per Sec: 13184.784180\n",
      "\n",
      "Epoch Step: 1951 Loss: 2.998307 Tokens per Sec: 13021.583008\n",
      "\n",
      "Epoch Step: 2001 Loss: 2.124246 Tokens per Sec: 13324.315430\n",
      "\n",
      "Epoch Step: 2051 Loss: 2.169854 Tokens per Sec: 13251.576172\n",
      "\n",
      "Epoch Step: 2101 Loss: 2.096480 Tokens per Sec: 13083.286133\n",
      "\n",
      "Epoch Step: 2151 Loss: 2.180991 Tokens per Sec: 13211.639648\n",
      "\n",
      "Epoch Step: 1 Loss: 1.449175 Tokens per Sec: 11550.625000\n",
      "\n",
      "tensor(1.8288, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 2.294553 Tokens per Sec: 2666.967285\n",
      "\n",
      "Epoch Step: 51 Loss: 2.150380 Tokens per Sec: 12919.891602\n",
      "\n",
      "Epoch Step: 101 Loss: 1.771089 Tokens per Sec: 13379.071289\n",
      "\n",
      "Epoch Step: 151 Loss: 2.331228 Tokens per Sec: 12956.984375\n",
      "\n",
      "Epoch Step: 201 Loss: 2.067836 Tokens per Sec: 13341.248047\n",
      "\n",
      "Epoch Step: 251 Loss: 1.474604 Tokens per Sec: 13265.471680\n",
      "\n",
      "Epoch Step: 301 Loss: 1.992493 Tokens per Sec: 12921.825195\n",
      "\n",
      "Epoch Step: 351 Loss: 2.052924 Tokens per Sec: 12891.189453\n",
      "\n",
      "Epoch Step: 401 Loss: 1.955689 Tokens per Sec: 13329.708984\n",
      "\n",
      "Epoch Step: 451 Loss: 2.350195 Tokens per Sec: 13238.490234\n",
      "\n",
      "Epoch Step: 501 Loss: 1.811893 Tokens per Sec: 13181.794922\n",
      "\n",
      "Epoch Step: 551 Loss: 1.394779 Tokens per Sec: 13181.864258\n",
      "\n",
      "Epoch Step: 601 Loss: 2.039308 Tokens per Sec: 13464.354492\n",
      "\n",
      "Epoch Step: 651 Loss: 2.413507 Tokens per Sec: 13346.268555\n",
      "\n",
      "Epoch Step: 701 Loss: 2.010534 Tokens per Sec: 12776.227539\n",
      "\n",
      "Epoch Step: 751 Loss: 2.117251 Tokens per Sec: 13050.983398\n",
      "\n",
      "Epoch Step: 801 Loss: 1.824742 Tokens per Sec: 13417.900391\n",
      "\n",
      "Epoch Step: 851 Loss: 2.282470 Tokens per Sec: 13128.536133\n",
      "\n",
      "Epoch Step: 901 Loss: 1.858562 Tokens per Sec: 13178.622070\n",
      "\n",
      "Epoch Step: 951 Loss: 2.210553 Tokens per Sec: 13333.839844\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.404310 Tokens per Sec: 13255.650391\n",
      "\n",
      "Epoch Step: 1051 Loss: 2.168279 Tokens per Sec: 12971.836914\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.944464 Tokens per Sec: 12812.012695\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.764747 Tokens per Sec: 12644.560547\n",
      "\n",
      "Epoch Step: 1201 Loss: 2.370767 Tokens per Sec: 13520.510742\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.346539 Tokens per Sec: 13180.796875\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.831267 Tokens per Sec: 13383.021484\n",
      "\n",
      "Epoch Step: 1351 Loss: 2.233212 Tokens per Sec: 13641.394531\n",
      "\n",
      "Epoch Step: 1401 Loss: 2.032645 Tokens per Sec: 13324.373047\n",
      "\n",
      "Epoch Step: 1451 Loss: 2.206123 Tokens per Sec: 12256.767578\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.628955 Tokens per Sec: 12126.811523\n",
      "\n",
      "Epoch Step: 1551 Loss: 2.512872 Tokens per Sec: 12042.833984\n",
      "\n",
      "Epoch Step: 1601 Loss: 2.097098 Tokens per Sec: 13838.240234\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.489916 Tokens per Sec: 13732.030273\n",
      "\n",
      "Epoch Step: 1701 Loss: 2.733739 Tokens per Sec: 13616.251953\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.827644 Tokens per Sec: 14063.538086\n",
      "\n",
      "Epoch Step: 1801 Loss: 2.113134 Tokens per Sec: 13737.687500\n",
      "\n",
      "Epoch Step: 1851 Loss: 2.791164 Tokens per Sec: 13767.526367\n",
      "\n",
      "Epoch Step: 1901 Loss: 2.172802 Tokens per Sec: 13602.673828\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.809273 Tokens per Sec: 13109.855469\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.620162 Tokens per Sec: 13210.239258\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.989131 Tokens per Sec: 13235.987305\n",
      "\n",
      "Epoch Step: 2101 Loss: 2.539470 Tokens per Sec: 13128.493164\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.670064 Tokens per Sec: 13143.470703\n",
      "\n",
      "Epoch Step: 1 Loss: 1.416045 Tokens per Sec: 11431.942383\n",
      "\n",
      "tensor(1.7744, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.847420 Tokens per Sec: 2918.462158\n",
      "\n",
      "Epoch Step: 51 Loss: 1.700387 Tokens per Sec: 13225.884766\n",
      "\n",
      "Epoch Step: 101 Loss: 1.843587 Tokens per Sec: 12998.138672\n",
      "\n",
      "Epoch Step: 151 Loss: 2.635886 Tokens per Sec: 13123.575195\n",
      "\n",
      "Epoch Step: 201 Loss: 1.701256 Tokens per Sec: 13268.484375\n",
      "\n",
      "Epoch Step: 251 Loss: 1.820830 Tokens per Sec: 13148.920898\n",
      "\n",
      "Epoch Step: 301 Loss: 1.735886 Tokens per Sec: 13479.459961\n",
      "\n",
      "Epoch Step: 351 Loss: 2.523891 Tokens per Sec: 13258.591797\n",
      "\n",
      "Epoch Step: 401 Loss: 1.740966 Tokens per Sec: 13272.575195\n",
      "\n",
      "Epoch Step: 451 Loss: 1.995150 Tokens per Sec: 13230.644531\n",
      "\n",
      "Epoch Step: 501 Loss: 1.615532 Tokens per Sec: 13189.551758\n",
      "\n",
      "Epoch Step: 551 Loss: 1.859170 Tokens per Sec: 13548.955078\n",
      "\n",
      "Epoch Step: 601 Loss: 1.718947 Tokens per Sec: 13280.730469\n",
      "\n",
      "Epoch Step: 651 Loss: 1.734014 Tokens per Sec: 13292.052734\n",
      "\n",
      "Epoch Step: 701 Loss: 1.559320 Tokens per Sec: 13248.910156\n",
      "\n",
      "Epoch Step: 751 Loss: 2.185956 Tokens per Sec: 12869.554688\n",
      "\n",
      "Epoch Step: 801 Loss: 2.292612 Tokens per Sec: 13021.704102\n",
      "\n",
      "Epoch Step: 851 Loss: 2.091365 Tokens per Sec: 13425.527344\n",
      "\n",
      "Epoch Step: 901 Loss: 2.308576 Tokens per Sec: 13231.892578\n",
      "\n",
      "Epoch Step: 951 Loss: 1.831585 Tokens per Sec: 12802.296875\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.692025 Tokens per Sec: 12984.545898\n",
      "\n",
      "Epoch Step: 1051 Loss: 2.497892 Tokens per Sec: 12677.625000\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.983245 Tokens per Sec: 13261.635742\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.731349 Tokens per Sec: 13245.165039\n",
      "\n",
      "Epoch Step: 1201 Loss: 2.142823 Tokens per Sec: 13213.240234\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.989745 Tokens per Sec: 13323.770508\n",
      "\n",
      "Epoch Step: 1301 Loss: 2.267248 Tokens per Sec: 13302.436523\n",
      "\n",
      "Epoch Step: 1351 Loss: 2.052210 Tokens per Sec: 13031.993164\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.560244 Tokens per Sec: 13090.608398\n",
      "\n",
      "Epoch Step: 1451 Loss: 2.194234 Tokens per Sec: 13248.930664\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.400549 Tokens per Sec: 13030.137695\n",
      "\n",
      "Epoch Step: 1551 Loss: 2.355141 Tokens per Sec: 13169.346680\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.871039 Tokens per Sec: 12779.522461\n",
      "\n",
      "Epoch Step: 1651 Loss: 2.864214 Tokens per Sec: 12255.992188\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.331566 Tokens per Sec: 12636.773438\n",
      "\n",
      "Epoch Step: 1751 Loss: 2.134574 Tokens per Sec: 12623.958008\n",
      "\n",
      "Epoch Step: 1801 Loss: 2.259102 Tokens per Sec: 13612.187500\n",
      "\n",
      "Epoch Step: 1851 Loss: 2.146358 Tokens per Sec: 13449.387695\n",
      "\n",
      "Epoch Step: 1901 Loss: 2.040952 Tokens per Sec: 13412.022461\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.755033 Tokens per Sec: 13888.402344\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.958238 Tokens per Sec: 13646.423828\n",
      "\n",
      "Epoch Step: 2051 Loss: 2.315034 Tokens per Sec: 13656.122070\n",
      "\n",
      "Epoch Step: 2101 Loss: 2.088715 Tokens per Sec: 13393.180664\n",
      "\n",
      "Epoch Step: 2151 Loss: 2.156010 Tokens per Sec: 12966.119141\n",
      "\n",
      "Epoch Step: 1 Loss: 1.376091 Tokens per Sec: 10617.339844\n",
      "\n",
      "tensor(1.7103, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.883625 Tokens per Sec: 2482.150146\n",
      "\n",
      "Epoch Step: 51 Loss: 2.092926 Tokens per Sec: 13223.158203\n",
      "\n",
      "Epoch Step: 101 Loss: 1.938709 Tokens per Sec: 13045.531250\n",
      "\n",
      "Epoch Step: 151 Loss: 2.280715 Tokens per Sec: 13338.710938\n",
      "\n",
      "Epoch Step: 201 Loss: 2.045589 Tokens per Sec: 13287.421875\n",
      "\n",
      "Epoch Step: 251 Loss: 1.988907 Tokens per Sec: 12634.797852\n",
      "\n",
      "Epoch Step: 301 Loss: 2.098959 Tokens per Sec: 13375.133789\n",
      "\n",
      "Epoch Step: 351 Loss: 1.347439 Tokens per Sec: 12914.990234\n",
      "\n",
      "Epoch Step: 401 Loss: 1.949494 Tokens per Sec: 13616.642578\n",
      "\n",
      "Epoch Step: 451 Loss: 1.318124 Tokens per Sec: 13008.656250\n",
      "\n",
      "Epoch Step: 501 Loss: 2.168533 Tokens per Sec: 13402.404297\n",
      "\n",
      "Epoch Step: 551 Loss: 2.150323 Tokens per Sec: 12746.059570\n",
      "\n",
      "Epoch Step: 601 Loss: 1.999026 Tokens per Sec: 12907.403320\n",
      "\n",
      "Epoch Step: 651 Loss: 2.270856 Tokens per Sec: 13005.000977\n",
      "\n",
      "Epoch Step: 701 Loss: 2.225712 Tokens per Sec: 12935.447266\n",
      "\n",
      "Epoch Step: 751 Loss: 2.269002 Tokens per Sec: 13255.893555\n",
      "\n",
      "Epoch Step: 801 Loss: 1.855034 Tokens per Sec: 13263.771484\n",
      "\n",
      "Epoch Step: 851 Loss: 1.997012 Tokens per Sec: 13223.920898\n",
      "\n",
      "Epoch Step: 901 Loss: 2.138438 Tokens per Sec: 13510.796875\n",
      "\n",
      "Epoch Step: 951 Loss: 1.642684 Tokens per Sec: 12981.484375\n",
      "\n",
      "Epoch Step: 1001 Loss: 2.477796 Tokens per Sec: 13083.341797\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.585640 Tokens per Sec: 13023.385742\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.811989 Tokens per Sec: 12982.942383\n",
      "\n",
      "Epoch Step: 1151 Loss: 2.009996 Tokens per Sec: 13010.280273\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.568311 Tokens per Sec: 13141.431641\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.464221 Tokens per Sec: 13237.970703\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.774440 Tokens per Sec: 13105.796875\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.518179 Tokens per Sec: 12958.178711\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.314978 Tokens per Sec: 13253.577148\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.868775 Tokens per Sec: 13216.727539\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.445256 Tokens per Sec: 13114.663086\n",
      "\n",
      "Epoch Step: 1551 Loss: 2.083406 Tokens per Sec: 13322.909180\n",
      "\n",
      "Epoch Step: 1601 Loss: 2.278322 Tokens per Sec: 12931.520508\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.550294 Tokens per Sec: 13050.593750\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.572942 Tokens per Sec: 12750.961914\n",
      "\n",
      "Epoch Step: 1751 Loss: 2.241723 Tokens per Sec: 13125.327148\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.955186 Tokens per Sec: 12408.883789\n",
      "\n",
      "Epoch Step: 1851 Loss: 2.178175 Tokens per Sec: 12264.424805\n",
      "\n",
      "Epoch Step: 1901 Loss: 2.098739 Tokens per Sec: 12520.673828\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.588665 Tokens per Sec: 13496.256836\n",
      "\n",
      "Epoch Step: 2001 Loss: 2.026695 Tokens per Sec: 12770.481445\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.907889 Tokens per Sec: 13429.184570\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.759579 Tokens per Sec: 13319.865234\n",
      "\n",
      "Epoch Step: 2151 Loss: 2.552460 Tokens per Sec: 13544.382812\n",
      "\n",
      "Epoch Step: 1 Loss: 1.321668 Tokens per Sec: 11215.639648\n",
      "\n",
      "tensor(1.6660, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 2.241851 Tokens per Sec: 2874.850098\n",
      "\n",
      "Epoch Step: 51 Loss: 1.785204 Tokens per Sec: 13000.897461\n",
      "\n",
      "Epoch Step: 101 Loss: 1.961344 Tokens per Sec: 12965.867188\n",
      "\n",
      "Epoch Step: 151 Loss: 1.553426 Tokens per Sec: 13466.094727\n",
      "\n",
      "Epoch Step: 201 Loss: 2.263779 Tokens per Sec: 13389.762695\n",
      "\n",
      "Epoch Step: 251 Loss: 1.864053 Tokens per Sec: 13096.521484\n",
      "\n",
      "Epoch Step: 301 Loss: 1.512785 Tokens per Sec: 13344.959961\n",
      "\n",
      "Epoch Step: 351 Loss: 2.079304 Tokens per Sec: 13321.219727\n",
      "\n",
      "Epoch Step: 401 Loss: 1.660586 Tokens per Sec: 13201.596680\n",
      "\n",
      "Epoch Step: 451 Loss: 2.043403 Tokens per Sec: 12845.164062\n",
      "\n",
      "Epoch Step: 501 Loss: 1.849780 Tokens per Sec: 12547.743164\n",
      "\n",
      "Epoch Step: 551 Loss: 1.780575 Tokens per Sec: 13204.010742\n",
      "\n",
      "Epoch Step: 601 Loss: 2.230747 Tokens per Sec: 13385.345703\n",
      "\n",
      "Epoch Step: 651 Loss: 1.989041 Tokens per Sec: 13329.652344\n",
      "\n",
      "Epoch Step: 701 Loss: 1.771234 Tokens per Sec: 13035.080078\n",
      "\n",
      "Epoch Step: 751 Loss: 1.576544 Tokens per Sec: 12830.044922\n",
      "\n",
      "Epoch Step: 801 Loss: 1.780964 Tokens per Sec: 13393.833984\n",
      "\n",
      "Epoch Step: 851 Loss: 1.913441 Tokens per Sec: 13418.850586\n",
      "\n",
      "Epoch Step: 901 Loss: 2.435039 Tokens per Sec: 12571.671875\n",
      "\n",
      "Epoch Step: 951 Loss: 1.496531 Tokens per Sec: 12752.041016\n",
      "\n",
      "Epoch Step: 1001 Loss: 2.226986 Tokens per Sec: 13146.737305\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.662179 Tokens per Sec: 13083.398438\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.871930 Tokens per Sec: 13035.958008\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.929237 Tokens per Sec: 13369.141602\n",
      "\n",
      "Epoch Step: 1201 Loss: 2.438590 Tokens per Sec: 12824.646484\n",
      "\n",
      "Epoch Step: 1251 Loss: 2.201418 Tokens per Sec: 12936.408203\n",
      "\n",
      "Epoch Step: 1301 Loss: 2.160178 Tokens per Sec: 13419.377930\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.950297 Tokens per Sec: 13598.687500\n",
      "\n",
      "Epoch Step: 1401 Loss: 2.045831 Tokens per Sec: 13235.001953\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.372783 Tokens per Sec: 13197.402344\n",
      "\n",
      "Epoch Step: 1501 Loss: 2.361146 Tokens per Sec: 12949.579102\n",
      "\n",
      "Epoch Step: 1551 Loss: 2.311395 Tokens per Sec: 13324.474609\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.861844 Tokens per Sec: 13389.630859\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.953512 Tokens per Sec: 13193.142578\n",
      "\n",
      "Epoch Step: 1701 Loss: 2.318630 Tokens per Sec: 13091.347656\n",
      "\n",
      "Epoch Step: 1751 Loss: 2.390725 Tokens per Sec: 12770.896484\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.790191 Tokens per Sec: 13413.590820\n",
      "\n",
      "Epoch Step: 1851 Loss: 2.264405 Tokens per Sec: 13229.478516\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.947841 Tokens per Sec: 13393.465820\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.923148 Tokens per Sec: 12573.080078\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.793896 Tokens per Sec: 12120.839844\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.979732 Tokens per Sec: 12276.407227\n",
      "\n",
      "Epoch Step: 2101 Loss: 2.339414 Tokens per Sec: 13505.493164\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.848416 Tokens per Sec: 13747.948242\n",
      "\n",
      "Epoch Step: 1 Loss: 1.285347 Tokens per Sec: 10664.577148\n",
      "\n",
      "tensor(1.6241, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.936666 Tokens per Sec: 2505.691650\n",
      "\n",
      "Epoch Step: 51 Loss: 1.417280 Tokens per Sec: 13948.056641\n",
      "\n",
      "Epoch Step: 101 Loss: 0.933116 Tokens per Sec: 13461.304688\n",
      "\n",
      "Epoch Step: 151 Loss: 2.012771 Tokens per Sec: 13592.620117\n",
      "\n",
      "Epoch Step: 201 Loss: 1.478811 Tokens per Sec: 13292.814453\n",
      "\n",
      "Epoch Step: 251 Loss: 2.030675 Tokens per Sec: 13469.920898\n",
      "\n",
      "Epoch Step: 301 Loss: 2.008642 Tokens per Sec: 13477.961914\n",
      "\n",
      "Epoch Step: 351 Loss: 1.889237 Tokens per Sec: 13365.390625\n",
      "\n",
      "Epoch Step: 401 Loss: 1.230150 Tokens per Sec: 13223.496094\n",
      "\n",
      "Epoch Step: 451 Loss: 1.821011 Tokens per Sec: 13127.092773\n",
      "\n",
      "Epoch Step: 501 Loss: 1.619800 Tokens per Sec: 13079.102539\n",
      "\n",
      "Epoch Step: 551 Loss: 2.099828 Tokens per Sec: 13132.058594\n",
      "\n",
      "Epoch Step: 601 Loss: 1.403556 Tokens per Sec: 12782.913086\n",
      "\n",
      "Epoch Step: 651 Loss: 2.186223 Tokens per Sec: 13354.859375\n",
      "\n",
      "Epoch Step: 701 Loss: 1.829337 Tokens per Sec: 13239.178711\n",
      "\n",
      "Epoch Step: 751 Loss: 1.746091 Tokens per Sec: 13199.071289\n",
      "\n",
      "Epoch Step: 801 Loss: 2.104256 Tokens per Sec: 13446.764648\n",
      "\n",
      "Epoch Step: 851 Loss: 1.783500 Tokens per Sec: 13039.860352\n",
      "\n",
      "Epoch Step: 901 Loss: 1.810685 Tokens per Sec: 13302.439453\n",
      "\n",
      "Epoch Step: 951 Loss: 1.377954 Tokens per Sec: 13291.000000\n",
      "\n",
      "Epoch Step: 1001 Loss: 2.079113 Tokens per Sec: 13321.963867\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.621607 Tokens per Sec: 13162.642578\n",
      "\n",
      "Epoch Step: 1101 Loss: 2.011828 Tokens per Sec: 13232.085938\n",
      "\n",
      "Epoch Step: 1151 Loss: 2.014546 Tokens per Sec: 13238.745117\n",
      "\n",
      "Epoch Step: 1201 Loss: 2.104145 Tokens per Sec: 13564.500000\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.346689 Tokens per Sec: 12915.181641\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.897900 Tokens per Sec: 12894.843750\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.847722 Tokens per Sec: 13139.625977\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.655679 Tokens per Sec: 13217.283203\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.666985 Tokens per Sec: 13547.663086\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.753609 Tokens per Sec: 13214.801758\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.930762 Tokens per Sec: 12444.739258\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.886066 Tokens per Sec: 12962.904297\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.537868 Tokens per Sec: 12610.520508\n",
      "\n",
      "Epoch Step: 1701 Loss: 2.273621 Tokens per Sec: 13106.907227\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.350421 Tokens per Sec: 13271.876953\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.843791 Tokens per Sec: 13208.331055\n",
      "\n",
      "Epoch Step: 1851 Loss: 2.170293 Tokens per Sec: 12906.101562\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.608223 Tokens per Sec: 12901.180664\n",
      "\n",
      "Epoch Step: 1951 Loss: 2.189892 Tokens per Sec: 13495.135742\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.811694 Tokens per Sec: 13091.065430\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.647674 Tokens per Sec: 13710.187500\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.562410 Tokens per Sec: 13130.313477\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.555468 Tokens per Sec: 12192.187500\n",
      "\n",
      "Epoch Step: 1 Loss: 1.259657 Tokens per Sec: 11045.278320\n",
      "\n",
      "tensor(1.5774, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 0.928921 Tokens per Sec: 2241.244629\n",
      "\n",
      "Epoch Step: 51 Loss: 2.088474 Tokens per Sec: 13404.527344\n",
      "\n",
      "Epoch Step: 101 Loss: 1.295767 Tokens per Sec: 13507.010742\n",
      "\n",
      "Epoch Step: 151 Loss: 1.934141 Tokens per Sec: 13721.374023\n",
      "\n",
      "Epoch Step: 201 Loss: 1.154476 Tokens per Sec: 13304.326172\n",
      "\n",
      "Epoch Step: 251 Loss: 2.104199 Tokens per Sec: 13882.128906\n",
      "\n",
      "Epoch Step: 301 Loss: 1.523499 Tokens per Sec: 13714.870117\n",
      "\n",
      "Epoch Step: 351 Loss: 2.295144 Tokens per Sec: 13748.136719\n",
      "\n",
      "Epoch Step: 401 Loss: 2.184906 Tokens per Sec: 13737.556641\n",
      "\n",
      "Epoch Step: 451 Loss: 1.978562 Tokens per Sec: 13421.444336\n",
      "\n",
      "Epoch Step: 501 Loss: 1.597223 Tokens per Sec: 13283.133789\n",
      "\n",
      "Epoch Step: 551 Loss: 1.091696 Tokens per Sec: 12976.083984\n",
      "\n",
      "Epoch Step: 601 Loss: 1.381427 Tokens per Sec: 13488.900391\n",
      "\n",
      "Epoch Step: 651 Loss: 2.021959 Tokens per Sec: 13050.226562\n",
      "\n",
      "Epoch Step: 701 Loss: 1.765002 Tokens per Sec: 12869.690430\n",
      "\n",
      "Epoch Step: 751 Loss: 2.485415 Tokens per Sec: 13066.983398\n",
      "\n",
      "Epoch Step: 801 Loss: 1.958322 Tokens per Sec: 13261.573242\n",
      "\n",
      "Epoch Step: 851 Loss: 1.891945 Tokens per Sec: 13075.336914\n",
      "\n",
      "Epoch Step: 901 Loss: 1.887471 Tokens per Sec: 13324.796875\n",
      "\n",
      "Epoch Step: 951 Loss: 1.644173 Tokens per Sec: 12958.476562\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.829880 Tokens per Sec: 13080.434570\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.647586 Tokens per Sec: 13627.948242\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.381384 Tokens per Sec: 13414.290039\n",
      "\n",
      "Epoch Step: 1151 Loss: 2.405534 Tokens per Sec: 13242.896484\n",
      "\n",
      "Epoch Step: 1201 Loss: 2.081883 Tokens per Sec: 13439.865234\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.396261 Tokens per Sec: 13360.340820\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.719306 Tokens per Sec: 12837.571289\n",
      "\n",
      "Epoch Step: 1351 Loss: 2.272694 Tokens per Sec: 13191.230469\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.321675 Tokens per Sec: 13232.928711\n",
      "\n",
      "Epoch Step: 1451 Loss: 2.237060 Tokens per Sec: 13428.294922\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.634173 Tokens per Sec: 13385.993164\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.518400 Tokens per Sec: 13128.000000\n",
      "\n",
      "Epoch Step: 1601 Loss: 2.396605 Tokens per Sec: 13240.449219\n",
      "\n",
      "Epoch Step: 1651 Loss: 2.328892 Tokens per Sec: 12976.131836\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.780290 Tokens per Sec: 13345.104492\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.157766 Tokens per Sec: 12961.038086\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.893094 Tokens per Sec: 13285.928711\n",
      "\n",
      "Epoch Step: 1851 Loss: 2.059361 Tokens per Sec: 13401.436523\n",
      "\n",
      "Epoch Step: 1901 Loss: 2.247119 Tokens per Sec: 12823.833984\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.260296 Tokens per Sec: 13205.408203\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.800610 Tokens per Sec: 12994.049805\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.943586 Tokens per Sec: 13274.510742\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.615701 Tokens per Sec: 13636.893555\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.631722 Tokens per Sec: 13388.276367\n",
      "\n",
      "Epoch Step: 1 Loss: 1.247661 Tokens per Sec: 11088.087891\n",
      "\n",
      "tensor(1.5375, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.921129 Tokens per Sec: 2646.829346\n",
      "\n",
      "Epoch Step: 51 Loss: 1.699557 Tokens per Sec: 13417.317383\n",
      "\n",
      "Epoch Step: 101 Loss: 0.952225 Tokens per Sec: 12968.334961\n",
      "\n",
      "Epoch Step: 151 Loss: 1.927778 Tokens per Sec: 13084.332031\n",
      "\n",
      "Epoch Step: 201 Loss: 1.742043 Tokens per Sec: 12758.630859\n",
      "\n",
      "Epoch Step: 251 Loss: 1.749206 Tokens per Sec: 12433.291992\n",
      "\n",
      "Epoch Step: 301 Loss: 1.661791 Tokens per Sec: 13015.656250\n",
      "\n",
      "Epoch Step: 351 Loss: 2.034775 Tokens per Sec: 13767.865234\n",
      "\n",
      "Epoch Step: 401 Loss: 1.559462 Tokens per Sec: 13826.285156\n",
      "\n",
      "Epoch Step: 451 Loss: 1.256935 Tokens per Sec: 13147.972656\n",
      "\n",
      "Epoch Step: 501 Loss: 1.613878 Tokens per Sec: 13666.041016\n",
      "\n",
      "Epoch Step: 551 Loss: 1.518263 Tokens per Sec: 12902.270508\n",
      "\n",
      "Epoch Step: 601 Loss: 1.671885 Tokens per Sec: 12697.925781\n",
      "\n",
      "Epoch Step: 651 Loss: 1.656617 Tokens per Sec: 13464.125977\n",
      "\n",
      "Epoch Step: 701 Loss: 1.757346 Tokens per Sec: 13501.642578\n",
      "\n",
      "Epoch Step: 751 Loss: 1.587672 Tokens per Sec: 13435.987305\n",
      "\n",
      "Epoch Step: 801 Loss: 2.002057 Tokens per Sec: 13256.102539\n",
      "\n",
      "Epoch Step: 851 Loss: 1.958427 Tokens per Sec: 13009.424805\n",
      "\n",
      "Epoch Step: 901 Loss: 1.883653 Tokens per Sec: 13202.423828\n",
      "\n",
      "Epoch Step: 951 Loss: 1.231386 Tokens per Sec: 13088.526367\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.768436 Tokens per Sec: 13486.670898\n",
      "\n",
      "Epoch Step: 1051 Loss: 2.045591 Tokens per Sec: 13416.102539\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.537361 Tokens per Sec: 13278.849609\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.994008 Tokens per Sec: 13015.804688\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.932451 Tokens per Sec: 13321.537109\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.878702 Tokens per Sec: 13127.442383\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.633033 Tokens per Sec: 13468.519531\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.844928 Tokens per Sec: 12823.087891\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.805767 Tokens per Sec: 12771.392578\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.932904 Tokens per Sec: 12909.962891\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.765688 Tokens per Sec: 13004.862305\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.580809 Tokens per Sec: 13279.754883\n",
      "\n",
      "Epoch Step: 1601 Loss: 2.223194 Tokens per Sec: 13054.433594\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.746159 Tokens per Sec: 13473.493164\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.230208 Tokens per Sec: 13208.729492\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.544825 Tokens per Sec: 13108.580078\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.971526 Tokens per Sec: 13294.343750\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.836917 Tokens per Sec: 13080.462891\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.844688 Tokens per Sec: 12979.199219\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.869114 Tokens per Sec: 13258.116211\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.430137 Tokens per Sec: 13188.626953\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.827074 Tokens per Sec: 13011.164062\n",
      "\n",
      "Epoch Step: 2101 Loss: 2.270263 Tokens per Sec: 12903.471680\n",
      "\n",
      "Epoch Step: 2151 Loss: 2.163826 Tokens per Sec: 13371.315430\n",
      "\n",
      "Epoch Step: 1 Loss: 1.184872 Tokens per Sec: 9797.467773\n",
      "\n",
      "tensor(1.4957, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.112006 Tokens per Sec: 2530.818359\n",
      "\n",
      "Epoch Step: 51 Loss: 1.658418 Tokens per Sec: 13140.959961\n",
      "\n",
      "Epoch Step: 101 Loss: 1.580507 Tokens per Sec: 13228.375977\n",
      "\n",
      "Epoch Step: 151 Loss: 1.571068 Tokens per Sec: 13360.623047\n",
      "\n",
      "Epoch Step: 201 Loss: 1.970906 Tokens per Sec: 13495.626953\n",
      "\n",
      "Epoch Step: 251 Loss: 1.523839 Tokens per Sec: 13536.206055\n",
      "\n",
      "Epoch Step: 301 Loss: 2.363436 Tokens per Sec: 13735.226562\n",
      "\n",
      "Epoch Step: 351 Loss: 1.608334 Tokens per Sec: 12744.129883\n",
      "\n",
      "Epoch Step: 401 Loss: 1.479350 Tokens per Sec: 12418.254883\n",
      "\n",
      "Epoch Step: 451 Loss: 1.912015 Tokens per Sec: 12702.727539\n",
      "\n",
      "Epoch Step: 501 Loss: 1.667078 Tokens per Sec: 13493.380859\n",
      "\n",
      "Epoch Step: 551 Loss: 1.578461 Tokens per Sec: 13367.983398\n",
      "\n",
      "Epoch Step: 601 Loss: 1.244793 Tokens per Sec: 13916.921875\n",
      "\n",
      "Epoch Step: 651 Loss: 1.794464 Tokens per Sec: 13270.549805\n",
      "\n",
      "Epoch Step: 701 Loss: 1.772357 Tokens per Sec: 13705.941406\n",
      "\n",
      "Epoch Step: 751 Loss: 1.567503 Tokens per Sec: 13517.969727\n",
      "\n",
      "Epoch Step: 801 Loss: 1.633450 Tokens per Sec: 13472.307617\n",
      "\n",
      "Epoch Step: 851 Loss: 1.439661 Tokens per Sec: 13824.609375\n",
      "\n",
      "Epoch Step: 901 Loss: 1.989287 Tokens per Sec: 13224.396484\n",
      "\n",
      "Epoch Step: 951 Loss: 1.920867 Tokens per Sec: 13015.593750\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.651343 Tokens per Sec: 12799.099609\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.664902 Tokens per Sec: 13000.076172\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.913979 Tokens per Sec: 13364.662109\n",
      "\n",
      "Epoch Step: 1151 Loss: 2.192292 Tokens per Sec: 13266.373047\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.363240 Tokens per Sec: 12960.488281\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.894124 Tokens per Sec: 13113.035156\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.958540 Tokens per Sec: 13203.126953\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.586891 Tokens per Sec: 13084.980469\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.945896 Tokens per Sec: 13502.365234\n",
      "\n",
      "Epoch Step: 1451 Loss: 2.418730 Tokens per Sec: 12998.794922\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.365293 Tokens per Sec: 12985.445312\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.621327 Tokens per Sec: 13475.382812\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.826441 Tokens per Sec: 13393.386719\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.598628 Tokens per Sec: 13386.855469\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.769007 Tokens per Sec: 13113.132812\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.530903 Tokens per Sec: 13245.893555\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.870580 Tokens per Sec: 13145.950195\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.793989 Tokens per Sec: 13238.164062\n",
      "\n",
      "Epoch Step: 1901 Loss: 2.262118 Tokens per Sec: 13404.935547\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.893771 Tokens per Sec: 13394.198242\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.220927 Tokens per Sec: 12890.454102\n",
      "\n",
      "Epoch Step: 2051 Loss: 2.142909 Tokens per Sec: 13210.550781\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.910842 Tokens per Sec: 13538.486328\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.609649 Tokens per Sec: 13276.284180\n",
      "\n",
      "Epoch Step: 1 Loss: 1.161348 Tokens per Sec: 11591.359375\n",
      "\n",
      "tensor(1.4542, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.036543 Tokens per Sec: 2542.250488\n",
      "\n",
      "Epoch Step: 51 Loss: 1.689216 Tokens per Sec: 13238.937500\n",
      "\n",
      "Epoch Step: 101 Loss: 2.035177 Tokens per Sec: 13351.775391\n",
      "\n",
      "Epoch Step: 151 Loss: 1.485870 Tokens per Sec: 13241.947266\n",
      "\n",
      "Epoch Step: 201 Loss: 1.856801 Tokens per Sec: 13187.725586\n",
      "\n",
      "Epoch Step: 251 Loss: 1.330946 Tokens per Sec: 13293.535156\n",
      "\n",
      "Epoch Step: 301 Loss: 1.602613 Tokens per Sec: 13161.791016\n",
      "\n",
      "Epoch Step: 351 Loss: 1.404587 Tokens per Sec: 13329.552734\n",
      "\n",
      "Epoch Step: 401 Loss: 1.550395 Tokens per Sec: 13562.674805\n",
      "\n",
      "Epoch Step: 451 Loss: 1.733887 Tokens per Sec: 13509.844727\n",
      "\n",
      "Epoch Step: 501 Loss: 1.674614 Tokens per Sec: 13192.847656\n",
      "\n",
      "Epoch Step: 551 Loss: 2.100888 Tokens per Sec: 12692.916992\n",
      "\n",
      "Epoch Step: 601 Loss: 1.693560 Tokens per Sec: 12083.011719\n",
      "\n",
      "Epoch Step: 651 Loss: 1.528421 Tokens per Sec: 12980.545898\n",
      "\n",
      "Epoch Step: 701 Loss: 1.727681 Tokens per Sec: 13193.769531\n",
      "\n",
      "Epoch Step: 751 Loss: 1.698888 Tokens per Sec: 12896.982422\n",
      "\n",
      "Epoch Step: 801 Loss: 2.018656 Tokens per Sec: 13496.648438\n",
      "\n",
      "Epoch Step: 851 Loss: 1.735509 Tokens per Sec: 13722.625977\n",
      "\n",
      "Epoch Step: 901 Loss: 1.668858 Tokens per Sec: 12978.946289\n",
      "\n",
      "Epoch Step: 951 Loss: 1.358954 Tokens per Sec: 13473.850586\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.926329 Tokens per Sec: 12994.786133\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.665524 Tokens per Sec: 13361.300781\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.899946 Tokens per Sec: 13519.788086\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.421869 Tokens per Sec: 13295.055664\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.689240 Tokens per Sec: 13114.877930\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.809292 Tokens per Sec: 13468.367188\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.739096 Tokens per Sec: 13195.072266\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.637968 Tokens per Sec: 13005.330078\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.518289 Tokens per Sec: 13230.735352\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.851096 Tokens per Sec: 12973.719727\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.821451 Tokens per Sec: 13040.099609\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.722983 Tokens per Sec: 13321.819336\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.564458 Tokens per Sec: 13173.410156\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.932413 Tokens per Sec: 13011.053711\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.559273 Tokens per Sec: 13108.548828\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.930943 Tokens per Sec: 13008.245117\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.629899 Tokens per Sec: 13367.082031\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.757109 Tokens per Sec: 12780.969727\n",
      "\n",
      "Epoch Step: 1901 Loss: 2.261998 Tokens per Sec: 13413.130859\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.335048 Tokens per Sec: 13066.330078\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.402451 Tokens per Sec: 13550.532227\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.618698 Tokens per Sec: 13443.737305\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.509276 Tokens per Sec: 12982.740234\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.680341 Tokens per Sec: 13506.083984\n",
      "\n",
      "Epoch Step: 1 Loss: 1.160469 Tokens per Sec: 10466.222656\n",
      "\n",
      "tensor(1.4188, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 2.072500 Tokens per Sec: 2846.582031\n",
      "\n",
      "Epoch Step: 51 Loss: 1.615901 Tokens per Sec: 13393.680664\n",
      "\n",
      "Epoch Step: 101 Loss: 1.492617 Tokens per Sec: 12953.896484\n",
      "\n",
      "Epoch Step: 151 Loss: 2.074420 Tokens per Sec: 12840.936523\n",
      "\n",
      "Epoch Step: 201 Loss: 1.433749 Tokens per Sec: 13489.787109\n",
      "\n",
      "Epoch Step: 251 Loss: 2.041933 Tokens per Sec: 13382.704102\n",
      "\n",
      "Epoch Step: 301 Loss: 1.855732 Tokens per Sec: 13378.054688\n",
      "\n",
      "Epoch Step: 351 Loss: 0.928989 Tokens per Sec: 13466.774414\n",
      "\n",
      "Epoch Step: 401 Loss: 1.382509 Tokens per Sec: 13166.562500\n",
      "\n",
      "Epoch Step: 451 Loss: 1.640550 Tokens per Sec: 13021.334961\n",
      "\n",
      "Epoch Step: 501 Loss: 1.389189 Tokens per Sec: 12866.462891\n",
      "\n",
      "Epoch Step: 551 Loss: 1.684500 Tokens per Sec: 12841.343750\n",
      "\n",
      "Epoch Step: 601 Loss: 1.927664 Tokens per Sec: 13101.048828\n",
      "\n",
      "Epoch Step: 651 Loss: 1.509925 Tokens per Sec: 13603.719727\n",
      "\n",
      "Epoch Step: 701 Loss: 1.367411 Tokens per Sec: 12982.750977\n",
      "\n",
      "Epoch Step: 751 Loss: 1.539128 Tokens per Sec: 12645.474609\n",
      "\n",
      "Epoch Step: 801 Loss: 1.780157 Tokens per Sec: 12270.988281\n",
      "\n",
      "Epoch Step: 851 Loss: 1.607923 Tokens per Sec: 13429.440430\n",
      "\n",
      "Epoch Step: 901 Loss: 1.507984 Tokens per Sec: 13933.214844\n",
      "\n",
      "Epoch Step: 951 Loss: 1.448170 Tokens per Sec: 13797.594727\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.501182 Tokens per Sec: 13432.209961\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.169743 Tokens per Sec: 13995.575195\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.399466 Tokens per Sec: 13859.359375\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.556162 Tokens per Sec: 13793.634766\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.562201 Tokens per Sec: 13359.367188\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.997385 Tokens per Sec: 13403.421875\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.626689 Tokens per Sec: 12988.292969\n",
      "\n",
      "Epoch Step: 1351 Loss: 2.133464 Tokens per Sec: 12968.823242\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.360786 Tokens per Sec: 13198.313477\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.568741 Tokens per Sec: 13543.730469\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.703255 Tokens per Sec: 13308.541992\n",
      "\n",
      "Epoch Step: 1551 Loss: 2.072977 Tokens per Sec: 13323.965820\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.522734 Tokens per Sec: 12842.412109\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.630675 Tokens per Sec: 13260.141602\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.563987 Tokens per Sec: 13209.945312\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.851308 Tokens per Sec: 12986.918945\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.225383 Tokens per Sec: 13393.375000\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.714653 Tokens per Sec: 13001.558594\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.912497 Tokens per Sec: 13370.077148\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.604964 Tokens per Sec: 13223.328125\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.980109 Tokens per Sec: 12929.505859\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.870148 Tokens per Sec: 13115.447266\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.970000 Tokens per Sec: 13328.407227\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.402271 Tokens per Sec: 13256.218750\n",
      "\n",
      "Epoch Step: 1 Loss: 1.124323 Tokens per Sec: 11358.179688\n",
      "\n",
      "tensor(1.3836, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.940835 Tokens per Sec: 2799.550293\n",
      "\n",
      "Epoch Step: 51 Loss: 1.772145 Tokens per Sec: 13652.743164\n",
      "\n",
      "Epoch Step: 101 Loss: 1.719089 Tokens per Sec: 13211.227539\n",
      "\n",
      "Epoch Step: 151 Loss: 1.315635 Tokens per Sec: 12915.000000\n",
      "\n",
      "Epoch Step: 201 Loss: 1.590309 Tokens per Sec: 13030.896484\n",
      "\n",
      "Epoch Step: 251 Loss: 1.348485 Tokens per Sec: 13213.403320\n",
      "\n",
      "Epoch Step: 301 Loss: 1.291722 Tokens per Sec: 13142.485352\n",
      "\n",
      "Epoch Step: 351 Loss: 1.505623 Tokens per Sec: 13275.781250\n",
      "\n",
      "Epoch Step: 401 Loss: 1.458657 Tokens per Sec: 13364.056641\n",
      "\n",
      "Epoch Step: 451 Loss: 1.786318 Tokens per Sec: 13109.205078\n",
      "\n",
      "Epoch Step: 501 Loss: 2.239583 Tokens per Sec: 13363.722656\n",
      "\n",
      "Epoch Step: 551 Loss: 1.720710 Tokens per Sec: 13060.414062\n",
      "\n",
      "Epoch Step: 601 Loss: 1.230812 Tokens per Sec: 13309.863281\n",
      "\n",
      "Epoch Step: 651 Loss: 1.181734 Tokens per Sec: 13061.082031\n",
      "\n",
      "Epoch Step: 701 Loss: 1.355148 Tokens per Sec: 13342.582031\n",
      "\n",
      "Epoch Step: 751 Loss: 1.418404 Tokens per Sec: 13223.329102\n",
      "\n",
      "Epoch Step: 801 Loss: 1.463694 Tokens per Sec: 13205.556641\n",
      "\n",
      "Epoch Step: 851 Loss: 1.780692 Tokens per Sec: 13340.374023\n",
      "\n",
      "Epoch Step: 901 Loss: 1.949855 Tokens per Sec: 12652.960938\n",
      "\n",
      "Epoch Step: 951 Loss: 1.738336 Tokens per Sec: 12323.952148\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.308669 Tokens per Sec: 12453.428711\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.975061 Tokens per Sec: 13911.785156\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.792073 Tokens per Sec: 13615.710938\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.666492 Tokens per Sec: 13950.224609\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.420735 Tokens per Sec: 13906.519531\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.688072 Tokens per Sec: 13765.788086\n",
      "\n",
      "Epoch Step: 1301 Loss: 2.061185 Tokens per Sec: 13805.587891\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.295430 Tokens per Sec: 13426.382812\n",
      "\n",
      "Epoch Step: 1401 Loss: 2.149808 Tokens per Sec: 13155.335938\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.652200 Tokens per Sec: 13420.382812\n",
      "\n",
      "Epoch Step: 1501 Loss: 2.114188 Tokens per Sec: 13086.909180\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.398671 Tokens per Sec: 12899.978516\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.863467 Tokens per Sec: 13626.161133\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.510206 Tokens per Sec: 13324.613281\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.265189 Tokens per Sec: 13253.967773\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.282373 Tokens per Sec: 13052.482422\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.783957 Tokens per Sec: 12711.043945\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.838377 Tokens per Sec: 13603.671875\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.686094 Tokens per Sec: 13625.592773\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.845318 Tokens per Sec: 13035.943359\n",
      "\n",
      "Epoch Step: 2001 Loss: 2.122816 Tokens per Sec: 13494.164062\n",
      "\n",
      "Epoch Step: 2051 Loss: 2.006694 Tokens per Sec: 12973.026367\n",
      "\n",
      "Epoch Step: 2101 Loss: 2.088247 Tokens per Sec: 13107.489258\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.944469 Tokens per Sec: 13284.636719\n",
      "\n",
      "Epoch Step: 1 Loss: 1.103705 Tokens per Sec: 10990.375977\n",
      "\n",
      "tensor(1.3480, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.738546 Tokens per Sec: 2453.485840\n",
      "\n",
      "Epoch Step: 51 Loss: 0.930283 Tokens per Sec: 13204.478516\n",
      "\n",
      "Epoch Step: 101 Loss: 1.546653 Tokens per Sec: 13362.853516\n",
      "\n",
      "Epoch Step: 151 Loss: 1.600143 Tokens per Sec: 13406.784180\n",
      "\n",
      "Epoch Step: 201 Loss: 1.685016 Tokens per Sec: 13405.214844\n",
      "\n",
      "Epoch Step: 251 Loss: 1.557466 Tokens per Sec: 13059.204102\n",
      "\n",
      "Epoch Step: 301 Loss: 1.716172 Tokens per Sec: 12956.352539\n",
      "\n",
      "Epoch Step: 351 Loss: 1.774682 Tokens per Sec: 13078.134766\n",
      "\n",
      "Epoch Step: 401 Loss: 0.874308 Tokens per Sec: 13100.662109\n",
      "\n",
      "Epoch Step: 451 Loss: 1.486225 Tokens per Sec: 13146.279297\n",
      "\n",
      "Epoch Step: 501 Loss: 1.478668 Tokens per Sec: 13070.026367\n",
      "\n",
      "Epoch Step: 551 Loss: 1.690599 Tokens per Sec: 13293.083008\n",
      "\n",
      "Epoch Step: 601 Loss: 1.378068 Tokens per Sec: 13158.984375\n",
      "\n",
      "Epoch Step: 651 Loss: 1.740764 Tokens per Sec: 13474.408203\n",
      "\n",
      "Epoch Step: 701 Loss: 1.529891 Tokens per Sec: 13541.715820\n",
      "\n",
      "Epoch Step: 751 Loss: 1.496277 Tokens per Sec: 13474.757812\n",
      "\n",
      "Epoch Step: 801 Loss: 2.203063 Tokens per Sec: 13181.649414\n",
      "\n",
      "Epoch Step: 851 Loss: 1.591520 Tokens per Sec: 13028.063477\n",
      "\n",
      "Epoch Step: 901 Loss: 1.392033 Tokens per Sec: 13257.640625\n",
      "\n",
      "Epoch Step: 951 Loss: 1.261721 Tokens per Sec: 13550.121094\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.850671 Tokens per Sec: 12867.091797\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.662722 Tokens per Sec: 12542.744141\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.499410 Tokens per Sec: 12370.269531\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.607053 Tokens per Sec: 12658.151367\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.554852 Tokens per Sec: 13016.192383\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.949759 Tokens per Sec: 13524.266602\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.603582 Tokens per Sec: 13179.519531\n",
      "\n",
      "Epoch Step: 1351 Loss: 2.123883 Tokens per Sec: 12541.666992\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.720223 Tokens per Sec: 13715.554688\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.733946 Tokens per Sec: 13779.673828\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.475150 Tokens per Sec: 13454.078125\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.751289 Tokens per Sec: 13172.667969\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.253485 Tokens per Sec: 13163.496094\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.573878 Tokens per Sec: 13149.481445\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.506037 Tokens per Sec: 13357.510742\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.174289 Tokens per Sec: 13088.912109\n",
      "\n",
      "Epoch Step: 1801 Loss: 2.256757 Tokens per Sec: 13004.923828\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.691975 Tokens per Sec: 13070.723633\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.789233 Tokens per Sec: 13353.571289\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.797827 Tokens per Sec: 13206.211914\n",
      "\n",
      "Epoch Step: 2001 Loss: 2.041357 Tokens per Sec: 12919.136719\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.731284 Tokens per Sec: 13274.206055\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.970855 Tokens per Sec: 13497.268555\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.367287 Tokens per Sec: 13212.036133\n",
      "\n",
      "Epoch Step: 1 Loss: 1.067105 Tokens per Sec: 11285.808594\n",
      "\n",
      "tensor(1.3256, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.431102 Tokens per Sec: 2733.322266\n",
      "\n",
      "Epoch Step: 51 Loss: 1.654399 Tokens per Sec: 13056.851562\n",
      "\n",
      "Epoch Step: 101 Loss: 1.805198 Tokens per Sec: 13278.041992\n",
      "\n",
      "Epoch Step: 151 Loss: 1.493170 Tokens per Sec: 13072.893555\n",
      "\n",
      "Epoch Step: 201 Loss: 1.758627 Tokens per Sec: 13067.226562\n",
      "\n",
      "Epoch Step: 251 Loss: 1.759149 Tokens per Sec: 12830.363281\n",
      "\n",
      "Epoch Step: 301 Loss: 1.503841 Tokens per Sec: 13041.030273\n",
      "\n",
      "Epoch Step: 351 Loss: 1.497504 Tokens per Sec: 13256.006836\n",
      "\n",
      "Epoch Step: 401 Loss: 1.414811 Tokens per Sec: 13053.590820\n",
      "\n",
      "Epoch Step: 451 Loss: 1.473106 Tokens per Sec: 13621.328125\n",
      "\n",
      "Epoch Step: 501 Loss: 1.750220 Tokens per Sec: 13602.368164\n",
      "\n",
      "Epoch Step: 551 Loss: 1.540718 Tokens per Sec: 13424.190430\n",
      "\n",
      "Epoch Step: 601 Loss: 1.496449 Tokens per Sec: 13706.980469\n",
      "\n",
      "Epoch Step: 651 Loss: 1.664360 Tokens per Sec: 13412.755859\n",
      "\n",
      "Epoch Step: 701 Loss: 1.939591 Tokens per Sec: 13340.323242\n",
      "\n",
      "Epoch Step: 751 Loss: 1.086731 Tokens per Sec: 13553.037109\n",
      "\n",
      "Epoch Step: 801 Loss: 1.676323 Tokens per Sec: 13466.583008\n",
      "\n",
      "Epoch Step: 851 Loss: 2.078498 Tokens per Sec: 13455.549805\n",
      "\n",
      "Epoch Step: 901 Loss: 1.806395 Tokens per Sec: 13704.631836\n",
      "\n",
      "Epoch Step: 951 Loss: 2.136055 Tokens per Sec: 13074.137695\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.785603 Tokens per Sec: 12967.384766\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.587991 Tokens per Sec: 12901.038086\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.308325 Tokens per Sec: 13027.312500\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.828589 Tokens per Sec: 13363.166016\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.553417 Tokens per Sec: 13309.423828\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.463012 Tokens per Sec: 12552.482422\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.728233 Tokens per Sec: 12536.655273\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.018187 Tokens per Sec: 12678.893555\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.958519 Tokens per Sec: 12861.828125\n",
      "\n",
      "Epoch Step: 1451 Loss: 2.235636 Tokens per Sec: 13223.395508\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.577358 Tokens per Sec: 13527.016602\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.676307 Tokens per Sec: 14154.651367\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.396635 Tokens per Sec: 13693.485352\n",
      "\n",
      "Epoch Step: 1651 Loss: 2.201306 Tokens per Sec: 13737.173828\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.675241 Tokens per Sec: 13724.354492\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.606700 Tokens per Sec: 13384.482422\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.380263 Tokens per Sec: 13549.106445\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.517332 Tokens per Sec: 13434.105469\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.304469 Tokens per Sec: 13335.739258\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.660488 Tokens per Sec: 13326.260742\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.651409 Tokens per Sec: 13079.580078\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.490826 Tokens per Sec: 13062.459961\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.874071 Tokens per Sec: 12770.342773\n",
      "\n",
      "Epoch Step: 2151 Loss: 2.088223 Tokens per Sec: 13200.830078\n",
      "\n",
      "Epoch Step: 1 Loss: 1.056220 Tokens per Sec: 10420.735352\n",
      "\n",
      "tensor(1.2973, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.460601 Tokens per Sec: 2421.721436\n",
      "\n",
      "Epoch Step: 51 Loss: 1.485267 Tokens per Sec: 13306.498047\n",
      "\n",
      "Epoch Step: 101 Loss: 1.589023 Tokens per Sec: 13747.405273\n",
      "\n",
      "Epoch Step: 151 Loss: 1.456718 Tokens per Sec: 12974.673828\n",
      "\n",
      "Epoch Step: 201 Loss: 1.913337 Tokens per Sec: 13221.304688\n",
      "\n",
      "Epoch Step: 251 Loss: 1.322944 Tokens per Sec: 12534.918945\n",
      "\n",
      "Epoch Step: 301 Loss: 1.172709 Tokens per Sec: 13165.989258\n",
      "\n",
      "Epoch Step: 351 Loss: 1.902678 Tokens per Sec: 13190.515625\n",
      "\n",
      "Epoch Step: 401 Loss: 1.661042 Tokens per Sec: 13160.821289\n",
      "\n",
      "Epoch Step: 451 Loss: 1.322174 Tokens per Sec: 13058.270508\n",
      "\n",
      "Epoch Step: 501 Loss: 1.492430 Tokens per Sec: 13069.314453\n",
      "\n",
      "Epoch Step: 551 Loss: 1.649772 Tokens per Sec: 13389.641602\n",
      "\n",
      "Epoch Step: 601 Loss: 1.468900 Tokens per Sec: 13478.497070\n",
      "\n",
      "Epoch Step: 651 Loss: 2.174499 Tokens per Sec: 13374.817383\n",
      "\n",
      "Epoch Step: 701 Loss: 1.848566 Tokens per Sec: 13624.243164\n",
      "\n",
      "Epoch Step: 751 Loss: 1.602203 Tokens per Sec: 13074.083984\n",
      "\n",
      "Epoch Step: 801 Loss: 1.733254 Tokens per Sec: 13128.279297\n",
      "\n",
      "Epoch Step: 851 Loss: 1.618280 Tokens per Sec: 13589.547852\n",
      "\n",
      "Epoch Step: 901 Loss: 2.076001 Tokens per Sec: 13472.649414\n",
      "\n",
      "Epoch Step: 951 Loss: 1.277999 Tokens per Sec: 13211.604492\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.034084 Tokens per Sec: 13152.338867\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.966193 Tokens per Sec: 12808.614258\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.764289 Tokens per Sec: 13267.957031\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.741884 Tokens per Sec: 13352.506836\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.356740 Tokens per Sec: 13162.125000\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.420756 Tokens per Sec: 12967.004883\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.354174 Tokens per Sec: 13537.770508\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.639017 Tokens per Sec: 13647.311523\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.160777 Tokens per Sec: 12948.627930\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.960540 Tokens per Sec: 12327.621094\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.742630 Tokens per Sec: 12486.974609\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.746801 Tokens per Sec: 13400.798828\n",
      "\n",
      "Epoch Step: 1601 Loss: 2.257699 Tokens per Sec: 13882.967773\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.566275 Tokens per Sec: 13763.339844\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.855816 Tokens per Sec: 13857.405273\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.638900 Tokens per Sec: 13328.934570\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.566156 Tokens per Sec: 13533.332031\n",
      "\n",
      "Epoch Step: 1851 Loss: 2.120298 Tokens per Sec: 13823.526367\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.601302 Tokens per Sec: 13441.902344\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.581876 Tokens per Sec: 13333.875000\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.676800 Tokens per Sec: 13497.406250\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.710144 Tokens per Sec: 13288.452148\n",
      "\n",
      "Epoch Step: 2101 Loss: 2.035061 Tokens per Sec: 13245.973633\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.940408 Tokens per Sec: 13447.407227\n",
      "\n",
      "Epoch Step: 1 Loss: 1.030241 Tokens per Sec: 10627.467773\n",
      "\n",
      "tensor(1.2662, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.347047 Tokens per Sec: 2755.658447\n",
      "\n",
      "Epoch Step: 51 Loss: 1.422676 Tokens per Sec: 13549.303711\n",
      "\n",
      "Epoch Step: 101 Loss: 1.478121 Tokens per Sec: 13208.209961\n",
      "\n",
      "Epoch Step: 151 Loss: 2.176360 Tokens per Sec: 13470.365234\n",
      "\n",
      "Epoch Step: 201 Loss: 1.529659 Tokens per Sec: 13425.725586\n",
      "\n",
      "Epoch Step: 251 Loss: 1.650061 Tokens per Sec: 13036.022461\n",
      "\n",
      "Epoch Step: 301 Loss: 1.347905 Tokens per Sec: 13091.940430\n",
      "\n",
      "Epoch Step: 351 Loss: 1.527436 Tokens per Sec: 13371.596680\n",
      "\n",
      "Epoch Step: 401 Loss: 1.496047 Tokens per Sec: 13283.404297\n",
      "\n",
      "Epoch Step: 451 Loss: 1.800554 Tokens per Sec: 13454.653320\n",
      "\n",
      "Epoch Step: 501 Loss: 1.132245 Tokens per Sec: 13168.874023\n",
      "\n",
      "Epoch Step: 551 Loss: 1.559759 Tokens per Sec: 13194.461914\n",
      "\n",
      "Epoch Step: 601 Loss: 1.341204 Tokens per Sec: 13282.966797\n",
      "\n",
      "Epoch Step: 651 Loss: 1.536516 Tokens per Sec: 13048.029297\n",
      "\n",
      "Epoch Step: 701 Loss: 1.817790 Tokens per Sec: 12982.733398\n",
      "\n",
      "Epoch Step: 751 Loss: 1.763096 Tokens per Sec: 13156.350586\n",
      "\n",
      "Epoch Step: 801 Loss: 1.772947 Tokens per Sec: 13457.426758\n",
      "\n",
      "Epoch Step: 851 Loss: 1.577542 Tokens per Sec: 13055.622070\n",
      "\n",
      "Epoch Step: 901 Loss: 1.600433 Tokens per Sec: 12664.166992\n",
      "\n",
      "Epoch Step: 951 Loss: 1.451572 Tokens per Sec: 13461.427734\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.465288 Tokens per Sec: 13438.608398\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.334986 Tokens per Sec: 13072.400391\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.429036 Tokens per Sec: 13223.230469\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.509458 Tokens per Sec: 13451.974609\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.679096 Tokens per Sec: 13210.517578\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.319994 Tokens per Sec: 13328.371094\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.766414 Tokens per Sec: 13075.358398\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.207336 Tokens per Sec: 13126.748047\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.764329 Tokens per Sec: 12877.783203\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.055583 Tokens per Sec: 13364.708984\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.407908 Tokens per Sec: 13648.892578\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.815079 Tokens per Sec: 13937.619141\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.772765 Tokens per Sec: 12319.624023\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.473022 Tokens per Sec: 12458.425781\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.893628 Tokens per Sec: 12395.937500\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.695477 Tokens per Sec: 13669.140625\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.734708 Tokens per Sec: 13262.333984\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.948725 Tokens per Sec: 12951.203125\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.408565 Tokens per Sec: 13257.158203\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.686463 Tokens per Sec: 13646.177734\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.564209 Tokens per Sec: 13631.313477\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.432175 Tokens per Sec: 13859.267578\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.709781 Tokens per Sec: 13165.335938\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.742811 Tokens per Sec: 13268.715820\n",
      "\n",
      "Epoch Step: 1 Loss: 1.007580 Tokens per Sec: 11695.721680\n",
      "\n",
      "tensor(1.2361, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.708158 Tokens per Sec: 2374.734863\n",
      "\n",
      "Epoch Step: 51 Loss: 1.717431 Tokens per Sec: 13034.859375\n",
      "\n",
      "Epoch Step: 101 Loss: 1.473774 Tokens per Sec: 13343.026367\n",
      "\n",
      "Epoch Step: 151 Loss: 1.885806 Tokens per Sec: 12991.838867\n",
      "\n",
      "Epoch Step: 201 Loss: 1.530756 Tokens per Sec: 13193.997070\n",
      "\n",
      "Epoch Step: 251 Loss: 1.732701 Tokens per Sec: 13645.406250\n",
      "\n",
      "Epoch Step: 301 Loss: 1.541618 Tokens per Sec: 12997.529297\n",
      "\n",
      "Epoch Step: 351 Loss: 1.295596 Tokens per Sec: 13019.221680\n",
      "\n",
      "Epoch Step: 401 Loss: 1.602069 Tokens per Sec: 13008.702148\n",
      "\n",
      "Epoch Step: 451 Loss: 1.215973 Tokens per Sec: 13181.552734\n",
      "\n",
      "Epoch Step: 501 Loss: 1.295437 Tokens per Sec: 13013.185547\n",
      "\n",
      "Epoch Step: 551 Loss: 1.742548 Tokens per Sec: 13012.140625\n",
      "\n",
      "Epoch Step: 601 Loss: 1.493240 Tokens per Sec: 13085.445312\n",
      "\n",
      "Epoch Step: 651 Loss: 1.440679 Tokens per Sec: 13382.930664\n",
      "\n",
      "Epoch Step: 701 Loss: 1.617474 Tokens per Sec: 13304.791016\n",
      "\n",
      "Epoch Step: 751 Loss: 1.719152 Tokens per Sec: 13279.298828\n",
      "\n",
      "Epoch Step: 801 Loss: 1.806110 Tokens per Sec: 13279.136719\n",
      "\n",
      "Epoch Step: 851 Loss: 1.654390 Tokens per Sec: 13435.884766\n",
      "\n",
      "Epoch Step: 901 Loss: 1.774144 Tokens per Sec: 13182.099609\n",
      "\n",
      "Epoch Step: 951 Loss: 1.509093 Tokens per Sec: 13160.166992\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.571515 Tokens per Sec: 12899.475586\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.648306 Tokens per Sec: 13398.735352\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.523786 Tokens per Sec: 12915.118164\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.513014 Tokens per Sec: 13192.234375\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.517189 Tokens per Sec: 13489.563477\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.424810 Tokens per Sec: 13239.556641\n",
      "\n",
      "Epoch Step: 1301 Loss: 2.036357 Tokens per Sec: 13144.958984\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.554317 Tokens per Sec: 13057.321289\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.362679 Tokens per Sec: 13401.147461\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.503764 Tokens per Sec: 13387.715820\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.340222 Tokens per Sec: 12807.957031\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.510160 Tokens per Sec: 13205.320312\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.501569 Tokens per Sec: 13360.990234\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.555034 Tokens per Sec: 13338.706055\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.592554 Tokens per Sec: 13886.013672\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.090343 Tokens per Sec: 13194.034180\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.502486 Tokens per Sec: 12690.589844\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.753888 Tokens per Sec: 12200.020508\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.125851 Tokens per Sec: 12972.878906\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.959597 Tokens per Sec: 13551.683594\n",
      "\n",
      "Epoch Step: 2001 Loss: 2.091659 Tokens per Sec: 13725.619141\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.747275 Tokens per Sec: 13619.357422\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.625225 Tokens per Sec: 13820.801758\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.784653 Tokens per Sec: 13730.446289\n",
      "\n",
      "Epoch Step: 1 Loss: 0.974729 Tokens per Sec: 11369.934570\n",
      "\n",
      "tensor(1.2005, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.443379 Tokens per Sec: 2669.575928\n",
      "\n",
      "Epoch Step: 51 Loss: 1.678110 Tokens per Sec: 13380.256836\n",
      "\n",
      "Epoch Step: 101 Loss: 1.478386 Tokens per Sec: 12991.019531\n",
      "\n",
      "Epoch Step: 151 Loss: 1.764027 Tokens per Sec: 13282.457031\n",
      "\n",
      "Epoch Step: 201 Loss: 1.670277 Tokens per Sec: 13158.338867\n",
      "\n",
      "Epoch Step: 251 Loss: 1.940971 Tokens per Sec: 12924.034180\n",
      "\n",
      "Epoch Step: 301 Loss: 1.686482 Tokens per Sec: 13351.538086\n",
      "\n",
      "Epoch Step: 351 Loss: 1.284628 Tokens per Sec: 13229.435547\n",
      "\n",
      "Epoch Step: 401 Loss: 1.648910 Tokens per Sec: 12803.444336\n",
      "\n",
      "Epoch Step: 451 Loss: 1.780563 Tokens per Sec: 12738.409180\n",
      "\n",
      "Epoch Step: 501 Loss: 1.603938 Tokens per Sec: 13243.924805\n",
      "\n",
      "Epoch Step: 551 Loss: 1.214712 Tokens per Sec: 13055.801758\n",
      "\n",
      "Epoch Step: 601 Loss: 1.846482 Tokens per Sec: 13105.663086\n",
      "\n",
      "Epoch Step: 651 Loss: 2.115604 Tokens per Sec: 13081.820312\n",
      "\n",
      "Epoch Step: 701 Loss: 1.713336 Tokens per Sec: 13283.011719\n",
      "\n",
      "Epoch Step: 751 Loss: 1.059689 Tokens per Sec: 12962.028320\n",
      "\n",
      "Epoch Step: 801 Loss: 1.272369 Tokens per Sec: 13309.170898\n",
      "\n",
      "Epoch Step: 851 Loss: 1.559964 Tokens per Sec: 13329.590820\n",
      "\n",
      "Epoch Step: 901 Loss: 1.643291 Tokens per Sec: 13527.635742\n",
      "\n",
      "Epoch Step: 951 Loss: 1.778463 Tokens per Sec: 13532.996094\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.517215 Tokens per Sec: 13371.719727\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.424341 Tokens per Sec: 12631.953125\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.341605 Tokens per Sec: 13293.957031\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.152232 Tokens per Sec: 13046.866211\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.441323 Tokens per Sec: 13081.923828\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.822655 Tokens per Sec: 12902.658203\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.618855 Tokens per Sec: 13236.542969\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.605089 Tokens per Sec: 13425.007812\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.727177 Tokens per Sec: 13238.052734\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.610204 Tokens per Sec: 13201.456055\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.775585 Tokens per Sec: 13728.825195\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.438985 Tokens per Sec: 13296.471680\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.403573 Tokens per Sec: 13226.932617\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.670306 Tokens per Sec: 13234.000000\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.643074 Tokens per Sec: 12943.085938\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.707391 Tokens per Sec: 13448.612305\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.713553 Tokens per Sec: 13368.857422\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.349473 Tokens per Sec: 13295.493164\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.361223 Tokens per Sec: 13487.282227\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.339620 Tokens per Sec: 13050.519531\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.622518 Tokens per Sec: 12140.655273\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.593902 Tokens per Sec: 12451.548828\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.600670 Tokens per Sec: 12930.166016\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.554827 Tokens per Sec: 12929.280273\n",
      "\n",
      "Epoch Step: 1 Loss: 0.964964 Tokens per Sec: 11529.890625\n",
      "\n",
      "tensor(1.1805, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.316680 Tokens per Sec: 2391.887207\n",
      "\n",
      "Epoch Step: 51 Loss: 1.149618 Tokens per Sec: 13575.026367\n",
      "\n",
      "Epoch Step: 101 Loss: 1.463768 Tokens per Sec: 13627.706055\n",
      "\n",
      "Epoch Step: 151 Loss: 1.178394 Tokens per Sec: 13501.582031\n",
      "\n",
      "Epoch Step: 201 Loss: 1.103191 Tokens per Sec: 13690.237305\n",
      "\n",
      "Epoch Step: 251 Loss: 1.772760 Tokens per Sec: 13286.759766\n",
      "\n",
      "Epoch Step: 301 Loss: 1.793377 Tokens per Sec: 13063.347656\n",
      "\n",
      "Epoch Step: 351 Loss: 1.368430 Tokens per Sec: 12891.256836\n",
      "\n",
      "Epoch Step: 401 Loss: 1.723781 Tokens per Sec: 13436.609375\n",
      "\n",
      "Epoch Step: 451 Loss: 1.214679 Tokens per Sec: 13123.584961\n",
      "\n",
      "Epoch Step: 501 Loss: 1.456706 Tokens per Sec: 13351.672852\n",
      "\n",
      "Epoch Step: 551 Loss: 1.712949 Tokens per Sec: 13331.493164\n",
      "\n",
      "Epoch Step: 601 Loss: 1.653122 Tokens per Sec: 13254.563477\n",
      "\n",
      "Epoch Step: 651 Loss: 1.511877 Tokens per Sec: 12768.243164\n",
      "\n",
      "Epoch Step: 701 Loss: 1.474118 Tokens per Sec: 13215.806641\n",
      "\n",
      "Epoch Step: 751 Loss: 1.436049 Tokens per Sec: 13644.272461\n",
      "\n",
      "Epoch Step: 801 Loss: 1.523660 Tokens per Sec: 12730.666016\n",
      "\n",
      "Epoch Step: 851 Loss: 1.968694 Tokens per Sec: 13450.235352\n",
      "\n",
      "Epoch Step: 901 Loss: 1.830406 Tokens per Sec: 12722.392578\n",
      "\n",
      "Epoch Step: 951 Loss: 1.318871 Tokens per Sec: 13051.553711\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.594809 Tokens per Sec: 13230.894531\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.474250 Tokens per Sec: 13441.229492\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.261003 Tokens per Sec: 12975.213867\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.313014 Tokens per Sec: 13076.917969\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.545459 Tokens per Sec: 13461.048828\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.814098 Tokens per Sec: 13069.932617\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.429744 Tokens per Sec: 13013.384766\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.525911 Tokens per Sec: 13486.214844\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.681175 Tokens per Sec: 13081.017578\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.520613 Tokens per Sec: 12767.958008\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.528877 Tokens per Sec: 13108.970703\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.542311 Tokens per Sec: 13381.408203\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.611214 Tokens per Sec: 13288.979492\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.488225 Tokens per Sec: 13159.439453\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.470843 Tokens per Sec: 12661.899414\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.606810 Tokens per Sec: 13132.010742\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.797081 Tokens per Sec: 13231.458984\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.372872 Tokens per Sec: 13210.529297\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.436326 Tokens per Sec: 13471.274414\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.732451 Tokens per Sec: 13560.045898\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.972291 Tokens per Sec: 12976.591797\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.495776 Tokens per Sec: 13506.356445\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.914214 Tokens per Sec: 13702.676758\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.893232 Tokens per Sec: 12625.850586\n",
      "\n",
      "Epoch Step: 1 Loss: 0.939217 Tokens per Sec: 10286.207031\n",
      "\n",
      "tensor(1.1460, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.323647 Tokens per Sec: 2311.648926\n",
      "\n",
      "Epoch Step: 51 Loss: 1.413741 Tokens per Sec: 12635.886719\n",
      "\n",
      "Epoch Step: 101 Loss: 1.084187 Tokens per Sec: 13381.196289\n",
      "\n",
      "Epoch Step: 151 Loss: 1.302820 Tokens per Sec: 13862.627930\n",
      "\n",
      "Epoch Step: 201 Loss: 1.395436 Tokens per Sec: 13592.996094\n",
      "\n",
      "Epoch Step: 251 Loss: 1.404738 Tokens per Sec: 13493.802734\n",
      "\n",
      "Epoch Step: 301 Loss: 1.439070 Tokens per Sec: 13791.764648\n",
      "\n",
      "Epoch Step: 351 Loss: 1.623841 Tokens per Sec: 13433.209961\n",
      "\n",
      "Epoch Step: 401 Loss: 1.469921 Tokens per Sec: 12787.747070\n",
      "\n",
      "Epoch Step: 451 Loss: 1.034056 Tokens per Sec: 13330.085938\n",
      "\n",
      "Epoch Step: 501 Loss: 1.521399 Tokens per Sec: 13341.916016\n",
      "\n",
      "Epoch Step: 551 Loss: 1.402080 Tokens per Sec: 13352.037109\n",
      "\n",
      "Epoch Step: 601 Loss: 1.718565 Tokens per Sec: 13226.274414\n",
      "\n",
      "Epoch Step: 651 Loss: 1.355813 Tokens per Sec: 13266.052734\n",
      "\n",
      "Epoch Step: 701 Loss: 1.675838 Tokens per Sec: 12981.940430\n",
      "\n",
      "Epoch Step: 751 Loss: 1.631938 Tokens per Sec: 13085.098633\n",
      "\n",
      "Epoch Step: 801 Loss: 1.585213 Tokens per Sec: 13130.742188\n",
      "\n",
      "Epoch Step: 851 Loss: 1.322622 Tokens per Sec: 13151.940430\n",
      "\n",
      "Epoch Step: 901 Loss: 1.403210 Tokens per Sec: 13144.115234\n",
      "\n",
      "Epoch Step: 951 Loss: 1.514136 Tokens per Sec: 13055.051758\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.628546 Tokens per Sec: 13215.815430\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.371461 Tokens per Sec: 13605.480469\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.906571 Tokens per Sec: 13389.668945\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.425235 Tokens per Sec: 13101.188477\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.246180 Tokens per Sec: 13392.023438\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.323994 Tokens per Sec: 13306.340820\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.797747 Tokens per Sec: 13102.557617\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.394656 Tokens per Sec: 13234.655273\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.179709 Tokens per Sec: 13519.564453\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.385765 Tokens per Sec: 13178.287109\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.830979 Tokens per Sec: 13435.846680\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.528850 Tokens per Sec: 13020.847656\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.270389 Tokens per Sec: 13388.935547\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.352732 Tokens per Sec: 13565.951172\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.526923 Tokens per Sec: 12855.006836\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.672348 Tokens per Sec: 13110.874023\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.928410 Tokens per Sec: 13155.625977\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.620384 Tokens per Sec: 13426.775391\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.830066 Tokens per Sec: 13479.151367\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.525660 Tokens per Sec: 13122.553711\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.506169 Tokens per Sec: 13418.249023\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.473358 Tokens per Sec: 12700.559570\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.893757 Tokens per Sec: 13452.504883\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.673149 Tokens per Sec: 13486.671875\n",
      "\n",
      "Epoch Step: 1 Loss: 0.945065 Tokens per Sec: 10805.937500\n",
      "\n",
      "tensor(1.1333, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.382015 Tokens per Sec: 2825.851562\n",
      "\n",
      "Epoch Step: 51 Loss: 1.844490 Tokens per Sec: 13579.588867\n",
      "\n",
      "Epoch Step: 101 Loss: 1.442814 Tokens per Sec: 13705.333008\n",
      "\n",
      "Epoch Step: 151 Loss: 1.571753 Tokens per Sec: 12587.352539\n",
      "\n",
      "Epoch Step: 201 Loss: 1.170375 Tokens per Sec: 12643.350586\n",
      "\n",
      "Epoch Step: 251 Loss: 1.792825 Tokens per Sec: 12651.258789\n",
      "\n",
      "Epoch Step: 301 Loss: 1.135946 Tokens per Sec: 13108.791992\n",
      "\n",
      "Epoch Step: 351 Loss: 1.426373 Tokens per Sec: 13532.756836\n",
      "\n",
      "Epoch Step: 401 Loss: 1.491304 Tokens per Sec: 13430.338867\n",
      "\n",
      "Epoch Step: 451 Loss: 1.569023 Tokens per Sec: 13145.236328\n",
      "\n",
      "Epoch Step: 501 Loss: 1.739232 Tokens per Sec: 13394.499023\n",
      "\n",
      "Epoch Step: 551 Loss: 1.621080 Tokens per Sec: 13853.942383\n",
      "\n",
      "Epoch Step: 601 Loss: 1.686004 Tokens per Sec: 13910.057617\n",
      "\n",
      "Epoch Step: 651 Loss: 1.591048 Tokens per Sec: 13714.400391\n",
      "\n",
      "Epoch Step: 701 Loss: 1.803193 Tokens per Sec: 13230.739258\n",
      "\n",
      "Epoch Step: 751 Loss: 1.515994 Tokens per Sec: 13187.639648\n",
      "\n",
      "Epoch Step: 801 Loss: 1.461117 Tokens per Sec: 13724.267578\n",
      "\n",
      "Epoch Step: 851 Loss: 1.673525 Tokens per Sec: 13353.755859\n",
      "\n",
      "Epoch Step: 901 Loss: 1.537772 Tokens per Sec: 13453.333008\n",
      "\n",
      "Epoch Step: 951 Loss: 1.573476 Tokens per Sec: 12907.198242\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.647180 Tokens per Sec: 13093.665039\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.671714 Tokens per Sec: 13159.409180\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.603101 Tokens per Sec: 12826.736328\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.127554 Tokens per Sec: 12877.773438\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.501865 Tokens per Sec: 13228.662109\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.220213 Tokens per Sec: 13452.739258\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.777821 Tokens per Sec: 13002.149414\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.920547 Tokens per Sec: 13586.493164\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.513746 Tokens per Sec: 13505.886719\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.478107 Tokens per Sec: 13410.005859\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.533259 Tokens per Sec: 12964.452148\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.258151 Tokens per Sec: 12976.393555\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.146942 Tokens per Sec: 12539.485352\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.339484 Tokens per Sec: 13285.890625\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.657848 Tokens per Sec: 13431.657227\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.778962 Tokens per Sec: 13235.927734\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.468610 Tokens per Sec: 13123.794922\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.399697 Tokens per Sec: 13037.397461\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.578022 Tokens per Sec: 13577.094727\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.819222 Tokens per Sec: 13170.246094\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.463636 Tokens per Sec: 13315.591797\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.527105 Tokens per Sec: 13226.241211\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.517502 Tokens per Sec: 13102.766602\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.403102 Tokens per Sec: 13319.525391\n",
      "\n",
      "Epoch Step: 1 Loss: 0.917337 Tokens per Sec: 11415.551758\n",
      "\n",
      "tensor(1.1087, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.484766 Tokens per Sec: 2398.266602\n",
      "\n",
      "Epoch Step: 51 Loss: 1.086230 Tokens per Sec: 13210.274414\n",
      "\n",
      "Epoch Step: 101 Loss: 1.495072 Tokens per Sec: 13475.521484\n",
      "\n",
      "Epoch Step: 151 Loss: 0.752069 Tokens per Sec: 13028.026367\n",
      "\n",
      "Epoch Step: 201 Loss: 1.472557 Tokens per Sec: 13444.562500\n",
      "\n",
      "Epoch Step: 251 Loss: 1.657027 Tokens per Sec: 13634.828125\n",
      "\n",
      "Epoch Step: 301 Loss: 1.091675 Tokens per Sec: 13710.861328\n",
      "\n",
      "Epoch Step: 351 Loss: 1.902776 Tokens per Sec: 12700.508789\n",
      "\n",
      "Epoch Step: 401 Loss: 1.611292 Tokens per Sec: 12435.963867\n",
      "\n",
      "Epoch Step: 451 Loss: 1.590573 Tokens per Sec: 12379.169922\n",
      "\n",
      "Epoch Step: 501 Loss: 1.241054 Tokens per Sec: 13310.110352\n",
      "\n",
      "Epoch Step: 551 Loss: 1.373754 Tokens per Sec: 13210.091797\n",
      "\n",
      "Epoch Step: 601 Loss: 1.615550 Tokens per Sec: 13769.741211\n",
      "\n",
      "Epoch Step: 651 Loss: 1.364942 Tokens per Sec: 13666.080078\n",
      "\n",
      "Epoch Step: 701 Loss: 1.504806 Tokens per Sec: 13748.965820\n",
      "\n",
      "Epoch Step: 751 Loss: 1.474738 Tokens per Sec: 13518.500000\n",
      "\n",
      "Epoch Step: 801 Loss: 1.930071 Tokens per Sec: 13261.390625\n",
      "\n",
      "Epoch Step: 851 Loss: 1.164680 Tokens per Sec: 13339.176758\n",
      "\n",
      "Epoch Step: 901 Loss: 1.480289 Tokens per Sec: 13042.499023\n",
      "\n",
      "Epoch Step: 951 Loss: 1.352951 Tokens per Sec: 13101.016602\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.461987 Tokens per Sec: 13568.104492\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.556780 Tokens per Sec: 13271.759766\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.412063 Tokens per Sec: 13148.845703\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.454981 Tokens per Sec: 13124.197266\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.282683 Tokens per Sec: 13249.469727\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.527065 Tokens per Sec: 13284.750977\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.489743 Tokens per Sec: 13223.649414\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.909845 Tokens per Sec: 13702.893555\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.319311 Tokens per Sec: 13054.415039\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.383552 Tokens per Sec: 13169.265625\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.216567 Tokens per Sec: 13621.915039\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.729434 Tokens per Sec: 12851.802734\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.333731 Tokens per Sec: 12777.605469\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.133049 Tokens per Sec: 13356.624023\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.311758 Tokens per Sec: 12811.712891\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.543865 Tokens per Sec: 13317.393555\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.457003 Tokens per Sec: 13093.859375\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.493998 Tokens per Sec: 12891.742188\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.375625 Tokens per Sec: 13187.616211\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.105184 Tokens per Sec: 13408.337891\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.382591 Tokens per Sec: 12959.917969\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.492521 Tokens per Sec: 13412.047852\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.298652 Tokens per Sec: 12833.638672\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.757013 Tokens per Sec: 13274.891602\n",
      "\n",
      "Epoch Step: 1 Loss: 0.895588 Tokens per Sec: 11339.237305\n",
      "\n",
      "tensor(1.0822, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.381139 Tokens per Sec: 2648.825439\n",
      "\n",
      "Epoch Step: 51 Loss: 1.440960 Tokens per Sec: 13290.236328\n",
      "\n",
      "Epoch Step: 101 Loss: 1.546836 Tokens per Sec: 13668.784180\n",
      "\n",
      "Epoch Step: 151 Loss: 1.459908 Tokens per Sec: 13016.035156\n",
      "\n",
      "Epoch Step: 201 Loss: 1.379243 Tokens per Sec: 13375.767578\n",
      "\n",
      "Epoch Step: 251 Loss: 1.781684 Tokens per Sec: 13113.757812\n",
      "\n",
      "Epoch Step: 301 Loss: 1.200825 Tokens per Sec: 13265.308594\n",
      "\n",
      "Epoch Step: 351 Loss: 1.335418 Tokens per Sec: 12970.000000\n",
      "\n",
      "Epoch Step: 401 Loss: 1.099404 Tokens per Sec: 13440.198242\n",
      "\n",
      "Epoch Step: 451 Loss: 1.290668 Tokens per Sec: 13090.107422\n",
      "\n",
      "Epoch Step: 501 Loss: 1.070499 Tokens per Sec: 12761.894531\n",
      "\n",
      "Epoch Step: 551 Loss: 1.464843 Tokens per Sec: 12500.500000\n",
      "\n",
      "Epoch Step: 601 Loss: 1.776819 Tokens per Sec: 12414.548828\n",
      "\n",
      "Epoch Step: 651 Loss: 1.184350 Tokens per Sec: 13111.004883\n",
      "\n",
      "Epoch Step: 701 Loss: 1.097344 Tokens per Sec: 13392.660156\n",
      "\n",
      "Epoch Step: 751 Loss: 1.423724 Tokens per Sec: 13601.087891\n",
      "\n",
      "Epoch Step: 801 Loss: 1.382885 Tokens per Sec: 13419.164062\n",
      "\n",
      "Epoch Step: 851 Loss: 1.511432 Tokens per Sec: 13286.814453\n",
      "\n",
      "Epoch Step: 901 Loss: 1.348992 Tokens per Sec: 13344.836914\n",
      "\n",
      "Epoch Step: 951 Loss: 1.133376 Tokens per Sec: 13438.159180\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.338144 Tokens per Sec: 12995.301758\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.350566 Tokens per Sec: 12955.306641\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.493325 Tokens per Sec: 12984.860352\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.498679 Tokens per Sec: 13386.272461\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.150784 Tokens per Sec: 13252.181641\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.788019 Tokens per Sec: 13574.904297\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.321957 Tokens per Sec: 12795.452148\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.091741 Tokens per Sec: 13561.047852\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.459256 Tokens per Sec: 13348.356445\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.869872 Tokens per Sec: 13453.885742\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.188379 Tokens per Sec: 13128.547852\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.569654 Tokens per Sec: 13385.717773\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.270030 Tokens per Sec: 13065.795898\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.403415 Tokens per Sec: 13270.040039\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.398618 Tokens per Sec: 12730.606445\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.328268 Tokens per Sec: 13488.259766\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.674560 Tokens per Sec: 13363.094727\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.454241 Tokens per Sec: 13213.158203\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.561103 Tokens per Sec: 13261.650391\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.837948 Tokens per Sec: 13072.416016\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.516217 Tokens per Sec: 13325.916016\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.098608 Tokens per Sec: 13311.460938\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.476196 Tokens per Sec: 12932.369141\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.288158 Tokens per Sec: 13310.642578\n",
      "\n",
      "Epoch Step: 1 Loss: 0.879034 Tokens per Sec: 11628.052734\n",
      "\n",
      "tensor(1.0628, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.298570 Tokens per Sec: 2499.832275\n",
      "\n",
      "Epoch Step: 51 Loss: 1.313765 Tokens per Sec: 13431.232422\n",
      "\n",
      "Epoch Step: 101 Loss: 1.425860 Tokens per Sec: 13542.377930\n",
      "\n",
      "Epoch Step: 151 Loss: 1.557264 Tokens per Sec: 13317.798828\n",
      "\n",
      "Epoch Step: 201 Loss: 1.821863 Tokens per Sec: 12841.443359\n",
      "\n",
      "Epoch Step: 251 Loss: 1.762336 Tokens per Sec: 13259.612305\n",
      "\n",
      "Epoch Step: 301 Loss: 1.202386 Tokens per Sec: 13438.850586\n",
      "\n",
      "Epoch Step: 351 Loss: 1.487675 Tokens per Sec: 13397.564453\n",
      "\n",
      "Epoch Step: 401 Loss: 1.368271 Tokens per Sec: 12913.208008\n",
      "\n",
      "Epoch Step: 451 Loss: 1.198462 Tokens per Sec: 13396.812500\n",
      "\n",
      "Epoch Step: 501 Loss: 1.398335 Tokens per Sec: 13508.735352\n",
      "\n",
      "Epoch Step: 551 Loss: 1.593240 Tokens per Sec: 13480.457031\n",
      "\n",
      "Epoch Step: 601 Loss: 1.315103 Tokens per Sec: 13474.149414\n",
      "\n",
      "Epoch Step: 651 Loss: 1.262880 Tokens per Sec: 13444.895508\n",
      "\n",
      "Epoch Step: 701 Loss: 1.868160 Tokens per Sec: 12650.191406\n",
      "\n",
      "Epoch Step: 751 Loss: 1.309343 Tokens per Sec: 12535.802734\n",
      "\n",
      "Epoch Step: 801 Loss: 1.483593 Tokens per Sec: 12370.366211\n",
      "\n",
      "Epoch Step: 851 Loss: 1.795495 Tokens per Sec: 13655.977539\n",
      "\n",
      "Epoch Step: 901 Loss: 1.420355 Tokens per Sec: 13662.575195\n",
      "\n",
      "Epoch Step: 951 Loss: 0.951490 Tokens per Sec: 13305.406250\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.576260 Tokens per Sec: 13422.538086\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.707802 Tokens per Sec: 13673.866211\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.968335 Tokens per Sec: 13573.796875\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.407595 Tokens per Sec: 13434.178711\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.777193 Tokens per Sec: 12960.660156\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.123608 Tokens per Sec: 13138.113281\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.383641 Tokens per Sec: 13498.044922\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.524404 Tokens per Sec: 12684.382812\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.457241 Tokens per Sec: 13374.462891\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.296922 Tokens per Sec: 12976.991211\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.799364 Tokens per Sec: 13441.099609\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.681746 Tokens per Sec: 13447.803711\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.272391 Tokens per Sec: 13482.202148\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.284117 Tokens per Sec: 13481.943359\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.415358 Tokens per Sec: 13212.835938\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.638522 Tokens per Sec: 13119.251953\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.241546 Tokens per Sec: 13520.469727\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.522552 Tokens per Sec: 13326.792969\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.433788 Tokens per Sec: 13294.973633\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.683928 Tokens per Sec: 13120.228516\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.147955 Tokens per Sec: 13326.306641\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.292703 Tokens per Sec: 13398.521484\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.536654 Tokens per Sec: 13379.395508\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.476398 Tokens per Sec: 13278.017578\n",
      "\n",
      "Epoch Step: 1 Loss: 0.867523 Tokens per Sec: 11551.065430\n",
      "\n",
      "tensor(1.0396, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.500012 Tokens per Sec: 2627.796875\n",
      "\n",
      "Epoch Step: 51 Loss: 1.664850 Tokens per Sec: 13203.589844\n",
      "\n",
      "Epoch Step: 101 Loss: 1.370341 Tokens per Sec: 13228.472656\n",
      "\n",
      "Epoch Step: 151 Loss: 1.549554 Tokens per Sec: 13066.492188\n",
      "\n",
      "Epoch Step: 201 Loss: 1.312572 Tokens per Sec: 13318.793945\n",
      "\n",
      "Epoch Step: 251 Loss: 1.134993 Tokens per Sec: 13416.151367\n",
      "\n",
      "Epoch Step: 301 Loss: 1.093573 Tokens per Sec: 13108.799805\n",
      "\n",
      "Epoch Step: 351 Loss: 1.794139 Tokens per Sec: 13188.630859\n",
      "\n",
      "Epoch Step: 401 Loss: 1.165927 Tokens per Sec: 13167.778320\n",
      "\n",
      "Epoch Step: 451 Loss: 0.897773 Tokens per Sec: 13135.761719\n",
      "\n",
      "Epoch Step: 501 Loss: 1.874600 Tokens per Sec: 13266.475586\n",
      "\n",
      "Epoch Step: 551 Loss: 1.381145 Tokens per Sec: 13134.579102\n",
      "\n",
      "Epoch Step: 601 Loss: 1.581368 Tokens per Sec: 13465.327148\n",
      "\n",
      "Epoch Step: 651 Loss: 1.121271 Tokens per Sec: 13287.989258\n",
      "\n",
      "Epoch Step: 701 Loss: 1.503934 Tokens per Sec: 12927.818359\n",
      "\n",
      "Epoch Step: 751 Loss: 1.251005 Tokens per Sec: 13255.298828\n",
      "\n",
      "Epoch Step: 801 Loss: 1.226029 Tokens per Sec: 13050.977539\n",
      "\n",
      "Epoch Step: 851 Loss: 1.648625 Tokens per Sec: 12926.251953\n",
      "\n",
      "Epoch Step: 901 Loss: 1.493625 Tokens per Sec: 12473.265625\n",
      "\n",
      "Epoch Step: 951 Loss: 1.718203 Tokens per Sec: 12191.963867\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.475674 Tokens per Sec: 13017.882812\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.081188 Tokens per Sec: 13803.962891\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.434821 Tokens per Sec: 13913.633789\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.301829 Tokens per Sec: 14119.657227\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.574793 Tokens per Sec: 14078.054688\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.258713 Tokens per Sec: 13817.765625\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.846677 Tokens per Sec: 14168.492188\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.470749 Tokens per Sec: 13285.053711\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.619721 Tokens per Sec: 12933.550781\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.542531 Tokens per Sec: 13315.808594\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.893096 Tokens per Sec: 13489.781250\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.091313 Tokens per Sec: 12969.259766\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.470188 Tokens per Sec: 13191.559570\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.285475 Tokens per Sec: 13101.796875\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.479628 Tokens per Sec: 13168.681641\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.413203 Tokens per Sec: 12756.560547\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.393491 Tokens per Sec: 12983.446289\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.788016 Tokens per Sec: 13180.410156\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.190160 Tokens per Sec: 13038.373047\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.480248 Tokens per Sec: 13203.173828\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.547529 Tokens per Sec: 13251.379883\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.687466 Tokens per Sec: 13297.366211\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.479394 Tokens per Sec: 13003.181641\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.449666 Tokens per Sec: 13198.944336\n",
      "\n",
      "Epoch Step: 1 Loss: 0.854056 Tokens per Sec: 11502.080078\n",
      "\n",
      "tensor(1.0184, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.458346 Tokens per Sec: 2715.823486\n",
      "\n",
      "Epoch Step: 51 Loss: 1.108847 Tokens per Sec: 13182.138672\n",
      "\n",
      "Epoch Step: 101 Loss: 1.579964 Tokens per Sec: 13135.222656\n",
      "\n",
      "Epoch Step: 151 Loss: 1.130847 Tokens per Sec: 13520.917969\n",
      "\n",
      "Epoch Step: 201 Loss: 1.155517 Tokens per Sec: 13210.990234\n",
      "\n",
      "Epoch Step: 251 Loss: 1.153629 Tokens per Sec: 12780.005859\n",
      "\n",
      "Epoch Step: 301 Loss: 1.272559 Tokens per Sec: 12722.082031\n",
      "\n",
      "Epoch Step: 351 Loss: 0.799143 Tokens per Sec: 13295.441406\n",
      "\n",
      "Epoch Step: 401 Loss: 1.145816 Tokens per Sec: 13509.664062\n",
      "\n",
      "Epoch Step: 451 Loss: 1.536813 Tokens per Sec: 12941.677734\n",
      "\n",
      "Epoch Step: 501 Loss: 1.414131 Tokens per Sec: 13163.544922\n",
      "\n",
      "Epoch Step: 551 Loss: 1.408359 Tokens per Sec: 13214.888672\n",
      "\n",
      "Epoch Step: 601 Loss: 1.378129 Tokens per Sec: 12898.696289\n",
      "\n",
      "Epoch Step: 651 Loss: 1.408883 Tokens per Sec: 13646.781250\n",
      "\n",
      "Epoch Step: 701 Loss: 1.563094 Tokens per Sec: 13374.070312\n",
      "\n",
      "Epoch Step: 751 Loss: 1.500336 Tokens per Sec: 12961.535156\n",
      "\n",
      "Epoch Step: 801 Loss: 1.413883 Tokens per Sec: 12710.274414\n",
      "\n",
      "Epoch Step: 851 Loss: 1.615882 Tokens per Sec: 13328.297852\n",
      "\n",
      "Epoch Step: 901 Loss: 1.281765 Tokens per Sec: 13265.496094\n",
      "\n",
      "Epoch Step: 951 Loss: 1.469653 Tokens per Sec: 13595.080078\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.359106 Tokens per Sec: 13575.219727\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.027705 Tokens per Sec: 12569.377930\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.582943 Tokens per Sec: 12530.788086\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.184998 Tokens per Sec: 12484.941406\n",
      "\n",
      "Epoch Step: 1201 Loss: 0.964396 Tokens per Sec: 13634.776367\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.531256 Tokens per Sec: 13635.718750\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.558733 Tokens per Sec: 13611.440430\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.024661 Tokens per Sec: 12592.122070\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.527178 Tokens per Sec: 12945.250977\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.537140 Tokens per Sec: 13744.928711\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.508590 Tokens per Sec: 13222.859375\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.347706 Tokens per Sec: 13385.755859\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.368324 Tokens per Sec: 12873.654297\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.583180 Tokens per Sec: 13430.711914\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.393263 Tokens per Sec: 13422.563477\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.186113 Tokens per Sec: 13391.629883\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.433959 Tokens per Sec: 13321.297852\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.616439 Tokens per Sec: 12881.747070\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.458988 Tokens per Sec: 13263.164062\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.624951 Tokens per Sec: 13108.404297\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.521353 Tokens per Sec: 13357.134766\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.474695 Tokens per Sec: 12999.675781\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.129762 Tokens per Sec: 12999.899414\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.470139 Tokens per Sec: 13138.965820\n",
      "\n",
      "Epoch Step: 1 Loss: 0.842519 Tokens per Sec: 11784.277344\n",
      "\n",
      "tensor(1.0034, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.429562 Tokens per Sec: 2630.182373\n",
      "\n",
      "Epoch Step: 51 Loss: 1.203806 Tokens per Sec: 13448.228516\n",
      "\n",
      "Epoch Step: 101 Loss: 1.316223 Tokens per Sec: 12897.569336\n",
      "\n",
      "Epoch Step: 151 Loss: 1.599564 Tokens per Sec: 13340.565430\n",
      "\n",
      "Epoch Step: 201 Loss: 1.367880 Tokens per Sec: 13428.352539\n",
      "\n",
      "Epoch Step: 251 Loss: 1.279782 Tokens per Sec: 13252.514648\n",
      "\n",
      "Epoch Step: 301 Loss: 1.359861 Tokens per Sec: 13185.590820\n",
      "\n",
      "Epoch Step: 351 Loss: 1.237997 Tokens per Sec: 13209.315430\n",
      "\n",
      "Epoch Step: 401 Loss: 1.297994 Tokens per Sec: 12937.323242\n",
      "\n",
      "Epoch Step: 451 Loss: 1.116164 Tokens per Sec: 13297.883789\n",
      "\n",
      "Epoch Step: 501 Loss: 1.807555 Tokens per Sec: 13261.729492\n",
      "\n",
      "Epoch Step: 551 Loss: 1.510376 Tokens per Sec: 13345.381836\n",
      "\n",
      "Epoch Step: 601 Loss: 1.389918 Tokens per Sec: 13505.409180\n",
      "\n",
      "Epoch Step: 651 Loss: 1.426050 Tokens per Sec: 13120.165039\n",
      "\n",
      "Epoch Step: 701 Loss: 1.179777 Tokens per Sec: 13224.365234\n",
      "\n",
      "Epoch Step: 751 Loss: 0.965681 Tokens per Sec: 13287.077148\n",
      "\n",
      "Epoch Step: 801 Loss: 1.563115 Tokens per Sec: 13417.949219\n",
      "\n",
      "Epoch Step: 851 Loss: 1.297091 Tokens per Sec: 13001.579102\n",
      "\n",
      "Epoch Step: 901 Loss: 1.200271 Tokens per Sec: 13345.053711\n",
      "\n",
      "Epoch Step: 951 Loss: 1.356699 Tokens per Sec: 13026.906250\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.353791 Tokens per Sec: 13126.001953\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.404210 Tokens per Sec: 12978.710938\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.500107 Tokens per Sec: 12916.698242\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.412312 Tokens per Sec: 13564.930664\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.816564 Tokens per Sec: 12868.491211\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.648303 Tokens per Sec: 12056.379883\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.240118 Tokens per Sec: 12641.277344\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.692745 Tokens per Sec: 12985.825195\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.841466 Tokens per Sec: 13756.574219\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.862590 Tokens per Sec: 13359.451172\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.540737 Tokens per Sec: 13193.909180\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.340101 Tokens per Sec: 12357.618164\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.498993 Tokens per Sec: 13076.981445\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.299876 Tokens per Sec: 13365.408203\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.133575 Tokens per Sec: 13172.214844\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.825879 Tokens per Sec: 13177.413086\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.847271 Tokens per Sec: 13350.514648\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.394660 Tokens per Sec: 13615.649414\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.726766 Tokens per Sec: 13550.373047\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.210911 Tokens per Sec: 13287.778320\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.301868 Tokens per Sec: 13129.055664\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.601219 Tokens per Sec: 13320.639648\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.443050 Tokens per Sec: 13140.453125\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.640070 Tokens per Sec: 13357.004883\n",
      "\n",
      "Epoch Step: 1 Loss: 0.825834 Tokens per Sec: 11490.359375\n",
      "\n",
      "tensor(0.9850, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.137981 Tokens per Sec: 2653.635254\n",
      "\n",
      "Epoch Step: 51 Loss: 1.322598 Tokens per Sec: 13564.664062\n",
      "\n",
      "Epoch Step: 101 Loss: 1.527552 Tokens per Sec: 13130.039062\n",
      "\n",
      "Epoch Step: 151 Loss: 1.733440 Tokens per Sec: 13462.372070\n",
      "\n",
      "Epoch Step: 201 Loss: 1.118124 Tokens per Sec: 13490.368164\n",
      "\n",
      "Epoch Step: 251 Loss: 1.372413 Tokens per Sec: 13303.466797\n",
      "\n",
      "Epoch Step: 301 Loss: 1.246520 Tokens per Sec: 12801.222656\n",
      "\n",
      "Epoch Step: 351 Loss: 1.196446 Tokens per Sec: 12995.471680\n",
      "\n",
      "Epoch Step: 401 Loss: 1.316071 Tokens per Sec: 12603.555664\n",
      "\n",
      "Epoch Step: 451 Loss: 1.287453 Tokens per Sec: 13418.719727\n",
      "\n",
      "Epoch Step: 501 Loss: 1.146230 Tokens per Sec: 13065.825195\n",
      "\n",
      "Epoch Step: 551 Loss: 1.338359 Tokens per Sec: 13423.793945\n",
      "\n",
      "Epoch Step: 601 Loss: 1.503845 Tokens per Sec: 13150.988281\n",
      "\n",
      "Epoch Step: 651 Loss: 1.212588 Tokens per Sec: 12933.313477\n",
      "\n",
      "Epoch Step: 701 Loss: 1.378557 Tokens per Sec: 13119.163086\n",
      "\n",
      "Epoch Step: 751 Loss: 1.122431 Tokens per Sec: 13301.931641\n",
      "\n",
      "Epoch Step: 801 Loss: 1.351755 Tokens per Sec: 13534.361328\n",
      "\n",
      "Epoch Step: 851 Loss: 1.343601 Tokens per Sec: 12958.969727\n",
      "\n",
      "Epoch Step: 901 Loss: 1.141498 Tokens per Sec: 12982.114258\n",
      "\n",
      "Epoch Step: 951 Loss: 1.178171 Tokens per Sec: 13095.786133\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.548420 Tokens per Sec: 13328.410156\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.230389 Tokens per Sec: 12981.533203\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.573743 Tokens per Sec: 12801.755859\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.358770 Tokens per Sec: 13481.819336\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.144523 Tokens per Sec: 13242.446289\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.712774 Tokens per Sec: 13216.238281\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.265598 Tokens per Sec: 13737.040039\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.223436 Tokens per Sec: 12968.709961\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.086095 Tokens per Sec: 13006.823242\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.331620 Tokens per Sec: 12521.168945\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.715150 Tokens per Sec: 13129.586914\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.417002 Tokens per Sec: 13663.505859\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.276226 Tokens per Sec: 13606.341797\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.712215 Tokens per Sec: 13620.950195\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.589438 Tokens per Sec: 13472.260742\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.614067 Tokens per Sec: 13743.513672\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.183761 Tokens per Sec: 13772.147461\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.331176 Tokens per Sec: 13311.152344\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.431495 Tokens per Sec: 13398.612305\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.322842 Tokens per Sec: 12858.923828\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.202269 Tokens per Sec: 13316.713867\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.492439 Tokens per Sec: 13170.913086\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.277528 Tokens per Sec: 13451.148438\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.218680 Tokens per Sec: 13101.180664\n",
      "\n",
      "Epoch Step: 1 Loss: 0.798442 Tokens per Sec: 10668.049805\n",
      "\n",
      "tensor(0.9564, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.030188 Tokens per Sec: 2825.642090\n",
      "\n",
      "Epoch Step: 51 Loss: 1.117529 Tokens per Sec: 12874.707031\n",
      "\n",
      "Epoch Step: 101 Loss: 1.498865 Tokens per Sec: 13160.389648\n",
      "\n",
      "Epoch Step: 151 Loss: 1.336896 Tokens per Sec: 12706.547852\n",
      "\n",
      "Epoch Step: 201 Loss: 1.492175 Tokens per Sec: 12638.481445\n",
      "\n",
      "Epoch Step: 251 Loss: 1.546248 Tokens per Sec: 13332.387695\n",
      "\n",
      "Epoch Step: 301 Loss: 1.371515 Tokens per Sec: 13367.487305\n",
      "\n",
      "Epoch Step: 351 Loss: 1.271126 Tokens per Sec: 13261.402344\n",
      "\n",
      "Epoch Step: 401 Loss: 1.180566 Tokens per Sec: 13432.302734\n",
      "\n",
      "Epoch Step: 451 Loss: 1.519511 Tokens per Sec: 13368.607422\n",
      "\n",
      "Epoch Step: 501 Loss: 1.548116 Tokens per Sec: 13142.384766\n",
      "\n",
      "Epoch Step: 551 Loss: 0.903064 Tokens per Sec: 13035.236328\n",
      "\n",
      "Epoch Step: 601 Loss: 1.103260 Tokens per Sec: 13183.232422\n",
      "\n",
      "Epoch Step: 651 Loss: 1.565660 Tokens per Sec: 13083.435547\n",
      "\n",
      "Epoch Step: 701 Loss: 1.249312 Tokens per Sec: 12837.004883\n",
      "\n",
      "Epoch Step: 751 Loss: 1.234244 Tokens per Sec: 13040.537109\n",
      "\n",
      "Epoch Step: 801 Loss: 1.313504 Tokens per Sec: 13590.563477\n",
      "\n",
      "Epoch Step: 851 Loss: 1.429302 Tokens per Sec: 13567.516602\n",
      "\n",
      "Epoch Step: 901 Loss: 1.159397 Tokens per Sec: 13373.676758\n",
      "\n",
      "Epoch Step: 951 Loss: 1.342833 Tokens per Sec: 13414.240234\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.538266 Tokens per Sec: 13487.708008\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.633955 Tokens per Sec: 13246.825195\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.358000 Tokens per Sec: 13206.333984\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.048187 Tokens per Sec: 13034.031250\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.396508 Tokens per Sec: 13591.960938\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.275422 Tokens per Sec: 12940.803711\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.397586 Tokens per Sec: 13452.089844\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.475596 Tokens per Sec: 13441.696289\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.389876 Tokens per Sec: 13320.907227\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.318248 Tokens per Sec: 13349.349609\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.006061 Tokens per Sec: 13519.372070\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.565301 Tokens per Sec: 13018.951172\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.144552 Tokens per Sec: 12815.007812\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.385300 Tokens per Sec: 12574.579102\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.536789 Tokens per Sec: 12853.885742\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.496976 Tokens per Sec: 13255.466797\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.526160 Tokens per Sec: 13440.672852\n",
      "\n",
      "Epoch Step: 1851 Loss: 0.976772 Tokens per Sec: 13445.766602\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.694607 Tokens per Sec: 13342.574219\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.277078 Tokens per Sec: 13507.983398\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.459107 Tokens per Sec: 13454.516602\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.526830 Tokens per Sec: 12930.283203\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.370606 Tokens per Sec: 12833.270508\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.277007 Tokens per Sec: 13385.366211\n",
      "\n",
      "Epoch Step: 1 Loss: 0.784010 Tokens per Sec: 11594.603516\n",
      "\n",
      "tensor(0.9385, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.423172 Tokens per Sec: 2398.880615\n",
      "\n",
      "Epoch Step: 51 Loss: 1.317637 Tokens per Sec: 13351.728516\n",
      "\n",
      "Epoch Step: 101 Loss: 1.237875 Tokens per Sec: 13353.201172\n",
      "\n",
      "Epoch Step: 151 Loss: 0.958138 Tokens per Sec: 13440.385742\n",
      "\n",
      "Epoch Step: 201 Loss: 1.297466 Tokens per Sec: 13163.049805\n",
      "\n",
      "Epoch Step: 251 Loss: 1.474776 Tokens per Sec: 13368.573242\n",
      "\n",
      "Epoch Step: 301 Loss: 1.430729 Tokens per Sec: 12850.813477\n",
      "\n",
      "Epoch Step: 351 Loss: 1.598976 Tokens per Sec: 12894.968750\n",
      "\n",
      "Epoch Step: 401 Loss: 1.137664 Tokens per Sec: 13254.782227\n",
      "\n",
      "Epoch Step: 451 Loss: 1.453389 Tokens per Sec: 13291.774414\n",
      "\n",
      "Epoch Step: 501 Loss: 1.516848 Tokens per Sec: 13490.911133\n",
      "\n",
      "Epoch Step: 551 Loss: 1.429472 Tokens per Sec: 12911.056641\n",
      "\n",
      "Epoch Step: 601 Loss: 1.389381 Tokens per Sec: 13149.879883\n",
      "\n",
      "Epoch Step: 651 Loss: 1.311493 Tokens per Sec: 13532.150391\n",
      "\n",
      "Epoch Step: 701 Loss: 1.406042 Tokens per Sec: 13078.583008\n",
      "\n",
      "Epoch Step: 751 Loss: 1.213887 Tokens per Sec: 13588.279297\n",
      "\n",
      "Epoch Step: 801 Loss: 1.648042 Tokens per Sec: 13693.698242\n",
      "\n",
      "Epoch Step: 851 Loss: 1.375584 Tokens per Sec: 13238.767578\n",
      "\n",
      "Epoch Step: 901 Loss: 1.724942 Tokens per Sec: 13442.782227\n",
      "\n",
      "Epoch Step: 951 Loss: 1.254287 Tokens per Sec: 13479.099609\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.281906 Tokens per Sec: 13333.651367\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.194701 Tokens per Sec: 13090.718750\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.241346 Tokens per Sec: 12508.523438\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.416191 Tokens per Sec: 13349.833008\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.157104 Tokens per Sec: 13023.615234\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.184503 Tokens per Sec: 13339.922852\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.424854 Tokens per Sec: 12951.020508\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.405220 Tokens per Sec: 13124.112305\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.544787 Tokens per Sec: 12762.348633\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.280243 Tokens per Sec: 13419.596680\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.357427 Tokens per Sec: 13547.716797\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.084289 Tokens per Sec: 13416.021484\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.671207 Tokens per Sec: 12901.500977\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.251949 Tokens per Sec: 13599.274414\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.345311 Tokens per Sec: 13166.110352\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.655798 Tokens per Sec: 12701.924805\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.416155 Tokens per Sec: 12661.573242\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.391079 Tokens per Sec: 12168.047852\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.634447 Tokens per Sec: 13436.979492\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.367556 Tokens per Sec: 14131.975586\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.394423 Tokens per Sec: 13905.347656\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.646274 Tokens per Sec: 13738.076172\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.482908 Tokens per Sec: 13612.446289\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.490393 Tokens per Sec: 12923.267578\n",
      "\n",
      "Epoch Step: 1 Loss: 0.783413 Tokens per Sec: 11595.205078\n",
      "\n",
      "tensor(0.9235, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 0.735916 Tokens per Sec: 2914.110840\n",
      "\n",
      "Epoch Step: 51 Loss: 1.378261 Tokens per Sec: 13713.544922\n",
      "\n",
      "Epoch Step: 101 Loss: 1.307995 Tokens per Sec: 13352.951172\n",
      "\n",
      "Epoch Step: 151 Loss: 1.230694 Tokens per Sec: 12993.467773\n",
      "\n",
      "Epoch Step: 201 Loss: 0.917935 Tokens per Sec: 13158.072266\n",
      "\n",
      "Epoch Step: 251 Loss: 1.233108 Tokens per Sec: 13265.376953\n",
      "\n",
      "Epoch Step: 301 Loss: 1.531662 Tokens per Sec: 13108.223633\n",
      "\n",
      "Epoch Step: 351 Loss: 0.837964 Tokens per Sec: 13301.452148\n",
      "\n",
      "Epoch Step: 401 Loss: 1.221987 Tokens per Sec: 12956.351562\n",
      "\n",
      "Epoch Step: 451 Loss: 1.438647 Tokens per Sec: 13135.977539\n",
      "\n",
      "Epoch Step: 501 Loss: 1.305477 Tokens per Sec: 13296.609375\n",
      "\n",
      "Epoch Step: 551 Loss: 0.776141 Tokens per Sec: 13004.632812\n",
      "\n",
      "Epoch Step: 601 Loss: 0.862008 Tokens per Sec: 13431.766602\n",
      "\n",
      "Epoch Step: 651 Loss: 1.225022 Tokens per Sec: 13525.438477\n",
      "\n",
      "Epoch Step: 701 Loss: 1.275559 Tokens per Sec: 13599.580078\n",
      "\n",
      "Epoch Step: 751 Loss: 1.089604 Tokens per Sec: 13001.819336\n",
      "\n",
      "Epoch Step: 801 Loss: 1.529544 Tokens per Sec: 13272.195312\n",
      "\n",
      "Epoch Step: 851 Loss: 1.210577 Tokens per Sec: 13225.092773\n",
      "\n",
      "Epoch Step: 901 Loss: 1.449254 Tokens per Sec: 13175.979492\n",
      "\n",
      "Epoch Step: 951 Loss: 1.179190 Tokens per Sec: 13161.954102\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.052293 Tokens per Sec: 13126.724609\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.225888 Tokens per Sec: 13464.185547\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.425502 Tokens per Sec: 13204.181641\n",
      "\n",
      "Epoch Step: 1151 Loss: 0.972459 Tokens per Sec: 12971.538086\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.405042 Tokens per Sec: 12946.481445\n",
      "\n",
      "Epoch Step: 1251 Loss: 0.777000 Tokens per Sec: 12988.514648\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.430850 Tokens per Sec: 13341.843750\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.390502 Tokens per Sec: 13099.289062\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.270353 Tokens per Sec: 13147.967773\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.254976 Tokens per Sec: 13289.541016\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.297598 Tokens per Sec: 13603.123047\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.258663 Tokens per Sec: 13318.602539\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.702175 Tokens per Sec: 12828.790039\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.432160 Tokens per Sec: 13294.618164\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.461722 Tokens per Sec: 13389.496094\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.285549 Tokens per Sec: 13348.321289\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.466595 Tokens per Sec: 13272.147461\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.186683 Tokens per Sec: 13723.730469\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.446602 Tokens per Sec: 13371.335938\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.312285 Tokens per Sec: 13017.890625\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.709353 Tokens per Sec: 12716.368164\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.452477 Tokens per Sec: 12466.840820\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.204948 Tokens per Sec: 13538.071289\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.447227 Tokens per Sec: 13345.192383\n",
      "\n",
      "Epoch Step: 1 Loss: 0.769271 Tokens per Sec: 11076.581055\n",
      "\n",
      "tensor(0.9220, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 0.731774 Tokens per Sec: 2397.922119\n",
      "\n",
      "Epoch Step: 51 Loss: 1.174599 Tokens per Sec: 13696.625977\n",
      "\n",
      "Epoch Step: 101 Loss: 1.492390 Tokens per Sec: 14157.155273\n",
      "\n",
      "Epoch Step: 151 Loss: 1.159783 Tokens per Sec: 13937.747070\n",
      "\n",
      "Epoch Step: 201 Loss: 1.199740 Tokens per Sec: 13528.170898\n",
      "\n",
      "Epoch Step: 251 Loss: 0.825404 Tokens per Sec: 13277.629883\n",
      "\n",
      "Epoch Step: 301 Loss: 1.036569 Tokens per Sec: 12988.829102\n",
      "\n",
      "Epoch Step: 351 Loss: 1.439214 Tokens per Sec: 13707.225586\n",
      "\n",
      "Epoch Step: 401 Loss: 1.448261 Tokens per Sec: 13319.785156\n",
      "\n",
      "Epoch Step: 451 Loss: 1.229811 Tokens per Sec: 12752.813477\n",
      "\n",
      "Epoch Step: 501 Loss: 1.143911 Tokens per Sec: 13529.185547\n",
      "\n",
      "Epoch Step: 551 Loss: 1.273298 Tokens per Sec: 13435.582031\n",
      "\n",
      "Epoch Step: 601 Loss: 1.419473 Tokens per Sec: 13305.049805\n",
      "\n",
      "Epoch Step: 651 Loss: 1.187222 Tokens per Sec: 13639.937500\n",
      "\n",
      "Epoch Step: 701 Loss: 1.296964 Tokens per Sec: 13374.793945\n",
      "\n",
      "Epoch Step: 751 Loss: 1.480126 Tokens per Sec: 13093.132812\n",
      "\n",
      "Epoch Step: 801 Loss: 1.355714 Tokens per Sec: 13669.923828\n",
      "\n",
      "Epoch Step: 851 Loss: 1.216880 Tokens per Sec: 13007.551758\n",
      "\n",
      "Epoch Step: 901 Loss: 1.175594 Tokens per Sec: 13292.369141\n",
      "\n",
      "Epoch Step: 951 Loss: 1.250302 Tokens per Sec: 13074.878906\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.396445 Tokens per Sec: 13256.609375\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.354605 Tokens per Sec: 13393.214844\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.102390 Tokens per Sec: 13152.486328\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.227095 Tokens per Sec: 13179.167969\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.223124 Tokens per Sec: 13267.099609\n",
      "\n",
      "Epoch Step: 1251 Loss: 0.893539 Tokens per Sec: 13508.594727\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.239458 Tokens per Sec: 13114.772461\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.788739 Tokens per Sec: 12769.088867\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.545091 Tokens per Sec: 13070.148438\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.463709 Tokens per Sec: 12818.565430\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.433569 Tokens per Sec: 12915.437500\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.372180 Tokens per Sec: 13432.084961\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.407216 Tokens per Sec: 13182.102539\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.322062 Tokens per Sec: 13050.240234\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.392797 Tokens per Sec: 13117.409180\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.603313 Tokens per Sec: 13343.219727\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.568535 Tokens per Sec: 13207.154297\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.821887 Tokens per Sec: 13320.504883\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.388258 Tokens per Sec: 13298.855469\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.462261 Tokens per Sec: 13323.111328\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.823624 Tokens per Sec: 13409.505859\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.444031 Tokens per Sec: 13534.533203\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.075313 Tokens per Sec: 12833.287109\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.350609 Tokens per Sec: 12368.482422\n",
      "\n",
      "Epoch Step: 1 Loss: 0.751421 Tokens per Sec: 10126.728516\n",
      "\n",
      "tensor(0.8923, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.057555 Tokens per Sec: 2464.761230\n",
      "\n",
      "Epoch Step: 51 Loss: 1.139209 Tokens per Sec: 13535.006836\n",
      "\n",
      "Epoch Step: 101 Loss: 1.309507 Tokens per Sec: 13852.208008\n",
      "\n",
      "Epoch Step: 151 Loss: 1.191190 Tokens per Sec: 13443.930664\n",
      "\n",
      "Epoch Step: 201 Loss: 1.371308 Tokens per Sec: 13507.358398\n",
      "\n",
      "Epoch Step: 251 Loss: 1.116432 Tokens per Sec: 13758.613281\n",
      "\n",
      "Epoch Step: 301 Loss: 1.129375 Tokens per Sec: 12978.839844\n",
      "\n",
      "Epoch Step: 351 Loss: 1.532999 Tokens per Sec: 13107.121094\n",
      "\n",
      "Epoch Step: 401 Loss: 1.425267 Tokens per Sec: 12917.487305\n",
      "\n",
      "Epoch Step: 451 Loss: 1.380095 Tokens per Sec: 13118.720703\n",
      "\n",
      "Epoch Step: 501 Loss: 1.302614 Tokens per Sec: 13417.526367\n",
      "\n",
      "Epoch Step: 551 Loss: 1.212341 Tokens per Sec: 12979.674805\n",
      "\n",
      "Epoch Step: 601 Loss: 1.534337 Tokens per Sec: 13095.370117\n",
      "\n",
      "Epoch Step: 651 Loss: 1.182158 Tokens per Sec: 13472.308594\n",
      "\n",
      "Epoch Step: 701 Loss: 1.213939 Tokens per Sec: 13393.908203\n",
      "\n",
      "Epoch Step: 751 Loss: 1.586080 Tokens per Sec: 13556.483398\n",
      "\n",
      "Epoch Step: 801 Loss: 1.669838 Tokens per Sec: 12970.545898\n",
      "\n",
      "Epoch Step: 851 Loss: 1.231246 Tokens per Sec: 13474.680664\n",
      "\n",
      "Epoch Step: 901 Loss: 1.079651 Tokens per Sec: 13218.945312\n",
      "\n",
      "Epoch Step: 951 Loss: 1.623242 Tokens per Sec: 12652.027344\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.393611 Tokens per Sec: 13313.065430\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.368847 Tokens per Sec: 13216.254883\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.074973 Tokens per Sec: 13364.671875\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.251877 Tokens per Sec: 13584.434570\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.365393 Tokens per Sec: 13127.572266\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.433157 Tokens per Sec: 13069.082031\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.342030 Tokens per Sec: 12924.181641\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.062384 Tokens per Sec: 13240.087891\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.202771 Tokens per Sec: 13237.028320\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.374360 Tokens per Sec: 13684.007812\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.421273 Tokens per Sec: 13391.085938\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.048102 Tokens per Sec: 13359.092773\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.830820 Tokens per Sec: 13312.151367\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.447051 Tokens per Sec: 13191.472656\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.208484 Tokens per Sec: 13136.533203\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.208487 Tokens per Sec: 13221.212891\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.301280 Tokens per Sec: 13145.936523\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.243822 Tokens per Sec: 13278.188477\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.325372 Tokens per Sec: 13124.894531\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.255859 Tokens per Sec: 13333.370117\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.616088 Tokens per Sec: 12837.141602\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.392852 Tokens per Sec: 13033.206055\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.166781 Tokens per Sec: 13179.180664\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.369242 Tokens per Sec: 13373.288086\n",
      "\n",
      "Epoch Step: 1 Loss: 0.747933 Tokens per Sec: 11703.057617\n",
      "\n",
      "tensor(0.8797, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.073695 Tokens per Sec: 2782.776367\n",
      "\n",
      "Epoch Step: 51 Loss: 1.319557 Tokens per Sec: 13494.261719\n",
      "\n",
      "Epoch Step: 101 Loss: 1.357493 Tokens per Sec: 13105.709961\n",
      "\n",
      "Epoch Step: 151 Loss: 1.240804 Tokens per Sec: 12046.799805\n",
      "\n",
      "Epoch Step: 201 Loss: 1.094795 Tokens per Sec: 12532.944336\n",
      "\n",
      "Epoch Step: 251 Loss: 1.083388 Tokens per Sec: 13673.975586\n",
      "\n",
      "Epoch Step: 301 Loss: 1.115809 Tokens per Sec: 13756.888672\n",
      "\n",
      "Epoch Step: 351 Loss: 1.267740 Tokens per Sec: 13490.642578\n",
      "\n",
      "Epoch Step: 401 Loss: 1.328563 Tokens per Sec: 13786.082031\n",
      "\n",
      "Epoch Step: 451 Loss: 1.205333 Tokens per Sec: 13426.368164\n",
      "\n",
      "Epoch Step: 501 Loss: 1.301181 Tokens per Sec: 13687.754883\n",
      "\n",
      "Epoch Step: 551 Loss: 0.941593 Tokens per Sec: 13361.896484\n",
      "\n",
      "Epoch Step: 601 Loss: 1.476104 Tokens per Sec: 13525.484375\n",
      "\n",
      "Epoch Step: 651 Loss: 1.155524 Tokens per Sec: 13210.621094\n",
      "\n",
      "Epoch Step: 701 Loss: 1.242190 Tokens per Sec: 13097.705078\n",
      "\n",
      "Epoch Step: 751 Loss: 1.505237 Tokens per Sec: 13242.705078\n",
      "\n",
      "Epoch Step: 801 Loss: 1.218953 Tokens per Sec: 12900.703125\n",
      "\n",
      "Epoch Step: 851 Loss: 1.208468 Tokens per Sec: 13402.492188\n",
      "\n",
      "Epoch Step: 901 Loss: 1.011845 Tokens per Sec: 13280.829102\n",
      "\n",
      "Epoch Step: 951 Loss: 1.308912 Tokens per Sec: 13451.388672\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.288748 Tokens per Sec: 13355.516602\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.439251 Tokens per Sec: 13091.954102\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.495092 Tokens per Sec: 13440.296875\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.350479 Tokens per Sec: 13077.664062\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.679690 Tokens per Sec: 13289.549805\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.487044 Tokens per Sec: 13229.038086\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.735807 Tokens per Sec: 13474.387695\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.621510 Tokens per Sec: 13584.989258\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.549048 Tokens per Sec: 13416.992188\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.279489 Tokens per Sec: 12915.087891\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.631515 Tokens per Sec: 13486.300781\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.260029 Tokens per Sec: 13095.139648\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.308306 Tokens per Sec: 12713.778320\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.456100 Tokens per Sec: 13101.947266\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.373849 Tokens per Sec: 13561.004883\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.269132 Tokens per Sec: 12915.257812\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.360876 Tokens per Sec: 12853.593750\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.380454 Tokens per Sec: 13340.956055\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.620440 Tokens per Sec: 12901.076172\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.625493 Tokens per Sec: 13024.258789\n",
      "\n",
      "Epoch Step: 2001 Loss: 0.983672 Tokens per Sec: 12901.067383\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.099383 Tokens per Sec: 12730.560547\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.118217 Tokens per Sec: 12864.901367\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.378906 Tokens per Sec: 13088.963867\n",
      "\n",
      "Epoch Step: 1 Loss: 0.735266 Tokens per Sec: 10597.072266\n",
      "\n",
      "tensor(0.8611, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.404118 Tokens per Sec: 2598.155273\n",
      "\n",
      "Epoch Step: 51 Loss: 1.478048 Tokens per Sec: 13312.413086\n",
      "\n",
      "Epoch Step: 101 Loss: 1.411970 Tokens per Sec: 12942.959961\n",
      "\n",
      "Epoch Step: 151 Loss: 1.559722 Tokens per Sec: 13602.822266\n",
      "\n",
      "Epoch Step: 201 Loss: 1.042167 Tokens per Sec: 13693.254883\n",
      "\n",
      "Epoch Step: 251 Loss: 1.066695 Tokens per Sec: 12316.355469\n",
      "\n",
      "Epoch Step: 301 Loss: 1.140373 Tokens per Sec: 12606.289062\n",
      "\n",
      "Epoch Step: 351 Loss: 1.237813 Tokens per Sec: 12635.993164\n",
      "\n",
      "Epoch Step: 401 Loss: 1.097687 Tokens per Sec: 13653.740234\n",
      "\n",
      "Epoch Step: 451 Loss: 1.398612 Tokens per Sec: 13394.331055\n",
      "\n",
      "Epoch Step: 501 Loss: 1.243293 Tokens per Sec: 13061.648438\n",
      "\n",
      "Epoch Step: 551 Loss: 1.149521 Tokens per Sec: 13877.437500\n",
      "\n",
      "Epoch Step: 601 Loss: 1.517023 Tokens per Sec: 13691.218750\n",
      "\n",
      "Epoch Step: 651 Loss: 1.031339 Tokens per Sec: 13997.926758\n",
      "\n",
      "Epoch Step: 701 Loss: 1.361191 Tokens per Sec: 13541.246094\n",
      "\n",
      "Epoch Step: 751 Loss: 1.085862 Tokens per Sec: 13177.883789\n",
      "\n",
      "Epoch Step: 801 Loss: 1.251482 Tokens per Sec: 13332.678711\n",
      "\n",
      "Epoch Step: 851 Loss: 1.361524 Tokens per Sec: 12642.477539\n",
      "\n",
      "Epoch Step: 901 Loss: 1.400322 Tokens per Sec: 13322.348633\n",
      "\n",
      "Epoch Step: 951 Loss: 1.094640 Tokens per Sec: 13409.326172\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.179961 Tokens per Sec: 13621.850586\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.109546 Tokens per Sec: 13250.499023\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.124241 Tokens per Sec: 13094.782227\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.387205 Tokens per Sec: 13232.361328\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.282000 Tokens per Sec: 12775.831055\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.238650 Tokens per Sec: 13290.631836\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.716107 Tokens per Sec: 13564.764648\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.449178 Tokens per Sec: 12806.955078\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.184908 Tokens per Sec: 13236.479492\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.091920 Tokens per Sec: 12836.111328\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.128686 Tokens per Sec: 13130.620117\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.504860 Tokens per Sec: 12840.466797\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.425907 Tokens per Sec: 13315.410156\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.461052 Tokens per Sec: 13246.158203\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.072764 Tokens per Sec: 13486.003906\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.331990 Tokens per Sec: 13353.750977\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.372262 Tokens per Sec: 13220.869141\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.392848 Tokens per Sec: 12987.778320\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.077140 Tokens per Sec: 13115.314453\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.242757 Tokens per Sec: 13440.405273\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.418684 Tokens per Sec: 13259.070312\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.538598 Tokens per Sec: 12819.924805\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.231879 Tokens per Sec: 13289.445312\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.518059 Tokens per Sec: 13131.265625\n",
      "\n",
      "Epoch Step: 1 Loss: 0.718319 Tokens per Sec: 11077.625000\n",
      "\n",
      "tensor(0.8382, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.338511 Tokens per Sec: 2515.501465\n",
      "\n",
      "Epoch Step: 51 Loss: 1.141301 Tokens per Sec: 13426.416992\n",
      "\n",
      "Epoch Step: 101 Loss: 1.140306 Tokens per Sec: 13104.623047\n",
      "\n",
      "Epoch Step: 151 Loss: 1.356690 Tokens per Sec: 13217.686523\n",
      "\n",
      "Epoch Step: 201 Loss: 1.223300 Tokens per Sec: 13290.569336\n",
      "\n",
      "Epoch Step: 251 Loss: 0.971792 Tokens per Sec: 12995.200195\n",
      "\n",
      "Epoch Step: 301 Loss: 1.386197 Tokens per Sec: 13419.563477\n",
      "\n",
      "Epoch Step: 351 Loss: 0.964081 Tokens per Sec: 13903.285156\n",
      "\n",
      "Epoch Step: 401 Loss: 1.279150 Tokens per Sec: 13337.123047\n",
      "\n",
      "Epoch Step: 451 Loss: 1.074026 Tokens per Sec: 12682.089844\n",
      "\n",
      "Epoch Step: 501 Loss: 1.057512 Tokens per Sec: 12697.208984\n",
      "\n",
      "Epoch Step: 551 Loss: 1.373828 Tokens per Sec: 12685.974609\n",
      "\n",
      "Epoch Step: 601 Loss: 1.268438 Tokens per Sec: 13408.649414\n",
      "\n",
      "Epoch Step: 651 Loss: 1.329634 Tokens per Sec: 13598.952148\n",
      "\n",
      "Epoch Step: 701 Loss: 1.121770 Tokens per Sec: 13893.734375\n",
      "\n",
      "Epoch Step: 751 Loss: 1.618535 Tokens per Sec: 14040.041992\n",
      "\n",
      "Epoch Step: 801 Loss: 1.225991 Tokens per Sec: 13932.807617\n",
      "\n",
      "Epoch Step: 851 Loss: 1.121989 Tokens per Sec: 13856.515625\n",
      "\n",
      "Epoch Step: 901 Loss: 1.151735 Tokens per Sec: 13367.250000\n",
      "\n",
      "Epoch Step: 951 Loss: 1.289713 Tokens per Sec: 13109.528320\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.433209 Tokens per Sec: 13352.051758\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.332992 Tokens per Sec: 13538.275391\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.575268 Tokens per Sec: 13226.818359\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.633648 Tokens per Sec: 13174.838867\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.178689 Tokens per Sec: 12783.156250\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.467193 Tokens per Sec: 13271.991211\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.368681 Tokens per Sec: 12767.904297\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.415504 Tokens per Sec: 13585.476562\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.244163 Tokens per Sec: 13157.052734\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.354074 Tokens per Sec: 13581.823242\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.387297 Tokens per Sec: 13174.808594\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.373883 Tokens per Sec: 13630.403320\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.243095 Tokens per Sec: 13265.627930\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.125752 Tokens per Sec: 13428.161133\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.490684 Tokens per Sec: 13486.825195\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.067699 Tokens per Sec: 13226.884766\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.233809 Tokens per Sec: 12949.402344\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.400479 Tokens per Sec: 13266.248047\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.663331 Tokens per Sec: 13332.625977\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.532089 Tokens per Sec: 13219.636719\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.449616 Tokens per Sec: 12813.946289\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.356489 Tokens per Sec: 13377.473633\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.053728 Tokens per Sec: 13671.400391\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.126855 Tokens per Sec: 13259.461914\n",
      "\n",
      "Epoch Step: 1 Loss: 0.701135 Tokens per Sec: 11325.935547\n",
      "\n",
      "tensor(0.8266, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.285765 Tokens per Sec: 2792.616455\n",
      "\n",
      "Epoch Step: 51 Loss: 1.052122 Tokens per Sec: 13171.422852\n",
      "\n",
      "Epoch Step: 101 Loss: 1.069476 Tokens per Sec: 13252.007812\n",
      "\n",
      "Epoch Step: 151 Loss: 1.176064 Tokens per Sec: 13302.484375\n",
      "\n",
      "Epoch Step: 201 Loss: 0.945471 Tokens per Sec: 13038.430664\n",
      "\n",
      "Epoch Step: 251 Loss: 1.402963 Tokens per Sec: 13362.349609\n",
      "\n",
      "Epoch Step: 301 Loss: 1.480789 Tokens per Sec: 13161.571289\n",
      "\n",
      "Epoch Step: 351 Loss: 1.232542 Tokens per Sec: 13066.554688\n",
      "\n",
      "Epoch Step: 401 Loss: 1.584619 Tokens per Sec: 13394.023438\n",
      "\n",
      "Epoch Step: 451 Loss: 1.336904 Tokens per Sec: 13361.837891\n",
      "\n",
      "Epoch Step: 501 Loss: 1.055664 Tokens per Sec: 13207.114258\n",
      "\n",
      "Epoch Step: 551 Loss: 0.996477 Tokens per Sec: 13426.712891\n",
      "\n",
      "Epoch Step: 601 Loss: 1.264432 Tokens per Sec: 12953.087891\n",
      "\n",
      "Epoch Step: 651 Loss: 0.971846 Tokens per Sec: 12548.510742\n",
      "\n",
      "Epoch Step: 701 Loss: 1.164208 Tokens per Sec: 12601.202148\n",
      "\n",
      "Epoch Step: 751 Loss: 1.263208 Tokens per Sec: 12826.280273\n",
      "\n",
      "Epoch Step: 801 Loss: 0.993225 Tokens per Sec: 13532.727539\n",
      "\n",
      "Epoch Step: 851 Loss: 1.168126 Tokens per Sec: 13625.916992\n",
      "\n",
      "Epoch Step: 901 Loss: 1.248682 Tokens per Sec: 13516.872070\n",
      "\n",
      "Epoch Step: 951 Loss: 1.107674 Tokens per Sec: 13801.719727\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.278851 Tokens per Sec: 13820.976562\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.344181 Tokens per Sec: 13558.251953\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.331929 Tokens per Sec: 13485.487305\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.186630 Tokens per Sec: 12713.740234\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.543318 Tokens per Sec: 13088.273438\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.150660 Tokens per Sec: 13353.487305\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.082739 Tokens per Sec: 13370.156250\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.219602 Tokens per Sec: 12949.540039\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.328978 Tokens per Sec: 12704.239258\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.276340 Tokens per Sec: 13001.237305\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.454156 Tokens per Sec: 13033.139648\n",
      "\n",
      "Epoch Step: 1551 Loss: 0.969031 Tokens per Sec: 13385.038086\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.739780 Tokens per Sec: 13435.768555\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.058026 Tokens per Sec: 13446.129883\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.186275 Tokens per Sec: 13126.319336\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.367167 Tokens per Sec: 13142.500977\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.099624 Tokens per Sec: 13113.896484\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.043375 Tokens per Sec: 13190.875977\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.167961 Tokens per Sec: 13251.677734\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.464323 Tokens per Sec: 13606.221680\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.238604 Tokens per Sec: 13278.696289\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.576608 Tokens per Sec: 13372.046875\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.174147 Tokens per Sec: 13345.142578\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.485559 Tokens per Sec: 13084.191406\n",
      "\n",
      "Epoch Step: 1 Loss: 0.709830 Tokens per Sec: 10839.543945\n",
      "\n",
      "tensor(0.8201, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.139203 Tokens per Sec: 2128.596191\n",
      "\n",
      "Epoch Step: 51 Loss: 1.122139 Tokens per Sec: 13012.134766\n",
      "\n",
      "Epoch Step: 101 Loss: 1.081805 Tokens per Sec: 13012.311523\n",
      "\n",
      "Epoch Step: 151 Loss: 0.992217 Tokens per Sec: 12414.543945\n",
      "\n",
      "Epoch Step: 201 Loss: 1.271383 Tokens per Sec: 13247.314453\n",
      "\n",
      "Epoch Step: 251 Loss: 1.324009 Tokens per Sec: 13450.135742\n",
      "\n",
      "Epoch Step: 301 Loss: 1.242359 Tokens per Sec: 13393.063477\n",
      "\n",
      "Epoch Step: 351 Loss: 1.184370 Tokens per Sec: 13451.087891\n",
      "\n",
      "Epoch Step: 401 Loss: 1.268217 Tokens per Sec: 12942.129883\n",
      "\n",
      "Epoch Step: 451 Loss: 1.419835 Tokens per Sec: 13469.741211\n",
      "\n",
      "Epoch Step: 501 Loss: 1.257702 Tokens per Sec: 12912.885742\n",
      "\n",
      "Epoch Step: 551 Loss: 1.135787 Tokens per Sec: 13302.813477\n",
      "\n",
      "Epoch Step: 601 Loss: 1.268393 Tokens per Sec: 13336.852539\n",
      "\n",
      "Epoch Step: 651 Loss: 1.004421 Tokens per Sec: 12718.549805\n",
      "\n",
      "Epoch Step: 701 Loss: 1.403241 Tokens per Sec: 13550.924805\n",
      "\n",
      "Epoch Step: 751 Loss: 1.200874 Tokens per Sec: 13741.668945\n",
      "\n",
      "Epoch Step: 801 Loss: 1.260398 Tokens per Sec: 12894.243164\n",
      "\n",
      "Epoch Step: 851 Loss: 1.345246 Tokens per Sec: 12654.128906\n",
      "\n",
      "Epoch Step: 901 Loss: 1.223573 Tokens per Sec: 12366.526367\n",
      "\n",
      "Epoch Step: 951 Loss: 1.192434 Tokens per Sec: 13853.659180\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.262967 Tokens per Sec: 13612.541992\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.470919 Tokens per Sec: 13862.384766\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.341595 Tokens per Sec: 12718.578125\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.529202 Tokens per Sec: 13518.418945\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.419600 Tokens per Sec: 13737.341797\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.185938 Tokens per Sec: 13109.885742\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.070632 Tokens per Sec: 13102.789062\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.382335 Tokens per Sec: 13406.789062\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.066959 Tokens per Sec: 12689.887695\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.310415 Tokens per Sec: 12988.141602\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.437666 Tokens per Sec: 13325.945312\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.236359 Tokens per Sec: 13437.683594\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.152682 Tokens per Sec: 13567.783203\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.093281 Tokens per Sec: 13373.066406\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.300752 Tokens per Sec: 13417.151367\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.084119 Tokens per Sec: 13078.036133\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.304089 Tokens per Sec: 13060.927734\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.274747 Tokens per Sec: 13177.393555\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.279698 Tokens per Sec: 12998.875977\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.147091 Tokens per Sec: 13278.018555\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.410713 Tokens per Sec: 13131.384766\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.127695 Tokens per Sec: 12711.091797\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.338549 Tokens per Sec: 13439.083008\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.390265 Tokens per Sec: 13380.373047\n",
      "\n",
      "Epoch Step: 1 Loss: 0.663426 Tokens per Sec: 11001.614258\n",
      "\n",
      "tensor(0.8015, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.140682 Tokens per Sec: 3057.213135\n",
      "\n",
      "Epoch Step: 51 Loss: 0.972803 Tokens per Sec: 12956.282227\n",
      "\n",
      "Epoch Step: 101 Loss: 0.969436 Tokens per Sec: 13433.666016\n",
      "\n",
      "Epoch Step: 151 Loss: 1.309694 Tokens per Sec: 13422.471680\n",
      "\n",
      "Epoch Step: 201 Loss: 1.291789 Tokens per Sec: 12869.244141\n",
      "\n",
      "Epoch Step: 251 Loss: 1.047208 Tokens per Sec: 12881.548828\n",
      "\n",
      "Epoch Step: 301 Loss: 1.392021 Tokens per Sec: 13189.291016\n",
      "\n",
      "Epoch Step: 351 Loss: 0.974503 Tokens per Sec: 13322.668945\n",
      "\n",
      "Epoch Step: 401 Loss: 1.245173 Tokens per Sec: 13159.384766\n",
      "\n",
      "Epoch Step: 451 Loss: 1.330509 Tokens per Sec: 13420.913086\n",
      "\n",
      "Epoch Step: 501 Loss: 1.062191 Tokens per Sec: 13128.901367\n",
      "\n",
      "Epoch Step: 551 Loss: 1.201671 Tokens per Sec: 12817.428711\n",
      "\n",
      "Epoch Step: 601 Loss: 1.195451 Tokens per Sec: 13079.779297\n",
      "\n",
      "Epoch Step: 651 Loss: 1.261855 Tokens per Sec: 13330.875977\n",
      "\n",
      "Epoch Step: 701 Loss: 1.524463 Tokens per Sec: 13414.126953\n",
      "\n",
      "Epoch Step: 751 Loss: 1.156444 Tokens per Sec: 13388.012695\n",
      "\n",
      "Epoch Step: 801 Loss: 1.230166 Tokens per Sec: 13104.744141\n",
      "\n",
      "Epoch Step: 851 Loss: 1.076221 Tokens per Sec: 13338.686523\n",
      "\n",
      "Epoch Step: 901 Loss: 1.410019 Tokens per Sec: 13369.879883\n",
      "\n",
      "Epoch Step: 951 Loss: 1.418577 Tokens per Sec: 12564.929688\n",
      "\n",
      "Epoch Step: 1001 Loss: 0.937054 Tokens per Sec: 12651.696289\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.042922 Tokens per Sec: 12549.595703\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.565152 Tokens per Sec: 13527.899414\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.598757 Tokens per Sec: 13863.136719\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.206673 Tokens per Sec: 13801.302734\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.216650 Tokens per Sec: 13891.881836\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.208319 Tokens per Sec: 13557.632812\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.143016 Tokens per Sec: 13675.556641\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.477589 Tokens per Sec: 14223.390625\n",
      "\n",
      "Epoch Step: 1451 Loss: 0.924026 Tokens per Sec: 13647.422852\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.005825 Tokens per Sec: 13372.486328\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.533162 Tokens per Sec: 13159.977539\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.350863 Tokens per Sec: 13276.003906\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.565454 Tokens per Sec: 12807.347656\n",
      "\n",
      "Epoch Step: 1701 Loss: 0.949131 Tokens per Sec: 13133.899414\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.262771 Tokens per Sec: 13091.287109\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.046629 Tokens per Sec: 13462.675781\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.200279 Tokens per Sec: 13182.997070\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.057140 Tokens per Sec: 12874.325195\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.229312 Tokens per Sec: 13342.641602\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.476024 Tokens per Sec: 13263.422852\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.102143 Tokens per Sec: 13327.169922\n",
      "\n",
      "Epoch Step: 2101 Loss: 0.697855 Tokens per Sec: 13413.279297\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.281848 Tokens per Sec: 13342.516602\n",
      "\n",
      "Epoch Step: 1 Loss: 0.666596 Tokens per Sec: 11085.224609\n",
      "\n",
      "tensor(0.7833, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.091766 Tokens per Sec: 2895.278076\n",
      "\n",
      "Epoch Step: 51 Loss: 1.463565 Tokens per Sec: 13503.739258\n",
      "\n",
      "Epoch Step: 101 Loss: 0.953823 Tokens per Sec: 13210.626953\n",
      "\n",
      "Epoch Step: 151 Loss: 1.221088 Tokens per Sec: 13017.256836\n",
      "\n",
      "Epoch Step: 201 Loss: 1.265795 Tokens per Sec: 12967.690430\n",
      "\n",
      "Epoch Step: 251 Loss: 1.068317 Tokens per Sec: 13149.839844\n",
      "\n",
      "Epoch Step: 301 Loss: 1.292029 Tokens per Sec: 13430.936523\n",
      "\n",
      "Epoch Step: 351 Loss: 0.934976 Tokens per Sec: 13363.847656\n",
      "\n",
      "Epoch Step: 401 Loss: 0.884391 Tokens per Sec: 13211.787109\n",
      "\n",
      "Epoch Step: 451 Loss: 1.311806 Tokens per Sec: 13551.638672\n",
      "\n",
      "Epoch Step: 501 Loss: 0.947065 Tokens per Sec: 13568.247070\n",
      "\n",
      "Epoch Step: 551 Loss: 1.216078 Tokens per Sec: 13558.478516\n",
      "\n",
      "Epoch Step: 601 Loss: 0.950360 Tokens per Sec: 13208.890625\n",
      "\n",
      "Epoch Step: 651 Loss: 1.494959 Tokens per Sec: 13282.662109\n",
      "\n",
      "Epoch Step: 701 Loss: 1.207171 Tokens per Sec: 13490.430664\n",
      "\n",
      "Epoch Step: 751 Loss: 1.312551 Tokens per Sec: 13082.679688\n",
      "\n",
      "Epoch Step: 801 Loss: 1.047607 Tokens per Sec: 13482.996094\n",
      "\n",
      "Epoch Step: 851 Loss: 1.124193 Tokens per Sec: 13230.125000\n",
      "\n",
      "Epoch Step: 901 Loss: 1.258281 Tokens per Sec: 13153.031250\n",
      "\n",
      "Epoch Step: 951 Loss: 1.163093 Tokens per Sec: 13049.118164\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.432997 Tokens per Sec: 13073.972656\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.081177 Tokens per Sec: 13477.988281\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.359794 Tokens per Sec: 13353.838867\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.513937 Tokens per Sec: 12807.666016\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.256884 Tokens per Sec: 11906.369141\n",
      "\n",
      "Epoch Step: 1251 Loss: 0.986441 Tokens per Sec: 12413.402344\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.311289 Tokens per Sec: 13156.998047\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.454859 Tokens per Sec: 13012.165039\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.668479 Tokens per Sec: 13673.164062\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.110168 Tokens per Sec: 13832.078125\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.216067 Tokens per Sec: 13910.320312\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.253212 Tokens per Sec: 12697.486328\n",
      "\n",
      "Epoch Step: 1601 Loss: 0.972212 Tokens per Sec: 12814.358398\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.346879 Tokens per Sec: 13492.324219\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.422275 Tokens per Sec: 13104.789062\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.343675 Tokens per Sec: 13165.033203\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.021506 Tokens per Sec: 13398.390625\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.376817 Tokens per Sec: 13329.003906\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.499153 Tokens per Sec: 12994.233398\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.218421 Tokens per Sec: 13066.685547\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.334681 Tokens per Sec: 12961.311523\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.293648 Tokens per Sec: 13018.092773\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.418577 Tokens per Sec: 13241.518555\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.264731 Tokens per Sec: 13434.684570\n",
      "\n",
      "Epoch Step: 1 Loss: 0.657012 Tokens per Sec: 11472.248047\n",
      "\n",
      "tensor(0.7936, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.097734 Tokens per Sec: 2578.658691\n",
      "\n",
      "Epoch Step: 51 Loss: 1.283025 Tokens per Sec: 12956.208984\n",
      "\n",
      "Epoch Step: 101 Loss: 1.434146 Tokens per Sec: 13731.977539\n",
      "\n",
      "Epoch Step: 151 Loss: 1.034408 Tokens per Sec: 13394.676758\n",
      "\n",
      "Epoch Step: 201 Loss: 1.102497 Tokens per Sec: 13465.434570\n",
      "\n",
      "Epoch Step: 251 Loss: 1.093067 Tokens per Sec: 12716.869141\n",
      "\n",
      "Epoch Step: 301 Loss: 1.179286 Tokens per Sec: 13415.517578\n",
      "\n",
      "Epoch Step: 351 Loss: 1.366369 Tokens per Sec: 12807.342773\n",
      "\n",
      "Epoch Step: 401 Loss: 1.201698 Tokens per Sec: 12683.666992\n",
      "\n",
      "Epoch Step: 451 Loss: 1.297667 Tokens per Sec: 12968.708984\n",
      "\n",
      "Epoch Step: 501 Loss: 0.973541 Tokens per Sec: 13578.177734\n",
      "\n",
      "Epoch Step: 551 Loss: 0.962959 Tokens per Sec: 13125.588867\n",
      "\n",
      "Epoch Step: 601 Loss: 1.166910 Tokens per Sec: 13604.728516\n",
      "\n",
      "Epoch Step: 651 Loss: 1.269340 Tokens per Sec: 13058.736328\n",
      "\n",
      "Epoch Step: 701 Loss: 1.070925 Tokens per Sec: 13344.730469\n",
      "\n",
      "Epoch Step: 751 Loss: 1.275160 Tokens per Sec: 13114.250000\n",
      "\n",
      "Epoch Step: 801 Loss: 1.510221 Tokens per Sec: 13170.123047\n",
      "\n",
      "Epoch Step: 851 Loss: 1.148137 Tokens per Sec: 12856.829102\n",
      "\n",
      "Epoch Step: 901 Loss: 1.287764 Tokens per Sec: 13026.017578\n",
      "\n",
      "Epoch Step: 951 Loss: 0.931306 Tokens per Sec: 12854.149414\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.370003 Tokens per Sec: 13583.437500\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.168883 Tokens per Sec: 13554.896484\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.269590 Tokens per Sec: 13477.824219\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.184223 Tokens per Sec: 13390.602539\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.368561 Tokens per Sec: 13532.791992\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.604383 Tokens per Sec: 13727.379883\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.542549 Tokens per Sec: 12644.386719\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.200751 Tokens per Sec: 12605.375977\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.117167 Tokens per Sec: 12820.373047\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.197369 Tokens per Sec: 13141.823242\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.372055 Tokens per Sec: 13429.622070\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.363611 Tokens per Sec: 13894.666016\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.106211 Tokens per Sec: 13633.055664\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.355725 Tokens per Sec: 13869.525391\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.324724 Tokens per Sec: 13983.211914\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.308892 Tokens per Sec: 13347.965820\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.137346 Tokens per Sec: 13215.408203\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.326600 Tokens per Sec: 13489.675781\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.079311 Tokens per Sec: 13089.462891\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.396948 Tokens per Sec: 13295.832031\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.145058 Tokens per Sec: 13085.506836\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.712078 Tokens per Sec: 13355.477539\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.204943 Tokens per Sec: 13464.881836\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.390796 Tokens per Sec: 13520.181641\n",
      "\n",
      "Epoch Step: 1 Loss: 0.645614 Tokens per Sec: 10826.440430\n",
      "\n",
      "tensor(0.7616, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 0.899961 Tokens per Sec: 1991.702026\n",
      "\n",
      "Epoch Step: 51 Loss: 1.125800 Tokens per Sec: 13215.887695\n",
      "\n",
      "Epoch Step: 101 Loss: 1.060079 Tokens per Sec: 13504.696289\n",
      "\n",
      "Epoch Step: 151 Loss: 1.351997 Tokens per Sec: 13317.059570\n",
      "\n",
      "Epoch Step: 201 Loss: 1.378307 Tokens per Sec: 13344.367188\n",
      "\n",
      "Epoch Step: 251 Loss: 1.327375 Tokens per Sec: 13074.028320\n",
      "\n",
      "Epoch Step: 301 Loss: 1.209124 Tokens per Sec: 13128.236328\n",
      "\n",
      "Epoch Step: 351 Loss: 1.218678 Tokens per Sec: 12321.107422\n",
      "\n",
      "Epoch Step: 401 Loss: 1.250479 Tokens per Sec: 13241.154297\n",
      "\n",
      "Epoch Step: 451 Loss: 1.117686 Tokens per Sec: 13299.077148\n",
      "\n",
      "Epoch Step: 501 Loss: 1.042098 Tokens per Sec: 12972.357422\n",
      "\n",
      "Epoch Step: 551 Loss: 1.525819 Tokens per Sec: 13597.856445\n",
      "\n",
      "Epoch Step: 601 Loss: 1.188615 Tokens per Sec: 13370.791992\n",
      "\n",
      "Epoch Step: 651 Loss: 1.232050 Tokens per Sec: 13386.415039\n",
      "\n",
      "Epoch Step: 701 Loss: 0.877716 Tokens per Sec: 12733.469727\n",
      "\n",
      "Epoch Step: 751 Loss: 1.292508 Tokens per Sec: 13393.273438\n",
      "\n",
      "Epoch Step: 801 Loss: 1.227339 Tokens per Sec: 13337.363281\n",
      "\n",
      "Epoch Step: 851 Loss: 1.189817 Tokens per Sec: 13234.290039\n",
      "\n",
      "Epoch Step: 901 Loss: 1.114146 Tokens per Sec: 13437.218750\n",
      "\n",
      "Epoch Step: 951 Loss: 1.279057 Tokens per Sec: 13471.785156\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.222728 Tokens per Sec: 13249.916992\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.363306 Tokens per Sec: 13669.223633\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.212028 Tokens per Sec: 13340.148438\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.441511 Tokens per Sec: 13119.636719\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.470965 Tokens per Sec: 13225.208984\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.341058 Tokens per Sec: 13154.221680\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.104339 Tokens per Sec: 12994.891602\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.376102 Tokens per Sec: 13143.933594\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.343177 Tokens per Sec: 13771.819336\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.292900 Tokens per Sec: 13691.159180\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.220424 Tokens per Sec: 12767.703125\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.098563 Tokens per Sec: 12770.381836\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.100065 Tokens per Sec: 12601.190430\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.480375 Tokens per Sec: 13368.649414\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.200473 Tokens per Sec: 13166.791016\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.475992 Tokens per Sec: 14103.197266\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.234560 Tokens per Sec: 13933.952148\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.287505 Tokens per Sec: 14191.295898\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.071882 Tokens per Sec: 14085.144531\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.402900 Tokens per Sec: 14005.464844\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.248687 Tokens per Sec: 13336.487305\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.040666 Tokens per Sec: 13434.037109\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.319563 Tokens per Sec: 13176.282227\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.436033 Tokens per Sec: 13120.836914\n",
      "\n",
      "Epoch Step: 1 Loss: 0.660038 Tokens per Sec: 10952.218750\n",
      "\n",
      "tensor(0.7636, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 0.938624 Tokens per Sec: 2543.124023\n",
      "\n",
      "Epoch Step: 51 Loss: 1.031528 Tokens per Sec: 13219.259766\n",
      "\n",
      "Epoch Step: 101 Loss: 1.257110 Tokens per Sec: 13210.622070\n",
      "\n",
      "Epoch Step: 151 Loss: 1.271348 Tokens per Sec: 13268.110352\n",
      "\n",
      "Epoch Step: 201 Loss: 1.235145 Tokens per Sec: 13125.516602\n",
      "\n",
      "Epoch Step: 251 Loss: 1.260366 Tokens per Sec: 12727.718750\n",
      "\n",
      "Epoch Step: 301 Loss: 1.125565 Tokens per Sec: 13405.957031\n",
      "\n",
      "Epoch Step: 351 Loss: 1.274945 Tokens per Sec: 13117.729492\n",
      "\n",
      "Epoch Step: 401 Loss: 1.222964 Tokens per Sec: 13561.301758\n",
      "\n",
      "Epoch Step: 451 Loss: 1.151527 Tokens per Sec: 12956.650391\n",
      "\n",
      "Epoch Step: 501 Loss: 0.978756 Tokens per Sec: 13168.861328\n",
      "\n",
      "Epoch Step: 551 Loss: 1.177109 Tokens per Sec: 13432.622070\n",
      "\n",
      "Epoch Step: 601 Loss: 1.400003 Tokens per Sec: 13604.445312\n",
      "\n",
      "Epoch Step: 651 Loss: 1.107105 Tokens per Sec: 13458.749023\n",
      "\n",
      "Epoch Step: 701 Loss: 1.040861 Tokens per Sec: 13115.892578\n",
      "\n",
      "Epoch Step: 751 Loss: 0.771837 Tokens per Sec: 13051.747070\n",
      "\n",
      "Epoch Step: 801 Loss: 1.210219 Tokens per Sec: 13245.904297\n",
      "\n",
      "Epoch Step: 851 Loss: 1.128845 Tokens per Sec: 13109.262695\n",
      "\n",
      "Epoch Step: 901 Loss: 1.266696 Tokens per Sec: 13259.089844\n",
      "\n",
      "Epoch Step: 951 Loss: 1.115287 Tokens per Sec: 13412.358398\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.183854 Tokens per Sec: 12807.732422\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.294663 Tokens per Sec: 13589.286133\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.152981 Tokens per Sec: 13365.644531\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.425348 Tokens per Sec: 13112.060547\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.593981 Tokens per Sec: 13335.262695\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.224465 Tokens per Sec: 13747.834961\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.269898 Tokens per Sec: 13246.932617\n",
      "\n",
      "Epoch Step: 1351 Loss: 0.912424 Tokens per Sec: 13278.783203\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.212113 Tokens per Sec: 13337.387695\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.231404 Tokens per Sec: 12994.495117\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.183301 Tokens per Sec: 13347.901367\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.496246 Tokens per Sec: 12951.164062\n",
      "\n",
      "Epoch Step: 1601 Loss: 0.995075 Tokens per Sec: 13570.879883\n",
      "\n",
      "Epoch Step: 1651 Loss: 0.751087 Tokens per Sec: 12960.442383\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.341145 Tokens per Sec: 12715.257812\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.333701 Tokens per Sec: 12399.576172\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.198413 Tokens per Sec: 12371.595703\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.168516 Tokens per Sec: 13592.617188\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.624187 Tokens per Sec: 13672.524414\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.478290 Tokens per Sec: 13730.760742\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.235546 Tokens per Sec: 12892.083008\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.336209 Tokens per Sec: 13732.747070\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.175297 Tokens per Sec: 13986.172852\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.026287 Tokens per Sec: 13743.641602\n",
      "\n",
      "Epoch Step: 1 Loss: 0.617029 Tokens per Sec: 10511.710938\n",
      "\n",
      "tensor(0.7413, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 0.925072 Tokens per Sec: 2446.313232\n",
      "\n",
      "Epoch Step: 51 Loss: 0.968748 Tokens per Sec: 13006.250977\n",
      "\n",
      "Epoch Step: 101 Loss: 0.898639 Tokens per Sec: 13257.686523\n",
      "\n",
      "Epoch Step: 151 Loss: 1.201453 Tokens per Sec: 13149.453125\n",
      "\n",
      "Epoch Step: 201 Loss: 1.339928 Tokens per Sec: 12859.404297\n",
      "\n",
      "Epoch Step: 251 Loss: 1.004087 Tokens per Sec: 13301.092773\n",
      "\n",
      "Epoch Step: 301 Loss: 1.166290 Tokens per Sec: 13172.644531\n",
      "\n",
      "Epoch Step: 351 Loss: 1.305963 Tokens per Sec: 13165.487305\n",
      "\n",
      "Epoch Step: 401 Loss: 1.090404 Tokens per Sec: 13244.556641\n",
      "\n",
      "Epoch Step: 451 Loss: 1.446635 Tokens per Sec: 13388.519531\n",
      "\n",
      "Epoch Step: 501 Loss: 1.150920 Tokens per Sec: 13485.519531\n",
      "\n",
      "Epoch Step: 551 Loss: 1.082563 Tokens per Sec: 13261.593750\n",
      "\n",
      "Epoch Step: 601 Loss: 1.432042 Tokens per Sec: 13299.143555\n",
      "\n",
      "Epoch Step: 651 Loss: 1.108888 Tokens per Sec: 13623.856445\n",
      "\n",
      "Epoch Step: 701 Loss: 0.968049 Tokens per Sec: 13044.200195\n",
      "\n",
      "Epoch Step: 751 Loss: 1.120059 Tokens per Sec: 12906.506836\n",
      "\n",
      "Epoch Step: 801 Loss: 1.220737 Tokens per Sec: 13098.015625\n",
      "\n",
      "Epoch Step: 851 Loss: 1.413376 Tokens per Sec: 13068.929688\n",
      "\n",
      "Epoch Step: 901 Loss: 1.453999 Tokens per Sec: 13276.043945\n",
      "\n",
      "Epoch Step: 951 Loss: 1.376186 Tokens per Sec: 13494.432617\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.127010 Tokens per Sec: 13330.621094\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.415211 Tokens per Sec: 13239.081055\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.200319 Tokens per Sec: 13175.012695\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.101002 Tokens per Sec: 13176.102539\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.612670 Tokens per Sec: 13321.599609\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.131049 Tokens per Sec: 13485.526367\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.232263 Tokens per Sec: 13343.542969\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.130330 Tokens per Sec: 12819.142578\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.218189 Tokens per Sec: 13146.928711\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.011059 Tokens per Sec: 13251.124023\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.546059 Tokens per Sec: 13446.518555\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.607125 Tokens per Sec: 13390.926758\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.221586 Tokens per Sec: 13415.535156\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.018005 Tokens per Sec: 13346.607422\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.191100 Tokens per Sec: 13611.781250\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.115232 Tokens per Sec: 13310.797852\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.116267 Tokens per Sec: 13291.695312\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.309592 Tokens per Sec: 12213.695312\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.067022 Tokens per Sec: 12527.356445\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.395081 Tokens per Sec: 12839.975586\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.308729 Tokens per Sec: 13134.200195\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.452229 Tokens per Sec: 13599.740234\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.007146 Tokens per Sec: 13558.667969\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.534490 Tokens per Sec: 13651.149414\n",
      "\n",
      "Epoch Step: 1 Loss: 0.618344 Tokens per Sec: 11602.114258\n",
      "\n",
      "tensor(0.7247, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.252202 Tokens per Sec: 2420.052490\n",
      "\n",
      "Epoch Step: 51 Loss: 1.295913 Tokens per Sec: 13838.369141\n",
      "\n",
      "Epoch Step: 101 Loss: 0.912335 Tokens per Sec: 13481.534180\n",
      "\n",
      "Epoch Step: 151 Loss: 1.062867 Tokens per Sec: 13443.260742\n",
      "\n",
      "Epoch Step: 201 Loss: 1.140483 Tokens per Sec: 13320.990234\n",
      "\n",
      "Epoch Step: 251 Loss: 1.178916 Tokens per Sec: 13247.525391\n",
      "\n",
      "Epoch Step: 301 Loss: 1.067131 Tokens per Sec: 13006.925781\n",
      "\n",
      "Epoch Step: 351 Loss: 0.771195 Tokens per Sec: 13081.872070\n",
      "\n",
      "Epoch Step: 401 Loss: 1.186664 Tokens per Sec: 13142.324219\n",
      "\n",
      "Epoch Step: 451 Loss: 1.163784 Tokens per Sec: 13508.911133\n",
      "\n",
      "Epoch Step: 501 Loss: 1.209279 Tokens per Sec: 13384.032227\n",
      "\n",
      "Epoch Step: 551 Loss: 1.131176 Tokens per Sec: 13669.974609\n",
      "\n",
      "Epoch Step: 601 Loss: 1.010864 Tokens per Sec: 13665.008789\n",
      "\n",
      "Epoch Step: 651 Loss: 0.992114 Tokens per Sec: 13404.292969\n",
      "\n",
      "Epoch Step: 701 Loss: 1.172746 Tokens per Sec: 13393.109375\n",
      "\n",
      "Epoch Step: 751 Loss: 1.096364 Tokens per Sec: 12311.747070\n",
      "\n",
      "Epoch Step: 801 Loss: 1.039508 Tokens per Sec: 13583.794922\n",
      "\n",
      "Epoch Step: 851 Loss: 1.202113 Tokens per Sec: 13486.388672\n",
      "\n",
      "Epoch Step: 901 Loss: 1.316744 Tokens per Sec: 13080.477539\n",
      "\n",
      "Epoch Step: 951 Loss: 1.257200 Tokens per Sec: 12626.631836\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.152472 Tokens per Sec: 12954.523438\n",
      "\n",
      "Epoch Step: 1051 Loss: 0.966597 Tokens per Sec: 13284.595703\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.303084 Tokens per Sec: 13663.217773\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.367794 Tokens per Sec: 13308.892578\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.159154 Tokens per Sec: 13339.083008\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.241728 Tokens per Sec: 13535.746094\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.484055 Tokens per Sec: 13500.456055\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.258814 Tokens per Sec: 13561.964844\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.327416 Tokens per Sec: 13387.539062\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.267423 Tokens per Sec: 13278.702148\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.175726 Tokens per Sec: 12981.186523\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.585896 Tokens per Sec: 13200.622070\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.274301 Tokens per Sec: 13254.093750\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.186346 Tokens per Sec: 13263.467773\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.156298 Tokens per Sec: 13537.504883\n",
      "\n",
      "Epoch Step: 1751 Loss: 0.941855 Tokens per Sec: 13111.223633\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.393416 Tokens per Sec: 13049.903320\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.054314 Tokens per Sec: 12924.076172\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.010376 Tokens per Sec: 13036.184570\n",
      "\n",
      "Epoch Step: 1951 Loss: 0.975459 Tokens per Sec: 13785.805664\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.551285 Tokens per Sec: 12589.018555\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.067646 Tokens per Sec: 13022.214844\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.250058 Tokens per Sec: 12141.790039\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.108065 Tokens per Sec: 12782.646484\n",
      "\n",
      "Epoch Step: 1 Loss: 0.629015 Tokens per Sec: 11837.383789\n",
      "\n",
      "tensor(0.7229, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 0.908058 Tokens per Sec: 2974.918213\n",
      "\n",
      "Epoch Step: 51 Loss: 1.157495 Tokens per Sec: 13788.758789\n",
      "\n",
      "Epoch Step: 101 Loss: 1.132740 Tokens per Sec: 13772.029297\n",
      "\n",
      "Epoch Step: 151 Loss: 0.938084 Tokens per Sec: 14069.416992\n",
      "\n",
      "Epoch Step: 201 Loss: 1.352935 Tokens per Sec: 13672.181641\n",
      "\n",
      "Epoch Step: 251 Loss: 1.088194 Tokens per Sec: 13850.551758\n",
      "\n",
      "Epoch Step: 301 Loss: 1.124815 Tokens per Sec: 13519.941406\n",
      "\n",
      "Epoch Step: 351 Loss: 1.274863 Tokens per Sec: 13207.888672\n",
      "\n",
      "Epoch Step: 401 Loss: 1.452936 Tokens per Sec: 13273.005859\n",
      "\n",
      "Epoch Step: 451 Loss: 1.232067 Tokens per Sec: 13370.901367\n",
      "\n",
      "Epoch Step: 501 Loss: 0.921648 Tokens per Sec: 13309.553711\n",
      "\n",
      "Epoch Step: 551 Loss: 1.465393 Tokens per Sec: 13333.208008\n",
      "\n",
      "Epoch Step: 601 Loss: 0.923974 Tokens per Sec: 13282.023438\n",
      "\n",
      "Epoch Step: 651 Loss: 1.123581 Tokens per Sec: 13820.861328\n",
      "\n",
      "Epoch Step: 701 Loss: 1.297458 Tokens per Sec: 13370.671875\n",
      "\n",
      "Epoch Step: 751 Loss: 1.004068 Tokens per Sec: 13530.695312\n",
      "\n",
      "Epoch Step: 801 Loss: 1.074821 Tokens per Sec: 13078.211914\n",
      "\n",
      "Epoch Step: 851 Loss: 1.306456 Tokens per Sec: 12976.713867\n",
      "\n",
      "Epoch Step: 901 Loss: 1.386887 Tokens per Sec: 12979.916992\n",
      "\n",
      "Epoch Step: 951 Loss: 1.157893 Tokens per Sec: 13328.291016\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.414446 Tokens per Sec: 13382.054688\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.160722 Tokens per Sec: 13210.190430\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.126586 Tokens per Sec: 13306.322266\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.095349 Tokens per Sec: 13264.163086\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.071271 Tokens per Sec: 13064.125000\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.262381 Tokens per Sec: 13457.234375\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.149549 Tokens per Sec: 13062.368164\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.251804 Tokens per Sec: 13093.704102\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.164970 Tokens per Sec: 13258.748047\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.044082 Tokens per Sec: 13113.069336\n",
      "\n",
      "Epoch Step: 1501 Loss: 0.896573 Tokens per Sec: 12895.414062\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.258316 Tokens per Sec: 13017.301758\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.460722 Tokens per Sec: 13284.474609\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.197201 Tokens per Sec: 13300.759766\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.291641 Tokens per Sec: 13369.041016\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.582535 Tokens per Sec: 13422.212891\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.035615 Tokens per Sec: 13266.590820\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.156443 Tokens per Sec: 13250.470703\n",
      "\n",
      "Epoch Step: 1901 Loss: 0.998228 Tokens per Sec: 13281.774414\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.525205 Tokens per Sec: 13383.480469\n",
      "\n",
      "Epoch Step: 2001 Loss: 0.966896 Tokens per Sec: 13026.462891\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.372751 Tokens per Sec: 13084.961914\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.405441 Tokens per Sec: 13175.776367\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.392956 Tokens per Sec: 13262.388672\n",
      "\n",
      "Epoch Step: 1 Loss: 0.622626 Tokens per Sec: 10433.059570\n",
      "\n",
      "tensor(0.7122, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.152433 Tokens per Sec: 2200.716797\n",
      "\n",
      "Epoch Step: 51 Loss: 0.952383 Tokens per Sec: 12547.503906\n",
      "\n",
      "Epoch Step: 101 Loss: 1.219059 Tokens per Sec: 12314.497070\n",
      "\n",
      "Epoch Step: 151 Loss: 0.957643 Tokens per Sec: 13320.245117\n",
      "\n",
      "Epoch Step: 201 Loss: 0.848792 Tokens per Sec: 13027.135742\n",
      "\n",
      "Epoch Step: 251 Loss: 1.085454 Tokens per Sec: 13648.531250\n",
      "\n",
      "Epoch Step: 301 Loss: 0.995909 Tokens per Sec: 13580.808594\n",
      "\n",
      "Epoch Step: 351 Loss: 1.042926 Tokens per Sec: 13624.078125\n",
      "\n",
      "Epoch Step: 401 Loss: 1.078540 Tokens per Sec: 13401.013672\n",
      "\n",
      "Epoch Step: 451 Loss: 1.108305 Tokens per Sec: 13485.013672\n",
      "\n",
      "Epoch Step: 501 Loss: 0.921603 Tokens per Sec: 13505.484375\n",
      "\n",
      "Epoch Step: 551 Loss: 1.294032 Tokens per Sec: 12862.220703\n",
      "\n",
      "Epoch Step: 601 Loss: 1.296229 Tokens per Sec: 13070.085938\n",
      "\n",
      "Epoch Step: 651 Loss: 1.181742 Tokens per Sec: 13053.396484\n",
      "\n",
      "Epoch Step: 701 Loss: 0.932425 Tokens per Sec: 13090.576172\n",
      "\n",
      "Epoch Step: 751 Loss: 1.151891 Tokens per Sec: 13321.630859\n",
      "\n",
      "Epoch Step: 801 Loss: 1.215576 Tokens per Sec: 13189.860352\n",
      "\n",
      "Epoch Step: 851 Loss: 1.231146 Tokens per Sec: 13041.468750\n",
      "\n",
      "Epoch Step: 901 Loss: 0.995682 Tokens per Sec: 13272.903320\n",
      "\n",
      "Epoch Step: 951 Loss: 0.958103 Tokens per Sec: 13100.097656\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.195653 Tokens per Sec: 13027.113281\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.134484 Tokens per Sec: 13219.220703\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.006976 Tokens per Sec: 13447.501953\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.022599 Tokens per Sec: 12529.100586\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.428332 Tokens per Sec: 13205.339844\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.203847 Tokens per Sec: 13449.387695\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.279144 Tokens per Sec: 13351.386719\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.363245 Tokens per Sec: 13341.284180\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.550711 Tokens per Sec: 13357.967773\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.022214 Tokens per Sec: 13414.330078\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.078089 Tokens per Sec: 13480.191406\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.125692 Tokens per Sec: 13454.439453\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.319544 Tokens per Sec: 13028.766602\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.294795 Tokens per Sec: 13012.674805\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.430930 Tokens per Sec: 13584.098633\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.167258 Tokens per Sec: 13149.194336\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.485351 Tokens per Sec: 13280.905273\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.364292 Tokens per Sec: 13294.646484\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.130205 Tokens per Sec: 13022.951172\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.434618 Tokens per Sec: 13409.276367\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.321233 Tokens per Sec: 12936.878906\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.303277 Tokens per Sec: 12830.921875\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.157223 Tokens per Sec: 12705.224609\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.129361 Tokens per Sec: 13308.347656\n",
      "\n",
      "Epoch Step: 1 Loss: 0.600312 Tokens per Sec: 11681.628906\n",
      "\n",
      "tensor(0.7070, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.240362 Tokens per Sec: 2755.311523\n",
      "\n",
      "Epoch Step: 51 Loss: 1.149307 Tokens per Sec: 12835.400391\n",
      "\n",
      "Epoch Step: 101 Loss: 1.081507 Tokens per Sec: 13700.065430\n",
      "\n",
      "Epoch Step: 151 Loss: 1.185364 Tokens per Sec: 13504.593750\n",
      "\n",
      "Epoch Step: 201 Loss: 0.942167 Tokens per Sec: 12295.675781\n",
      "\n",
      "Epoch Step: 251 Loss: 1.195715 Tokens per Sec: 12594.484375\n",
      "\n",
      "Epoch Step: 301 Loss: 0.942963 Tokens per Sec: 12864.946289\n",
      "\n",
      "Epoch Step: 351 Loss: 1.266543 Tokens per Sec: 13863.249023\n",
      "\n",
      "Epoch Step: 401 Loss: 0.716780 Tokens per Sec: 13867.286133\n",
      "\n",
      "Epoch Step: 451 Loss: 1.249208 Tokens per Sec: 13358.685547\n",
      "\n",
      "Epoch Step: 501 Loss: 1.140775 Tokens per Sec: 13492.440430\n",
      "\n",
      "Epoch Step: 551 Loss: 0.905891 Tokens per Sec: 13828.696289\n",
      "\n",
      "Epoch Step: 601 Loss: 1.313801 Tokens per Sec: 13378.689453\n",
      "\n",
      "Epoch Step: 651 Loss: 1.529830 Tokens per Sec: 13335.894531\n",
      "\n",
      "Epoch Step: 701 Loss: 1.303909 Tokens per Sec: 13334.833984\n",
      "\n",
      "Epoch Step: 751 Loss: 1.088323 Tokens per Sec: 13198.844727\n",
      "\n",
      "Epoch Step: 801 Loss: 0.976005 Tokens per Sec: 13206.367188\n",
      "\n",
      "Epoch Step: 851 Loss: 1.187238 Tokens per Sec: 13078.056641\n",
      "\n",
      "Epoch Step: 901 Loss: 1.217124 Tokens per Sec: 13450.774414\n",
      "\n",
      "Epoch Step: 951 Loss: 1.282493 Tokens per Sec: 13181.088867\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.164048 Tokens per Sec: 13373.056641\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.150446 Tokens per Sec: 13145.307617\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.138363 Tokens per Sec: 13137.316406\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.329368 Tokens per Sec: 13329.875000\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.002687 Tokens per Sec: 13433.938477\n",
      "\n",
      "Epoch Step: 1251 Loss: 0.958665 Tokens per Sec: 13332.555664\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.404612 Tokens per Sec: 13390.544922\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.228099 Tokens per Sec: 13329.935547\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.506170 Tokens per Sec: 13063.346680\n",
      "\n",
      "Epoch Step: 1451 Loss: 0.952688 Tokens per Sec: 13417.516602\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.266353 Tokens per Sec: 12896.406250\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.173062 Tokens per Sec: 13497.621094\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.098286 Tokens per Sec: 13096.974609\n",
      "\n",
      "Epoch Step: 1651 Loss: 0.992809 Tokens per Sec: 13165.964844\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.109194 Tokens per Sec: 13167.296875\n",
      "\n",
      "Epoch Step: 1751 Loss: 0.938236 Tokens per Sec: 13322.824219\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.550149 Tokens per Sec: 12818.358398\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.532808 Tokens per Sec: 12836.743164\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.169584 Tokens per Sec: 13545.216797\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.020979 Tokens per Sec: 13235.364258\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.085579 Tokens per Sec: 12790.779297\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.456378 Tokens per Sec: 13203.013672\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.069394 Tokens per Sec: 13101.530273\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.051391 Tokens per Sec: 13164.914062\n",
      "\n",
      "Epoch Step: 1 Loss: 0.601481 Tokens per Sec: 11405.527344\n",
      "\n",
      "tensor(0.7037, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.033818 Tokens per Sec: 2654.177734\n",
      "\n",
      "Epoch Step: 51 Loss: 0.880050 Tokens per Sec: 12983.620117\n",
      "\n",
      "Epoch Step: 101 Loss: 1.087028 Tokens per Sec: 12892.481445\n",
      "\n",
      "Epoch Step: 151 Loss: 1.180264 Tokens per Sec: 13332.333984\n",
      "\n",
      "Epoch Step: 201 Loss: 1.071900 Tokens per Sec: 12767.370117\n",
      "\n",
      "Epoch Step: 251 Loss: 0.670548 Tokens per Sec: 13481.701172\n",
      "\n",
      "Epoch Step: 301 Loss: 1.064638 Tokens per Sec: 13457.186523\n",
      "\n",
      "Epoch Step: 351 Loss: 1.078260 Tokens per Sec: 12592.390625\n",
      "\n",
      "Epoch Step: 401 Loss: 0.841763 Tokens per Sec: 12861.318359\n",
      "\n",
      "Epoch Step: 451 Loss: 1.403273 Tokens per Sec: 12493.465820\n",
      "\n",
      "Epoch Step: 501 Loss: 1.360322 Tokens per Sec: 13520.069336\n",
      "\n",
      "Epoch Step: 551 Loss: 1.050890 Tokens per Sec: 13671.998047\n",
      "\n",
      "Epoch Step: 601 Loss: 1.169998 Tokens per Sec: 13463.390625\n",
      "\n",
      "Epoch Step: 651 Loss: 1.201485 Tokens per Sec: 13607.850586\n",
      "\n",
      "Epoch Step: 701 Loss: 1.218805 Tokens per Sec: 13462.574219\n",
      "\n",
      "Epoch Step: 751 Loss: 1.311003 Tokens per Sec: 13820.267578\n",
      "\n",
      "Epoch Step: 801 Loss: 1.006484 Tokens per Sec: 13633.735352\n",
      "\n",
      "Epoch Step: 851 Loss: 1.167225 Tokens per Sec: 13675.975586\n",
      "\n",
      "Epoch Step: 901 Loss: 1.096447 Tokens per Sec: 13263.607422\n",
      "\n",
      "Epoch Step: 951 Loss: 1.017182 Tokens per Sec: 13118.308594\n",
      "\n",
      "Epoch Step: 1001 Loss: 0.990881 Tokens per Sec: 12981.111328\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.238711 Tokens per Sec: 13221.966797\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.123360 Tokens per Sec: 13327.515625\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.362053 Tokens per Sec: 12956.395508\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.219731 Tokens per Sec: 13188.136719\n",
      "\n",
      "Epoch Step: 1251 Loss: 0.948976 Tokens per Sec: 13537.170898\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.105282 Tokens per Sec: 12912.416016\n",
      "\n",
      "Epoch Step: 1351 Loss: 0.846517 Tokens per Sec: 13434.319336\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.086212 Tokens per Sec: 13170.307617\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.303860 Tokens per Sec: 12795.970703\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.119118 Tokens per Sec: 13211.990234\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.254459 Tokens per Sec: 13203.045898\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.406260 Tokens per Sec: 13192.786133\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.295631 Tokens per Sec: 12988.367188\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.154861 Tokens per Sec: 12867.489258\n",
      "\n",
      "Epoch Step: 1751 Loss: 0.964799 Tokens per Sec: 13292.873047\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.253231 Tokens per Sec: 12941.565430\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.348646 Tokens per Sec: 13428.675781\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.292533 Tokens per Sec: 13547.297852\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.193135 Tokens per Sec: 13079.187500\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.296706 Tokens per Sec: 13326.250000\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.499940 Tokens per Sec: 13613.970703\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.100162 Tokens per Sec: 13287.196289\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.105429 Tokens per Sec: 13472.556641\n",
      "\n",
      "Epoch Step: 1 Loss: 0.596852 Tokens per Sec: 11244.998047\n",
      "\n",
      "tensor(0.6860, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.121361 Tokens per Sec: 1889.196045\n",
      "\n",
      "Epoch Step: 51 Loss: 1.197419 Tokens per Sec: 13569.189453\n",
      "\n",
      "Epoch Step: 101 Loss: 0.991072 Tokens per Sec: 13354.657227\n",
      "\n",
      "Epoch Step: 151 Loss: 1.049899 Tokens per Sec: 12968.634766\n",
      "\n",
      "Epoch Step: 201 Loss: 1.014123 Tokens per Sec: 12547.967773\n",
      "\n",
      "Epoch Step: 251 Loss: 0.929295 Tokens per Sec: 12850.713867\n",
      "\n",
      "Epoch Step: 301 Loss: 1.119413 Tokens per Sec: 13091.007812\n",
      "\n",
      "Epoch Step: 351 Loss: 1.231742 Tokens per Sec: 13331.186523\n",
      "\n",
      "Epoch Step: 401 Loss: 1.224868 Tokens per Sec: 13238.585938\n",
      "\n",
      "Epoch Step: 451 Loss: 1.267657 Tokens per Sec: 13091.864258\n",
      "\n",
      "Epoch Step: 501 Loss: 1.128154 Tokens per Sec: 13045.354492\n",
      "\n",
      "Epoch Step: 551 Loss: 1.010117 Tokens per Sec: 12534.108398\n",
      "\n",
      "Epoch Step: 601 Loss: 1.151743 Tokens per Sec: 12467.799805\n",
      "\n",
      "Epoch Step: 651 Loss: 1.116173 Tokens per Sec: 12913.088867\n",
      "\n",
      "Epoch Step: 701 Loss: 1.030982 Tokens per Sec: 13607.577148\n",
      "\n",
      "Epoch Step: 751 Loss: 1.314749 Tokens per Sec: 13628.093750\n",
      "\n",
      "Epoch Step: 801 Loss: 1.275436 Tokens per Sec: 13845.326172\n",
      "\n",
      "Epoch Step: 851 Loss: 1.038962 Tokens per Sec: 13594.634766\n",
      "\n",
      "Epoch Step: 901 Loss: 0.980688 Tokens per Sec: 13692.844727\n",
      "\n",
      "Epoch Step: 951 Loss: 1.076373 Tokens per Sec: 13677.563477\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.133536 Tokens per Sec: 13327.250000\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.355326 Tokens per Sec: 13147.791992\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.093463 Tokens per Sec: 12898.781250\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.027127 Tokens per Sec: 13194.324219\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.048055 Tokens per Sec: 13537.547852\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.062990 Tokens per Sec: 13232.394531\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.058529 Tokens per Sec: 13456.758789\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.049780 Tokens per Sec: 13335.995117\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.019822 Tokens per Sec: 13491.403320\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.152593 Tokens per Sec: 13526.286133\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.068192 Tokens per Sec: 13304.357422\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.058121 Tokens per Sec: 13293.000000\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.209794 Tokens per Sec: 13292.615234\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.131968 Tokens per Sec: 13369.896484\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.119617 Tokens per Sec: 13324.814453\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.494026 Tokens per Sec: 13127.803711\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.132048 Tokens per Sec: 13085.261719\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.118016 Tokens per Sec: 13128.418945\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.080686 Tokens per Sec: 13204.166016\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.027891 Tokens per Sec: 13174.048828\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.225526 Tokens per Sec: 13582.290039\n",
      "\n",
      "Epoch Step: 2051 Loss: 0.818446 Tokens per Sec: 12698.250000\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.249444 Tokens per Sec: 13267.224609\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.075323 Tokens per Sec: 13277.234375\n",
      "\n",
      "Epoch Step: 1 Loss: 0.582358 Tokens per Sec: 11410.538086\n",
      "\n",
      "tensor(0.6743, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.427441 Tokens per Sec: 2664.182373\n",
      "\n",
      "Epoch Step: 51 Loss: 0.850529 Tokens per Sec: 13276.691406\n",
      "\n",
      "Epoch Step: 101 Loss: 1.096348 Tokens per Sec: 13434.714844\n",
      "\n",
      "Epoch Step: 151 Loss: 0.975483 Tokens per Sec: 13137.250000\n",
      "\n",
      "Epoch Step: 201 Loss: 0.961385 Tokens per Sec: 13213.450195\n",
      "\n",
      "Epoch Step: 251 Loss: 0.930652 Tokens per Sec: 13208.916992\n",
      "\n",
      "Epoch Step: 301 Loss: 1.098019 Tokens per Sec: 13145.071289\n",
      "\n",
      "Epoch Step: 351 Loss: 1.198815 Tokens per Sec: 13429.637695\n",
      "\n",
      "Epoch Step: 401 Loss: 1.051042 Tokens per Sec: 13394.800781\n",
      "\n",
      "Epoch Step: 451 Loss: 1.144070 Tokens per Sec: 13450.397461\n",
      "\n",
      "Epoch Step: 501 Loss: 0.981133 Tokens per Sec: 13279.005859\n",
      "\n",
      "Epoch Step: 551 Loss: 0.938222 Tokens per Sec: 13372.882812\n",
      "\n",
      "Epoch Step: 601 Loss: 1.128806 Tokens per Sec: 13525.649414\n",
      "\n",
      "Epoch Step: 651 Loss: 1.064493 Tokens per Sec: 13136.683594\n",
      "\n",
      "Epoch Step: 701 Loss: 1.002039 Tokens per Sec: 12937.474609\n",
      "\n",
      "Epoch Step: 751 Loss: 0.895460 Tokens per Sec: 12359.489258\n",
      "\n",
      "Epoch Step: 801 Loss: 1.219326 Tokens per Sec: 12659.891602\n",
      "\n",
      "Epoch Step: 851 Loss: 1.359661 Tokens per Sec: 12657.977539\n",
      "\n",
      "Epoch Step: 901 Loss: 1.090449 Tokens per Sec: 13723.023438\n",
      "\n",
      "Epoch Step: 951 Loss: 1.245190 Tokens per Sec: 13000.291992\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.023592 Tokens per Sec: 13826.390625\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.308189 Tokens per Sec: 13715.012695\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.223216 Tokens per Sec: 14029.026367\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.069020 Tokens per Sec: 13674.026367\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.077400 Tokens per Sec: 13468.223633\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.193526 Tokens per Sec: 13485.344727\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.134865 Tokens per Sec: 13251.018555\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.249481 Tokens per Sec: 13586.745117\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.015041 Tokens per Sec: 12926.600586\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.156351 Tokens per Sec: 13197.951172\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.223447 Tokens per Sec: 13451.467773\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.241891 Tokens per Sec: 13071.451172\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.260422 Tokens per Sec: 13556.088867\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.238252 Tokens per Sec: 13412.421875\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.094348 Tokens per Sec: 12637.001953\n",
      "\n",
      "Epoch Step: 1751 Loss: 0.965375 Tokens per Sec: 13326.050781\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.227383 Tokens per Sec: 13098.443359\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.254429 Tokens per Sec: 13309.279297\n",
      "\n",
      "Epoch Step: 1901 Loss: 0.964659 Tokens per Sec: 13236.829102\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.363918 Tokens per Sec: 12664.006836\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.156520 Tokens per Sec: 13121.928711\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.396386 Tokens per Sec: 13161.045898\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.137740 Tokens per Sec: 13243.132812\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.072700 Tokens per Sec: 13131.935547\n",
      "\n",
      "Epoch Step: 1 Loss: 0.605000 Tokens per Sec: 11352.283203\n",
      "\n",
      "tensor(0.6787, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.156027 Tokens per Sec: 2496.221191\n",
      "\n",
      "Epoch Step: 51 Loss: 0.917788 Tokens per Sec: 13280.370117\n",
      "\n",
      "Epoch Step: 101 Loss: 1.017293 Tokens per Sec: 13252.007812\n",
      "\n",
      "Epoch Step: 151 Loss: 1.227367 Tokens per Sec: 12993.299805\n",
      "\n",
      "Epoch Step: 201 Loss: 1.158221 Tokens per Sec: 12952.506836\n",
      "\n",
      "Epoch Step: 251 Loss: 0.962162 Tokens per Sec: 12995.676758\n",
      "\n",
      "Epoch Step: 301 Loss: 0.919105 Tokens per Sec: 13593.542969\n",
      "\n",
      "Epoch Step: 351 Loss: 0.958271 Tokens per Sec: 12859.914062\n",
      "\n",
      "Epoch Step: 401 Loss: 1.025503 Tokens per Sec: 13372.971680\n",
      "\n",
      "Epoch Step: 451 Loss: 1.146316 Tokens per Sec: 13290.971680\n",
      "\n",
      "Epoch Step: 501 Loss: 1.081638 Tokens per Sec: 13215.510742\n",
      "\n",
      "Epoch Step: 551 Loss: 0.887383 Tokens per Sec: 13085.303711\n",
      "\n",
      "Epoch Step: 601 Loss: 1.116337 Tokens per Sec: 13346.158203\n",
      "\n",
      "Epoch Step: 651 Loss: 1.185880 Tokens per Sec: 13151.491211\n",
      "\n",
      "Epoch Step: 701 Loss: 1.119247 Tokens per Sec: 13437.884766\n",
      "\n",
      "Epoch Step: 751 Loss: 1.087144 Tokens per Sec: 13225.673828\n",
      "\n",
      "Epoch Step: 801 Loss: 1.348825 Tokens per Sec: 13462.718750\n",
      "\n",
      "Epoch Step: 851 Loss: 1.025694 Tokens per Sec: 13571.331055\n",
      "\n",
      "Epoch Step: 901 Loss: 1.141822 Tokens per Sec: 12543.085938\n",
      "\n",
      "Epoch Step: 951 Loss: 1.068489 Tokens per Sec: 12664.230469\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.322004 Tokens per Sec: 12425.253906\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.172670 Tokens per Sec: 13171.972656\n",
      "\n",
      "Epoch Step: 1101 Loss: 0.988737 Tokens per Sec: 13624.056641\n",
      "\n",
      "Epoch Step: 1151 Loss: 0.907118 Tokens per Sec: 13826.814453\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.203395 Tokens per Sec: 13753.524414\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.283353 Tokens per Sec: 13756.372070\n",
      "\n",
      "Epoch Step: 1301 Loss: 0.940646 Tokens per Sec: 13624.996094\n",
      "\n",
      "Epoch Step: 1351 Loss: 0.939398 Tokens per Sec: 13649.857422\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.289635 Tokens per Sec: 13457.513672\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.098584 Tokens per Sec: 13482.672852\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.132863 Tokens per Sec: 13865.649414\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.198090 Tokens per Sec: 13844.384766\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.226478 Tokens per Sec: 13357.500977\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.241862 Tokens per Sec: 13718.207031\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.455888 Tokens per Sec: 13405.764648\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.066195 Tokens per Sec: 13215.250977\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.081800 Tokens per Sec: 13232.218750\n",
      "\n",
      "Epoch Step: 1851 Loss: 0.757346 Tokens per Sec: 13448.641602\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.135945 Tokens per Sec: 13058.574219\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.383960 Tokens per Sec: 13223.519531\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.110121 Tokens per Sec: 13034.550781\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.084933 Tokens per Sec: 13402.277344\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.306242 Tokens per Sec: 13474.812500\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.201214 Tokens per Sec: 13281.355469\n",
      "\n",
      "Epoch Step: 1 Loss: 0.576428 Tokens per Sec: 10763.008789\n",
      "\n",
      "tensor(0.6664, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.330889 Tokens per Sec: 2758.277588\n",
      "\n",
      "Epoch Step: 51 Loss: 1.066999 Tokens per Sec: 13260.713867\n",
      "\n",
      "Epoch Step: 101 Loss: 0.991800 Tokens per Sec: 13227.173828\n",
      "\n",
      "Epoch Step: 151 Loss: 1.211718 Tokens per Sec: 13774.161133\n",
      "\n",
      "Epoch Step: 201 Loss: 0.990923 Tokens per Sec: 13229.000000\n",
      "\n",
      "Epoch Step: 251 Loss: 1.111004 Tokens per Sec: 13005.320312\n",
      "\n",
      "Epoch Step: 301 Loss: 1.046682 Tokens per Sec: 12733.083984\n",
      "\n",
      "Epoch Step: 351 Loss: 1.244239 Tokens per Sec: 13271.228516\n",
      "\n",
      "Epoch Step: 401 Loss: 1.165498 Tokens per Sec: 13234.640625\n",
      "\n",
      "Epoch Step: 451 Loss: 1.235304 Tokens per Sec: 13256.989258\n",
      "\n",
      "Epoch Step: 501 Loss: 1.104932 Tokens per Sec: 13224.851562\n",
      "\n",
      "Epoch Step: 551 Loss: 1.206700 Tokens per Sec: 12939.793945\n",
      "\n",
      "Epoch Step: 601 Loss: 0.816130 Tokens per Sec: 13418.115234\n",
      "\n",
      "Epoch Step: 651 Loss: 1.245023 Tokens per Sec: 13442.393555\n",
      "\n",
      "Epoch Step: 701 Loss: 1.071910 Tokens per Sec: 13517.435547\n",
      "\n",
      "Epoch Step: 751 Loss: 1.268707 Tokens per Sec: 13325.412109\n",
      "\n",
      "Epoch Step: 801 Loss: 0.995865 Tokens per Sec: 12999.696289\n",
      "\n",
      "Epoch Step: 851 Loss: 1.189936 Tokens per Sec: 13120.928711\n",
      "\n",
      "Epoch Step: 901 Loss: 1.185248 Tokens per Sec: 13384.328125\n",
      "\n",
      "Epoch Step: 951 Loss: 0.950534 Tokens per Sec: 13249.962891\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.015319 Tokens per Sec: 13293.533203\n",
      "\n",
      "Epoch Step: 1051 Loss: 0.990738 Tokens per Sec: 13200.952148\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.258783 Tokens per Sec: 12965.636719\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.001936 Tokens per Sec: 13089.071289\n",
      "\n",
      "Epoch Step: 1201 Loss: 0.998566 Tokens per Sec: 12913.805664\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.185303 Tokens per Sec: 13121.728516\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.127267 Tokens per Sec: 13764.371094\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.226995 Tokens per Sec: 13154.663086\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.166491 Tokens per Sec: 12363.642578\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.044748 Tokens per Sec: 12481.131836\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.075391 Tokens per Sec: 12584.854492\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.094374 Tokens per Sec: 13833.633789\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.230620 Tokens per Sec: 13558.886719\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.121615 Tokens per Sec: 13769.504883\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.371246 Tokens per Sec: 13757.335938\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.215320 Tokens per Sec: 13855.018555\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.173347 Tokens per Sec: 13710.588867\n",
      "\n",
      "Epoch Step: 1851 Loss: 0.975285 Tokens per Sec: 13181.101562\n",
      "\n",
      "Epoch Step: 1901 Loss: 0.978996 Tokens per Sec: 13531.025391\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.047157 Tokens per Sec: 12923.625977\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.113000 Tokens per Sec: 12835.347656\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.074603 Tokens per Sec: 13182.561523\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.150689 Tokens per Sec: 13286.737305\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.100759 Tokens per Sec: 12978.166992\n",
      "\n",
      "Epoch Step: 1 Loss: 0.562637 Tokens per Sec: 11755.359375\n",
      "\n",
      "tensor(0.6524, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.072567 Tokens per Sec: 2860.026367\n",
      "\n",
      "Epoch Step: 51 Loss: 1.009632 Tokens per Sec: 13417.499023\n",
      "\n",
      "Epoch Step: 101 Loss: 1.152372 Tokens per Sec: 13205.655273\n",
      "\n",
      "Epoch Step: 151 Loss: 1.027198 Tokens per Sec: 13613.281250\n",
      "\n",
      "Epoch Step: 201 Loss: 0.982988 Tokens per Sec: 12979.638672\n",
      "\n",
      "Epoch Step: 251 Loss: 1.154346 Tokens per Sec: 13315.171875\n",
      "\n",
      "Epoch Step: 301 Loss: 1.010117 Tokens per Sec: 13140.594727\n",
      "\n",
      "Epoch Step: 351 Loss: 0.758229 Tokens per Sec: 13447.925781\n",
      "\n",
      "Epoch Step: 401 Loss: 1.062277 Tokens per Sec: 12881.373047\n",
      "\n",
      "Epoch Step: 451 Loss: 1.112851 Tokens per Sec: 13241.521484\n",
      "\n",
      "Epoch Step: 501 Loss: 0.973295 Tokens per Sec: 13048.597656\n",
      "\n",
      "Epoch Step: 551 Loss: 1.091580 Tokens per Sec: 12834.710938\n",
      "\n",
      "Epoch Step: 601 Loss: 1.149601 Tokens per Sec: 13313.647461\n",
      "\n",
      "Epoch Step: 651 Loss: 1.168630 Tokens per Sec: 13574.583008\n",
      "\n",
      "Epoch Step: 701 Loss: 0.871588 Tokens per Sec: 13396.344727\n",
      "\n",
      "Epoch Step: 751 Loss: 1.151481 Tokens per Sec: 13401.007812\n",
      "\n",
      "Epoch Step: 801 Loss: 0.963957 Tokens per Sec: 13451.238281\n",
      "\n",
      "Epoch Step: 851 Loss: 1.114980 Tokens per Sec: 13364.825195\n",
      "\n",
      "Epoch Step: 901 Loss: 0.986624 Tokens per Sec: 13481.317383\n",
      "\n",
      "Epoch Step: 951 Loss: 0.833166 Tokens per Sec: 13340.297852\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.152168 Tokens per Sec: 13250.269531\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.210299 Tokens per Sec: 12654.257812\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.073627 Tokens per Sec: 13430.785156\n",
      "\n",
      "Epoch Step: 1151 Loss: 0.987157 Tokens per Sec: 13500.902344\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.039892 Tokens per Sec: 13270.875977\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.069936 Tokens per Sec: 13430.526367\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.176334 Tokens per Sec: 13466.016602\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.077588 Tokens per Sec: 13110.599609\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.109638 Tokens per Sec: 13336.626953\n",
      "\n",
      "Epoch Step: 1451 Loss: 0.958497 Tokens per Sec: 13526.809570\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.047132 Tokens per Sec: 13500.318359\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.322091 Tokens per Sec: 12769.701172\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.276479 Tokens per Sec: 12327.398438\n",
      "\n",
      "Epoch Step: 1651 Loss: 0.791887 Tokens per Sec: 12345.130859\n",
      "\n",
      "Epoch Step: 1701 Loss: 0.942636 Tokens per Sec: 13165.966797\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.173054 Tokens per Sec: 13820.845703\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.161695 Tokens per Sec: 13693.885742\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.325965 Tokens per Sec: 13590.920898\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.340585 Tokens per Sec: 13611.122070\n",
      "\n",
      "Epoch Step: 1951 Loss: 0.968667 Tokens per Sec: 13685.296875\n",
      "\n",
      "Epoch Step: 2001 Loss: 0.949289 Tokens per Sec: 13571.031250\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.275476 Tokens per Sec: 13392.462891\n",
      "\n",
      "Epoch Step: 2101 Loss: 0.984056 Tokens per Sec: 12978.489258\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.202609 Tokens per Sec: 13333.583984\n",
      "\n",
      "Epoch Step: 1 Loss: 0.567362 Tokens per Sec: 10453.831055\n",
      "\n",
      "tensor(0.6484, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 0.958705 Tokens per Sec: 2704.167969\n",
      "\n",
      "Epoch Step: 51 Loss: 1.082991 Tokens per Sec: 13327.920898\n",
      "\n",
      "Epoch Step: 101 Loss: 1.199477 Tokens per Sec: 13088.665039\n",
      "\n",
      "Epoch Step: 151 Loss: 1.075326 Tokens per Sec: 13509.037109\n",
      "\n",
      "Epoch Step: 201 Loss: 1.271347 Tokens per Sec: 13300.852539\n",
      "\n",
      "Epoch Step: 251 Loss: 1.040192 Tokens per Sec: 13470.750000\n",
      "\n",
      "Epoch Step: 301 Loss: 1.049356 Tokens per Sec: 13352.613281\n",
      "\n",
      "Epoch Step: 351 Loss: 1.169444 Tokens per Sec: 12887.027344\n",
      "\n",
      "Epoch Step: 401 Loss: 0.934861 Tokens per Sec: 13513.061523\n",
      "\n",
      "Epoch Step: 451 Loss: 1.148437 Tokens per Sec: 12716.924805\n",
      "\n",
      "Epoch Step: 501 Loss: 0.872698 Tokens per Sec: 13061.706055\n",
      "\n",
      "Epoch Step: 551 Loss: 1.016972 Tokens per Sec: 13051.852539\n",
      "\n",
      "Epoch Step: 601 Loss: 1.151104 Tokens per Sec: 13325.493164\n",
      "\n",
      "Epoch Step: 651 Loss: 0.909413 Tokens per Sec: 13062.022461\n",
      "\n",
      "Epoch Step: 701 Loss: 1.042383 Tokens per Sec: 13269.010742\n",
      "\n",
      "Epoch Step: 751 Loss: 0.839350 Tokens per Sec: 13491.142578\n",
      "\n",
      "Epoch Step: 801 Loss: 1.156458 Tokens per Sec: 13436.348633\n",
      "\n",
      "Epoch Step: 851 Loss: 1.166155 Tokens per Sec: 13054.136719\n",
      "\n",
      "Epoch Step: 901 Loss: 1.070063 Tokens per Sec: 13255.750000\n",
      "\n",
      "Epoch Step: 951 Loss: 1.182240 Tokens per Sec: 12856.807617\n",
      "\n",
      "Epoch Step: 1001 Loss: 0.999794 Tokens per Sec: 13147.113281\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.103123 Tokens per Sec: 13310.693359\n",
      "\n",
      "Epoch Step: 1101 Loss: 0.895349 Tokens per Sec: 12946.097656\n",
      "\n",
      "Epoch Step: 1151 Loss: 0.968626 Tokens per Sec: 12868.364258\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.377589 Tokens per Sec: 13606.060547\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.141512 Tokens per Sec: 13163.656250\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.131864 Tokens per Sec: 12882.398438\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.069395 Tokens per Sec: 13265.675781\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.235663 Tokens per Sec: 13099.000000\n",
      "\n",
      "Epoch Step: 1451 Loss: 0.955392 Tokens per Sec: 13414.116211\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.142153 Tokens per Sec: 12943.964844\n",
      "\n",
      "Epoch Step: 1551 Loss: 0.970341 Tokens per Sec: 13275.436523\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.177103 Tokens per Sec: 13428.641602\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.195751 Tokens per Sec: 13570.136719\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.357855 Tokens per Sec: 13247.896484\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.104004 Tokens per Sec: 12664.654297\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.119689 Tokens per Sec: 12381.903320\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.081234 Tokens per Sec: 12789.786133\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.216047 Tokens per Sec: 13384.619141\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.085137 Tokens per Sec: 13746.536133\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.264448 Tokens per Sec: 13430.523438\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.099370 Tokens per Sec: 13711.355469\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.123299 Tokens per Sec: 13296.211914\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.461023 Tokens per Sec: 13249.816406\n",
      "\n",
      "Epoch Step: 1 Loss: 0.551132 Tokens per Sec: 10958.166016\n",
      "\n",
      "tensor(0.6419, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 0.920093 Tokens per Sec: 2696.346924\n",
      "\n",
      "Epoch Step: 51 Loss: 0.948027 Tokens per Sec: 13247.713867\n",
      "\n",
      "Epoch Step: 101 Loss: 1.015952 Tokens per Sec: 13122.943359\n",
      "\n",
      "Epoch Step: 151 Loss: 0.888112 Tokens per Sec: 13492.592773\n",
      "\n",
      "Epoch Step: 201 Loss: 1.071070 Tokens per Sec: 13499.051758\n",
      "\n",
      "Epoch Step: 251 Loss: 0.888830 Tokens per Sec: 13198.666992\n",
      "\n",
      "Epoch Step: 301 Loss: 0.954852 Tokens per Sec: 13205.858398\n",
      "\n",
      "Epoch Step: 351 Loss: 1.251088 Tokens per Sec: 13153.302734\n",
      "\n",
      "Epoch Step: 401 Loss: 0.929001 Tokens per Sec: 13325.846680\n",
      "\n",
      "Epoch Step: 451 Loss: 1.189030 Tokens per Sec: 13089.714844\n",
      "\n",
      "Epoch Step: 501 Loss: 1.131627 Tokens per Sec: 13078.700195\n",
      "\n",
      "Epoch Step: 551 Loss: 1.243886 Tokens per Sec: 12449.916992\n",
      "\n",
      "Epoch Step: 601 Loss: 1.220021 Tokens per Sec: 13383.425781\n",
      "\n",
      "Epoch Step: 651 Loss: 1.093863 Tokens per Sec: 13380.272461\n",
      "\n",
      "Epoch Step: 701 Loss: 1.183267 Tokens per Sec: 12773.816406\n",
      "\n",
      "Epoch Step: 751 Loss: 1.034242 Tokens per Sec: 12648.879883\n",
      "\n",
      "Epoch Step: 801 Loss: 1.254289 Tokens per Sec: 13044.610352\n",
      "\n",
      "Epoch Step: 851 Loss: 0.984922 Tokens per Sec: 13282.300781\n",
      "\n",
      "Epoch Step: 901 Loss: 1.124758 Tokens per Sec: 13222.648438\n",
      "\n",
      "Epoch Step: 951 Loss: 1.294101 Tokens per Sec: 12809.835938\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.203111 Tokens per Sec: 13396.045898\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.064004 Tokens per Sec: 12864.210938\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.084319 Tokens per Sec: 13419.356445\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.121913 Tokens per Sec: 13116.336914\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.179096 Tokens per Sec: 13325.156250\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.030682 Tokens per Sec: 13571.414062\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.460287 Tokens per Sec: 13134.360352\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.065833 Tokens per Sec: 13110.158203\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.216981 Tokens per Sec: 13726.127930\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.479982 Tokens per Sec: 12908.795898\n",
      "\n",
      "Epoch Step: 1501 Loss: 0.965961 Tokens per Sec: 13289.909180\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.258531 Tokens per Sec: 13745.676758\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.013915 Tokens per Sec: 13140.797852\n",
      "\n",
      "Epoch Step: 1651 Loss: 0.920538 Tokens per Sec: 13545.215820\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.240088 Tokens per Sec: 12892.172852\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.087701 Tokens per Sec: 13042.633789\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.126613 Tokens per Sec: 13148.453125\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.217468 Tokens per Sec: 13756.811523\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.109248 Tokens per Sec: 12272.544922\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.453635 Tokens per Sec: 12042.007812\n",
      "\n",
      "Epoch Step: 2001 Loss: 0.931665 Tokens per Sec: 12588.575195\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.238399 Tokens per Sec: 13728.968750\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.147856 Tokens per Sec: 13521.212891\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.176677 Tokens per Sec: 13469.756836\n",
      "\n",
      "Epoch Step: 1 Loss: 0.544084 Tokens per Sec: 11623.266602\n",
      "\n",
      "tensor(0.6369, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.068288 Tokens per Sec: 2900.704346\n",
      "\n",
      "Epoch Step: 51 Loss: 0.941325 Tokens per Sec: 13993.338867\n",
      "\n",
      "Epoch Step: 101 Loss: 1.154032 Tokens per Sec: 13975.146484\n",
      "\n",
      "Epoch Step: 151 Loss: 0.944992 Tokens per Sec: 13447.586914\n",
      "\n",
      "Epoch Step: 201 Loss: 1.120194 Tokens per Sec: 13088.583984\n",
      "\n",
      "Epoch Step: 251 Loss: 1.283901 Tokens per Sec: 12752.808594\n",
      "\n",
      "Epoch Step: 301 Loss: 0.991464 Tokens per Sec: 13416.822266\n",
      "\n",
      "Epoch Step: 351 Loss: 0.951819 Tokens per Sec: 13131.605469\n",
      "\n",
      "Epoch Step: 401 Loss: 1.045467 Tokens per Sec: 13647.493164\n",
      "\n",
      "Epoch Step: 451 Loss: 1.221627 Tokens per Sec: 13185.829102\n",
      "\n",
      "Epoch Step: 501 Loss: 0.924498 Tokens per Sec: 13655.236328\n",
      "\n",
      "Epoch Step: 551 Loss: 1.144344 Tokens per Sec: 13185.519531\n",
      "\n",
      "Epoch Step: 601 Loss: 0.760802 Tokens per Sec: 12842.781250\n",
      "\n",
      "Epoch Step: 651 Loss: 1.252261 Tokens per Sec: 12824.513672\n",
      "\n",
      "Epoch Step: 701 Loss: 0.846169 Tokens per Sec: 13247.862305\n",
      "\n",
      "Epoch Step: 751 Loss: 0.979407 Tokens per Sec: 13404.549805\n",
      "\n",
      "Epoch Step: 801 Loss: 1.024947 Tokens per Sec: 13161.400391\n",
      "\n",
      "Epoch Step: 851 Loss: 1.102066 Tokens per Sec: 13087.980469\n",
      "\n",
      "Epoch Step: 901 Loss: 0.852154 Tokens per Sec: 13409.835938\n",
      "\n",
      "Epoch Step: 951 Loss: 1.102359 Tokens per Sec: 13223.928711\n",
      "\n",
      "Epoch Step: 1001 Loss: 0.810352 Tokens per Sec: 12788.061523\n",
      "\n",
      "Epoch Step: 1051 Loss: 0.940288 Tokens per Sec: 13417.556641\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.102316 Tokens per Sec: 13215.165039\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.346249 Tokens per Sec: 13013.171875\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.200609 Tokens per Sec: 12933.657227\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.181103 Tokens per Sec: 13132.869141\n",
      "\n",
      "Epoch Step: 1301 Loss: 0.904757 Tokens per Sec: 12666.084961\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.243248 Tokens per Sec: 12572.250977\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.003782 Tokens per Sec: 13052.250000\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.262016 Tokens per Sec: 13729.419922\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.082975 Tokens per Sec: 13240.695312\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.126219 Tokens per Sec: 12942.614258\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.034270 Tokens per Sec: 13334.398438\n",
      "\n",
      "Epoch Step: 1651 Loss: 0.980821 Tokens per Sec: 13424.051758\n",
      "\n",
      "Epoch Step: 1701 Loss: 0.741635 Tokens per Sec: 13027.295898\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.110195 Tokens per Sec: 13422.948242\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.024521 Tokens per Sec: 13435.868164\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.406875 Tokens per Sec: 13189.735352\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.074648 Tokens per Sec: 13333.670898\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.076063 Tokens per Sec: 13205.283203\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.040305 Tokens per Sec: 13492.050781\n",
      "\n",
      "Epoch Step: 2051 Loss: 0.855673 Tokens per Sec: 13019.293945\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.146716 Tokens per Sec: 12782.486328\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.306715 Tokens per Sec: 12770.747070\n",
      "\n",
      "Epoch Step: 1 Loss: 0.549127 Tokens per Sec: 11854.037109\n",
      "\n",
      "tensor(0.6315, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.096088 Tokens per Sec: 2595.651123\n",
      "\n",
      "Epoch Step: 51 Loss: 0.976865 Tokens per Sec: 13823.458008\n",
      "\n",
      "Epoch Step: 101 Loss: 1.033500 Tokens per Sec: 13613.483398\n",
      "\n",
      "Epoch Step: 151 Loss: 0.992604 Tokens per Sec: 13697.423828\n",
      "\n",
      "Epoch Step: 201 Loss: 0.932817 Tokens per Sec: 13795.308594\n",
      "\n",
      "Epoch Step: 251 Loss: 0.892800 Tokens per Sec: 13683.276367\n",
      "\n",
      "Epoch Step: 301 Loss: 1.089429 Tokens per Sec: 13283.101562\n",
      "\n",
      "Epoch Step: 351 Loss: 1.134232 Tokens per Sec: 13505.247070\n",
      "\n",
      "Epoch Step: 401 Loss: 1.002118 Tokens per Sec: 13793.292969\n",
      "\n",
      "Epoch Step: 451 Loss: 1.137928 Tokens per Sec: 13252.850586\n",
      "\n",
      "Epoch Step: 501 Loss: 0.952721 Tokens per Sec: 13266.657227\n",
      "\n",
      "Epoch Step: 551 Loss: 1.048834 Tokens per Sec: 13456.635742\n",
      "\n",
      "Epoch Step: 601 Loss: 0.835971 Tokens per Sec: 13354.402344\n",
      "\n",
      "Epoch Step: 651 Loss: 0.943614 Tokens per Sec: 13140.388672\n",
      "\n",
      "Epoch Step: 701 Loss: 1.134766 Tokens per Sec: 13277.133789\n",
      "\n",
      "Epoch Step: 751 Loss: 1.265093 Tokens per Sec: 12790.131836\n",
      "\n",
      "Epoch Step: 801 Loss: 0.977331 Tokens per Sec: 13176.783203\n",
      "\n",
      "Epoch Step: 851 Loss: 1.245597 Tokens per Sec: 13407.424805\n",
      "\n",
      "Epoch Step: 901 Loss: 0.925919 Tokens per Sec: 13373.215820\n",
      "\n",
      "Epoch Step: 951 Loss: 0.953810 Tokens per Sec: 13341.903320\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.011335 Tokens per Sec: 13396.116211\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.265924 Tokens per Sec: 13522.457031\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.240552 Tokens per Sec: 13601.299805\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.092811 Tokens per Sec: 13048.134766\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.149221 Tokens per Sec: 13442.445312\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.284075 Tokens per Sec: 13425.240234\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.062855 Tokens per Sec: 13245.954102\n",
      "\n",
      "Epoch Step: 1351 Loss: 0.856534 Tokens per Sec: 13291.256836\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.164167 Tokens per Sec: 13170.907227\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.179663 Tokens per Sec: 13207.964844\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.110118 Tokens per Sec: 13235.568359\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.124171 Tokens per Sec: 13358.546875\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.131675 Tokens per Sec: 13452.348633\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.192094 Tokens per Sec: 13153.146484\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.358435 Tokens per Sec: 13239.541992\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.145535 Tokens per Sec: 13244.378906\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.303973 Tokens per Sec: 13206.090820\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.010993 Tokens per Sec: 13322.800781\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.135617 Tokens per Sec: 13318.397461\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.189015 Tokens per Sec: 13080.717773\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.116732 Tokens per Sec: 13464.338867\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.153779 Tokens per Sec: 13315.488281\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.128977 Tokens per Sec: 13393.693359\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.189737 Tokens per Sec: 13387.039062\n",
      "\n",
      "Epoch Step: 1 Loss: 0.537786 Tokens per Sec: 11571.619141\n",
      "\n",
      "tensor(0.6262, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.034689 Tokens per Sec: 3029.740723\n",
      "\n",
      "Epoch Step: 51 Loss: 1.029229 Tokens per Sec: 13036.047852\n",
      "\n",
      "Epoch Step: 101 Loss: 1.154933 Tokens per Sec: 12427.278320\n",
      "\n",
      "Epoch Step: 151 Loss: 1.094171 Tokens per Sec: 12588.157227\n",
      "\n",
      "Epoch Step: 201 Loss: 1.082928 Tokens per Sec: 13169.746094\n",
      "\n",
      "Epoch Step: 251 Loss: 0.914329 Tokens per Sec: 13224.898438\n",
      "\n",
      "Epoch Step: 301 Loss: 1.022126 Tokens per Sec: 13536.796875\n",
      "\n",
      "Epoch Step: 351 Loss: 1.092456 Tokens per Sec: 13471.045898\n",
      "\n",
      "Epoch Step: 401 Loss: 0.773324 Tokens per Sec: 13566.662109\n",
      "\n",
      "Epoch Step: 451 Loss: 1.159180 Tokens per Sec: 13596.587891\n",
      "\n",
      "Epoch Step: 501 Loss: 0.996511 Tokens per Sec: 13852.905273\n",
      "\n",
      "Epoch Step: 551 Loss: 1.159111 Tokens per Sec: 12957.491211\n",
      "\n",
      "Epoch Step: 601 Loss: 1.356031 Tokens per Sec: 13055.352539\n",
      "\n",
      "Epoch Step: 651 Loss: 1.322841 Tokens per Sec: 13411.058594\n",
      "\n",
      "Epoch Step: 701 Loss: 0.883626 Tokens per Sec: 13176.066406\n",
      "\n",
      "Epoch Step: 751 Loss: 1.141966 Tokens per Sec: 13426.376953\n",
      "\n",
      "Epoch Step: 801 Loss: 1.089585 Tokens per Sec: 13436.869141\n",
      "\n",
      "Epoch Step: 851 Loss: 1.072361 Tokens per Sec: 13072.238281\n",
      "\n",
      "Epoch Step: 901 Loss: 1.099455 Tokens per Sec: 13209.041016\n",
      "\n",
      "Epoch Step: 951 Loss: 1.035069 Tokens per Sec: 13139.096680\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.072062 Tokens per Sec: 13356.655273\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.092735 Tokens per Sec: 13109.675781\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.214314 Tokens per Sec: 13395.142578\n",
      "\n",
      "Epoch Step: 1151 Loss: 0.997089 Tokens per Sec: 13513.595703\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.167442 Tokens per Sec: 13580.673828\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.150153 Tokens per Sec: 13147.598633\n",
      "\n",
      "Epoch Step: 1301 Loss: 0.989892 Tokens per Sec: 13247.201172\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.180415 Tokens per Sec: 13387.388672\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.115777 Tokens per Sec: 12810.004883\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.332006 Tokens per Sec: 12768.866211\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.217417 Tokens per Sec: 13292.814453\n",
      "\n",
      "Epoch Step: 1551 Loss: 0.894844 Tokens per Sec: 13552.640625\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.092953 Tokens per Sec: 12626.005859\n",
      "\n",
      "Epoch Step: 1651 Loss: 0.947943 Tokens per Sec: 13156.316406\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.389395 Tokens per Sec: 13112.118164\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.144756 Tokens per Sec: 12988.137695\n",
      "\n",
      "Epoch Step: 1801 Loss: 0.993628 Tokens per Sec: 13553.271484\n",
      "\n",
      "Epoch Step: 1851 Loss: 0.874729 Tokens per Sec: 12810.666016\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.388490 Tokens per Sec: 13246.655273\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.205066 Tokens per Sec: 13228.083984\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.192327 Tokens per Sec: 13326.213867\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.260195 Tokens per Sec: 13049.041992\n",
      "\n",
      "Epoch Step: 2101 Loss: 0.893964 Tokens per Sec: 13075.413086\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.223493 Tokens per Sec: 13201.169922\n",
      "\n",
      "Epoch Step: 1 Loss: 0.544915 Tokens per Sec: 9957.147461\n",
      "\n",
      "tensor(0.6191, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 0.952596 Tokens per Sec: 3021.595459\n",
      "\n",
      "Epoch Step: 51 Loss: 0.828221 Tokens per Sec: 13598.022461\n",
      "\n",
      "Epoch Step: 101 Loss: 1.044216 Tokens per Sec: 13340.862305\n",
      "\n",
      "Epoch Step: 151 Loss: 0.956945 Tokens per Sec: 13304.493164\n",
      "\n",
      "Epoch Step: 201 Loss: 1.021259 Tokens per Sec: 12303.595703\n",
      "\n",
      "Epoch Step: 251 Loss: 1.000588 Tokens per Sec: 12888.387695\n",
      "\n",
      "Epoch Step: 301 Loss: 0.861851 Tokens per Sec: 12489.155273\n",
      "\n",
      "Epoch Step: 351 Loss: 1.039469 Tokens per Sec: 12405.336914\n",
      "\n",
      "Epoch Step: 401 Loss: 0.970095 Tokens per Sec: 13458.763672\n",
      "\n",
      "Epoch Step: 451 Loss: 0.949694 Tokens per Sec: 13372.981445\n",
      "\n",
      "Epoch Step: 501 Loss: 0.994715 Tokens per Sec: 13077.722656\n",
      "\n",
      "Epoch Step: 551 Loss: 1.120315 Tokens per Sec: 13726.150391\n",
      "\n",
      "Epoch Step: 601 Loss: 1.066671 Tokens per Sec: 13808.383789\n",
      "\n",
      "Epoch Step: 651 Loss: 1.055532 Tokens per Sec: 13937.857422\n",
      "\n",
      "Epoch Step: 701 Loss: 0.931778 Tokens per Sec: 13153.230469\n",
      "\n",
      "Epoch Step: 751 Loss: 0.826458 Tokens per Sec: 13207.099609\n",
      "\n",
      "Epoch Step: 801 Loss: 0.927996 Tokens per Sec: 13475.260742\n",
      "\n",
      "Epoch Step: 851 Loss: 0.919291 Tokens per Sec: 13414.573242\n",
      "\n",
      "Epoch Step: 901 Loss: 1.068738 Tokens per Sec: 13348.795898\n",
      "\n",
      "Epoch Step: 951 Loss: 1.290960 Tokens per Sec: 12954.890625\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.191681 Tokens per Sec: 13132.721680\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.032103 Tokens per Sec: 13007.674805\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.123594 Tokens per Sec: 13168.085938\n",
      "\n",
      "Epoch Step: 1151 Loss: 0.909332 Tokens per Sec: 13053.400391\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.048886 Tokens per Sec: 13300.118164\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.159730 Tokens per Sec: 13345.706055\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.052972 Tokens per Sec: 13361.205078\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.249346 Tokens per Sec: 13481.658203\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.256124 Tokens per Sec: 13652.314453\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.097516 Tokens per Sec: 13733.745117\n",
      "\n",
      "Epoch Step: 1501 Loss: 0.981681 Tokens per Sec: 13176.705078\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.021702 Tokens per Sec: 13189.847656\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.233923 Tokens per Sec: 13044.336914\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.120232 Tokens per Sec: 12513.545898\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.081848 Tokens per Sec: 13387.803711\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.053638 Tokens per Sec: 13395.489258\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.311173 Tokens per Sec: 12970.070312\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.245135 Tokens per Sec: 13241.467773\n",
      "\n",
      "Epoch Step: 1901 Loss: 0.996407 Tokens per Sec: 13272.538086\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.421893 Tokens per Sec: 13347.872070\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.062809 Tokens per Sec: 13353.106445\n",
      "\n",
      "Epoch Step: 2051 Loss: 0.423051 Tokens per Sec: 13357.977539\n",
      "\n",
      "Epoch Step: 2101 Loss: 0.812232 Tokens per Sec: 13359.595703\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.013969 Tokens per Sec: 13645.751953\n",
      "\n",
      "Epoch Step: 1 Loss: 0.536664 Tokens per Sec: 11877.438477\n",
      "\n",
      "tensor(0.6073, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.169522 Tokens per Sec: 2559.837646\n",
      "\n",
      "Epoch Step: 51 Loss: 1.044810 Tokens per Sec: 13473.379883\n",
      "\n",
      "Epoch Step: 101 Loss: 0.888585 Tokens per Sec: 13415.686523\n",
      "\n",
      "Epoch Step: 151 Loss: 0.928019 Tokens per Sec: 12994.437500\n",
      "\n",
      "Epoch Step: 201 Loss: 0.956392 Tokens per Sec: 13135.562500\n",
      "\n",
      "Epoch Step: 251 Loss: 1.049332 Tokens per Sec: 13192.241211\n",
      "\n",
      "Epoch Step: 301 Loss: 0.959722 Tokens per Sec: 13387.087891\n",
      "\n",
      "Epoch Step: 351 Loss: 0.952783 Tokens per Sec: 13787.132812\n",
      "\n",
      "Epoch Step: 401 Loss: 1.032593 Tokens per Sec: 12760.901367\n",
      "\n",
      "Epoch Step: 451 Loss: 0.993593 Tokens per Sec: 12870.338867\n",
      "\n",
      "Epoch Step: 501 Loss: 1.023484 Tokens per Sec: 12632.530273\n",
      "\n",
      "Epoch Step: 551 Loss: 1.039656 Tokens per Sec: 12886.487305\n",
      "\n",
      "Epoch Step: 601 Loss: 0.918095 Tokens per Sec: 13081.000977\n",
      "\n",
      "Epoch Step: 651 Loss: 0.935772 Tokens per Sec: 13067.242188\n",
      "\n",
      "Epoch Step: 701 Loss: 1.020015 Tokens per Sec: 13084.392578\n",
      "\n",
      "Epoch Step: 751 Loss: 1.055156 Tokens per Sec: 13087.785156\n",
      "\n",
      "Epoch Step: 801 Loss: 1.036353 Tokens per Sec: 13614.666992\n",
      "\n",
      "Epoch Step: 851 Loss: 1.238763 Tokens per Sec: 13447.053711\n",
      "\n",
      "Epoch Step: 901 Loss: 1.105318 Tokens per Sec: 13066.923828\n",
      "\n",
      "Epoch Step: 951 Loss: 0.950854 Tokens per Sec: 13131.122070\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.342157 Tokens per Sec: 12840.719727\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.192978 Tokens per Sec: 13161.535156\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.090920 Tokens per Sec: 13080.199219\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.006161 Tokens per Sec: 13660.561523\n",
      "\n",
      "Epoch Step: 1201 Loss: 0.736783 Tokens per Sec: 13254.580078\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.171371 Tokens per Sec: 13370.699219\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.112099 Tokens per Sec: 13325.663086\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.082720 Tokens per Sec: 13409.318359\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.064048 Tokens per Sec: 13659.176758\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.223081 Tokens per Sec: 13535.061523\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.145831 Tokens per Sec: 13399.482422\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.375439 Tokens per Sec: 13565.668945\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.074383 Tokens per Sec: 13402.427734\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.101017 Tokens per Sec: 13390.486328\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.135952 Tokens per Sec: 13028.522461\n",
      "\n",
      "Epoch Step: 1751 Loss: 0.907112 Tokens per Sec: 12947.606445\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.220503 Tokens per Sec: 13363.120117\n",
      "\n",
      "Epoch Step: 1851 Loss: 0.817211 Tokens per Sec: 13662.268555\n",
      "\n",
      "Epoch Step: 1901 Loss: 0.937506 Tokens per Sec: 13353.250000\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.314889 Tokens per Sec: 13001.877930\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.378142 Tokens per Sec: 12968.412109\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.167866 Tokens per Sec: 13499.220703\n",
      "\n",
      "Epoch Step: 2101 Loss: 0.846090 Tokens per Sec: 13087.965820\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.206583 Tokens per Sec: 13300.608398\n",
      "\n",
      "Epoch Step: 1 Loss: 0.531187 Tokens per Sec: 10618.191406\n",
      "\n",
      "tensor(0.6071, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.072811 Tokens per Sec: 2385.694092\n",
      "\n",
      "Epoch Step: 51 Loss: 1.274788 Tokens per Sec: 13092.622070\n",
      "\n",
      "Epoch Step: 101 Loss: 1.039245 Tokens per Sec: 13090.838867\n",
      "\n",
      "Epoch Step: 151 Loss: 1.085126 Tokens per Sec: 13218.000000\n",
      "\n",
      "Epoch Step: 201 Loss: 1.264678 Tokens per Sec: 13470.129883\n",
      "\n",
      "Epoch Step: 251 Loss: 1.098989 Tokens per Sec: 13393.128906\n",
      "\n",
      "Epoch Step: 301 Loss: 1.059770 Tokens per Sec: 13244.648438\n",
      "\n",
      "Epoch Step: 351 Loss: 0.985031 Tokens per Sec: 13754.360352\n",
      "\n",
      "Epoch Step: 401 Loss: 0.913982 Tokens per Sec: 13107.398438\n",
      "\n",
      "Epoch Step: 451 Loss: 1.024303 Tokens per Sec: 13080.011719\n",
      "\n",
      "Epoch Step: 501 Loss: 1.352763 Tokens per Sec: 13376.745117\n",
      "\n",
      "Epoch Step: 551 Loss: 1.117724 Tokens per Sec: 13642.772461\n",
      "\n",
      "Epoch Step: 601 Loss: 0.901585 Tokens per Sec: 12443.083984\n",
      "\n",
      "Epoch Step: 651 Loss: 1.160766 Tokens per Sec: 12461.212891\n",
      "\n",
      "Epoch Step: 701 Loss: 1.131401 Tokens per Sec: 12613.279297\n",
      "\n",
      "Epoch Step: 751 Loss: 1.018885 Tokens per Sec: 13603.708008\n",
      "\n",
      "Epoch Step: 801 Loss: 1.259162 Tokens per Sec: 13241.092773\n",
      "\n",
      "Epoch Step: 851 Loss: 1.036587 Tokens per Sec: 12924.492188\n",
      "\n",
      "Epoch Step: 901 Loss: 0.479508 Tokens per Sec: 13576.546875\n",
      "\n",
      "Epoch Step: 951 Loss: 1.323895 Tokens per Sec: 13421.266602\n",
      "\n",
      "Epoch Step: 1001 Loss: 0.913672 Tokens per Sec: 13558.489258\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.310608 Tokens per Sec: 13795.897461\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.264202 Tokens per Sec: 13198.866211\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.005862 Tokens per Sec: 13206.428711\n",
      "\n",
      "Epoch Step: 1201 Loss: 0.913818 Tokens per Sec: 12931.822266\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.190945 Tokens per Sec: 13119.047852\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.036312 Tokens per Sec: 13207.245117\n",
      "\n",
      "Epoch Step: 1351 Loss: 0.977695 Tokens per Sec: 13029.506836\n",
      "\n",
      "Epoch Step: 1401 Loss: 0.876356 Tokens per Sec: 13387.005859\n",
      "\n",
      "Epoch Step: 1451 Loss: 0.974240 Tokens per Sec: 13274.198242\n",
      "\n",
      "Epoch Step: 1501 Loss: 0.953600 Tokens per Sec: 13223.028320\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.406273 Tokens per Sec: 13437.992188\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.061658 Tokens per Sec: 13309.390625\n",
      "\n",
      "Epoch Step: 1651 Loss: 0.727237 Tokens per Sec: 13490.630859\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.242571 Tokens per Sec: 13595.958984\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.190809 Tokens per Sec: 13485.408203\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.073056 Tokens per Sec: 13453.441406\n",
      "\n",
      "Epoch Step: 1851 Loss: 0.990422 Tokens per Sec: 13452.980469\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.059202 Tokens per Sec: 13164.107422\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.351072 Tokens per Sec: 13003.778320\n",
      "\n",
      "Epoch Step: 2001 Loss: 0.915368 Tokens per Sec: 12507.372070\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.260739 Tokens per Sec: 13253.025391\n",
      "\n",
      "Epoch Step: 2101 Loss: 0.765357 Tokens per Sec: 12989.910156\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.354182 Tokens per Sec: 13201.348633\n",
      "\n",
      "Epoch Step: 1 Loss: 0.527043 Tokens per Sec: 12038.649414\n",
      "\n",
      "tensor(0.6018, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.098278 Tokens per Sec: 2836.870605\n",
      "\n",
      "Epoch Step: 51 Loss: 0.854843 Tokens per Sec: 13482.969727\n",
      "\n",
      "Epoch Step: 101 Loss: 0.918331 Tokens per Sec: 13511.019531\n",
      "\n",
      "Epoch Step: 151 Loss: 1.097523 Tokens per Sec: 13488.699219\n",
      "\n",
      "Epoch Step: 201 Loss: 1.112643 Tokens per Sec: 13234.847656\n",
      "\n",
      "Epoch Step: 251 Loss: 1.002276 Tokens per Sec: 13456.400391\n",
      "\n",
      "Epoch Step: 301 Loss: 0.989197 Tokens per Sec: 13076.424805\n",
      "\n",
      "Epoch Step: 351 Loss: 1.050369 Tokens per Sec: 13174.029297\n",
      "\n",
      "Epoch Step: 401 Loss: 1.113398 Tokens per Sec: 12993.779297\n",
      "\n",
      "Epoch Step: 451 Loss: 1.217568 Tokens per Sec: 12919.905273\n",
      "\n",
      "Epoch Step: 501 Loss: 0.890917 Tokens per Sec: 12776.421875\n",
      "\n",
      "Epoch Step: 551 Loss: 1.270263 Tokens per Sec: 13516.755859\n",
      "\n",
      "Epoch Step: 601 Loss: 1.074201 Tokens per Sec: 13339.585938\n",
      "\n",
      "Epoch Step: 651 Loss: 1.153989 Tokens per Sec: 13069.605469\n",
      "\n",
      "Epoch Step: 701 Loss: 1.118958 Tokens per Sec: 13368.775391\n",
      "\n",
      "Epoch Step: 751 Loss: 0.793696 Tokens per Sec: 13263.121094\n",
      "\n",
      "Epoch Step: 801 Loss: 1.182292 Tokens per Sec: 12394.590820\n",
      "\n",
      "Epoch Step: 851 Loss: 1.057506 Tokens per Sec: 12410.349609\n",
      "\n",
      "Epoch Step: 901 Loss: 1.144104 Tokens per Sec: 13106.287109\n",
      "\n",
      "Epoch Step: 951 Loss: 0.906917 Tokens per Sec: 13791.900391\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.002225 Tokens per Sec: 13911.133789\n",
      "\n",
      "Epoch Step: 1051 Loss: 0.941843 Tokens per Sec: 14088.443359\n",
      "\n",
      "Epoch Step: 1101 Loss: 0.892003 Tokens per Sec: 13880.484375\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.020835 Tokens per Sec: 14140.069336\n",
      "\n",
      "Epoch Step: 1201 Loss: 0.650951 Tokens per Sec: 13960.370117\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.006143 Tokens per Sec: 13007.172852\n",
      "\n",
      "Epoch Step: 1301 Loss: 0.941200 Tokens per Sec: 13197.279297\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.062501 Tokens per Sec: 13613.187500\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.185397 Tokens per Sec: 13287.610352\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.254850 Tokens per Sec: 13266.396484\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.331892 Tokens per Sec: 13326.412109\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.174250 Tokens per Sec: 13709.604492\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.034131 Tokens per Sec: 12960.894531\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.145668 Tokens per Sec: 13015.637695\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.125149 Tokens per Sec: 12500.563477\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.099528 Tokens per Sec: 13081.971680\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.141933 Tokens per Sec: 13076.881836\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.028954 Tokens per Sec: 12837.726562\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.114364 Tokens per Sec: 13393.242188\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.131932 Tokens per Sec: 13486.208008\n",
      "\n",
      "Epoch Step: 2001 Loss: 0.904860 Tokens per Sec: 13582.451172\n",
      "\n",
      "Epoch Step: 2051 Loss: 0.880951 Tokens per Sec: 12930.914062\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.088947 Tokens per Sec: 13453.397461\n",
      "\n",
      "Epoch Step: 2151 Loss: 0.904245 Tokens per Sec: 13169.344727\n",
      "\n",
      "Epoch Step: 1 Loss: 0.519253 Tokens per Sec: 11258.785156\n",
      "\n",
      "tensor(0.5917, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 0.885570 Tokens per Sec: 3036.777832\n",
      "\n",
      "Epoch Step: 51 Loss: 0.975797 Tokens per Sec: 13580.857422\n",
      "\n",
      "Epoch Step: 101 Loss: 1.095293 Tokens per Sec: 13529.338867\n",
      "\n",
      "Epoch Step: 151 Loss: 1.005537 Tokens per Sec: 13331.805664\n",
      "\n",
      "Epoch Step: 201 Loss: 0.867346 Tokens per Sec: 12840.602539\n",
      "\n",
      "Epoch Step: 251 Loss: 0.934777 Tokens per Sec: 13536.853516\n",
      "\n",
      "Epoch Step: 301 Loss: 1.070435 Tokens per Sec: 13559.032227\n",
      "\n",
      "Epoch Step: 351 Loss: 0.821619 Tokens per Sec: 13324.381836\n",
      "\n",
      "Epoch Step: 401 Loss: 1.093871 Tokens per Sec: 13428.093750\n",
      "\n",
      "Epoch Step: 451 Loss: 0.896570 Tokens per Sec: 13133.980469\n",
      "\n",
      "Epoch Step: 501 Loss: 1.232611 Tokens per Sec: 12889.472656\n",
      "\n",
      "Epoch Step: 551 Loss: 1.180932 Tokens per Sec: 13477.409180\n",
      "\n",
      "Epoch Step: 601 Loss: 1.187926 Tokens per Sec: 13335.608398\n",
      "\n",
      "Epoch Step: 651 Loss: 1.031490 Tokens per Sec: 13380.787109\n",
      "\n",
      "Epoch Step: 701 Loss: 1.040442 Tokens per Sec: 13021.306641\n",
      "\n",
      "Epoch Step: 751 Loss: 0.891448 Tokens per Sec: 13358.438477\n",
      "\n",
      "Epoch Step: 801 Loss: 0.988864 Tokens per Sec: 13283.771484\n",
      "\n",
      "Epoch Step: 851 Loss: 1.117102 Tokens per Sec: 13436.328125\n",
      "\n",
      "Epoch Step: 901 Loss: 0.830304 Tokens per Sec: 13902.421875\n",
      "\n",
      "Epoch Step: 951 Loss: 0.770959 Tokens per Sec: 12635.842773\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.023247 Tokens per Sec: 12144.092773\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.111721 Tokens per Sec: 12499.826172\n",
      "\n",
      "Epoch Step: 1101 Loss: 0.900706 Tokens per Sec: 13197.291016\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.049957 Tokens per Sec: 13797.007812\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.060596 Tokens per Sec: 13699.947266\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.146819 Tokens per Sec: 13571.632812\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.103139 Tokens per Sec: 13863.242188\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.012799 Tokens per Sec: 13651.644531\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.042209 Tokens per Sec: 13565.655273\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.357981 Tokens per Sec: 13779.336914\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.055406 Tokens per Sec: 13261.495117\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.196083 Tokens per Sec: 13232.171875\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.113432 Tokens per Sec: 13399.108398\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.223789 Tokens per Sec: 13411.920898\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.311633 Tokens per Sec: 13293.609375\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.098424 Tokens per Sec: 13283.189453\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.140070 Tokens per Sec: 12854.858398\n",
      "\n",
      "Epoch Step: 1851 Loss: 0.860734 Tokens per Sec: 13395.442383\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.208556 Tokens per Sec: 13062.586914\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.165921 Tokens per Sec: 13270.399414\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.136052 Tokens per Sec: 13265.140625\n",
      "\n",
      "Epoch Step: 2051 Loss: 0.856968 Tokens per Sec: 13264.048828\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.167331 Tokens per Sec: 13515.139648\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.022613 Tokens per Sec: 13274.564453\n",
      "\n",
      "Epoch Step: 1 Loss: 0.510989 Tokens per Sec: 11552.768555\n",
      "\n",
      "tensor(0.5873, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 0.933980 Tokens per Sec: 2373.186279\n",
      "\n",
      "Epoch Step: 51 Loss: 1.276623 Tokens per Sec: 13416.281250\n",
      "\n",
      "Epoch Step: 101 Loss: 1.021215 Tokens per Sec: 13411.071289\n",
      "\n",
      "Epoch Step: 151 Loss: 0.955238 Tokens per Sec: 13033.262695\n",
      "\n",
      "Epoch Step: 201 Loss: 0.949360 Tokens per Sec: 12930.766602\n",
      "\n",
      "Epoch Step: 251 Loss: 0.907538 Tokens per Sec: 13235.040039\n",
      "\n",
      "Epoch Step: 301 Loss: 1.042297 Tokens per Sec: 13315.984375\n",
      "\n",
      "Epoch Step: 351 Loss: 1.116820 Tokens per Sec: 13404.609375\n",
      "\n",
      "Epoch Step: 401 Loss: 0.918329 Tokens per Sec: 13643.333984\n",
      "\n",
      "Epoch Step: 451 Loss: 0.956122 Tokens per Sec: 13063.713867\n",
      "\n",
      "Epoch Step: 501 Loss: 1.043411 Tokens per Sec: 12998.280273\n",
      "\n",
      "Epoch Step: 551 Loss: 1.165378 Tokens per Sec: 12957.630859\n",
      "\n",
      "Epoch Step: 601 Loss: 1.105655 Tokens per Sec: 13295.488281\n",
      "\n",
      "Epoch Step: 651 Loss: 1.287697 Tokens per Sec: 13142.289062\n",
      "\n",
      "Epoch Step: 701 Loss: 1.002095 Tokens per Sec: 13479.461914\n",
      "\n",
      "Epoch Step: 751 Loss: 0.967930 Tokens per Sec: 13196.722656\n",
      "\n",
      "Epoch Step: 801 Loss: 1.073254 Tokens per Sec: 12870.022461\n",
      "\n",
      "Epoch Step: 851 Loss: 1.079556 Tokens per Sec: 12924.315430\n",
      "\n",
      "Epoch Step: 901 Loss: 0.961399 Tokens per Sec: 13025.369141\n",
      "\n",
      "Epoch Step: 951 Loss: 1.121454 Tokens per Sec: 13331.560547\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.150181 Tokens per Sec: 13091.538086\n",
      "\n",
      "Epoch Step: 1051 Loss: 0.962834 Tokens per Sec: 13528.356445\n",
      "\n",
      "Epoch Step: 1101 Loss: 0.927253 Tokens per Sec: 13645.451172\n",
      "\n",
      "Epoch Step: 1151 Loss: 0.980761 Tokens per Sec: 12792.161133\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.094486 Tokens per Sec: 12815.621094\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.256852 Tokens per Sec: 12431.834961\n",
      "\n",
      "Epoch Step: 1301 Loss: 0.988653 Tokens per Sec: 13339.427734\n",
      "\n",
      "Epoch Step: 1351 Loss: 0.938358 Tokens per Sec: 13586.697266\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.182230 Tokens per Sec: 13759.805664\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.014971 Tokens per Sec: 13791.570312\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.271249 Tokens per Sec: 13757.997070\n",
      "\n",
      "Epoch Step: 1551 Loss: 0.842430 Tokens per Sec: 14102.580078\n",
      "\n",
      "Epoch Step: 1601 Loss: 0.989216 Tokens per Sec: 14017.572266\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.051123 Tokens per Sec: 12873.558594\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.086955 Tokens per Sec: 12966.206055\n",
      "\n",
      "Epoch Step: 1751 Loss: 0.990261 Tokens per Sec: 13183.710938\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.078504 Tokens per Sec: 13166.181641\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.056277 Tokens per Sec: 13174.934570\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.119898 Tokens per Sec: 12892.481445\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.035712 Tokens per Sec: 13323.817383\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.319942 Tokens per Sec: 13513.636719\n",
      "\n",
      "Epoch Step: 2051 Loss: 0.961570 Tokens per Sec: 13085.906250\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.162365 Tokens per Sec: 13173.890625\n",
      "\n",
      "Epoch Step: 2151 Loss: 0.873406 Tokens per Sec: 13340.219727\n",
      "\n",
      "Epoch Step: 1 Loss: 0.511839 Tokens per Sec: 11900.887695\n",
      "\n",
      "tensor(0.5800, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 0.915562 Tokens per Sec: 2525.853271\n",
      "\n",
      "Epoch Step: 51 Loss: 0.941468 Tokens per Sec: 13133.742188\n",
      "\n",
      "Epoch Step: 101 Loss: 1.030164 Tokens per Sec: 13179.910156\n",
      "\n",
      "Epoch Step: 151 Loss: 0.776377 Tokens per Sec: 13307.602539\n",
      "\n",
      "Epoch Step: 201 Loss: 0.961503 Tokens per Sec: 13209.445312\n",
      "\n",
      "Epoch Step: 251 Loss: 1.265400 Tokens per Sec: 13371.666992\n",
      "\n",
      "Epoch Step: 301 Loss: 1.152598 Tokens per Sec: 13130.075195\n",
      "\n",
      "Epoch Step: 351 Loss: 1.065593 Tokens per Sec: 13038.977539\n",
      "\n",
      "Epoch Step: 401 Loss: 1.012773 Tokens per Sec: 12997.859375\n",
      "\n",
      "Epoch Step: 451 Loss: 0.896028 Tokens per Sec: 13120.368164\n",
      "\n",
      "Epoch Step: 501 Loss: 1.110105 Tokens per Sec: 13140.528320\n",
      "\n",
      "Epoch Step: 551 Loss: 0.863133 Tokens per Sec: 13551.610352\n",
      "\n",
      "Epoch Step: 601 Loss: 1.117275 Tokens per Sec: 12993.726562\n",
      "\n",
      "Epoch Step: 651 Loss: 1.097935 Tokens per Sec: 12838.912109\n",
      "\n",
      "Epoch Step: 701 Loss: 1.232531 Tokens per Sec: 13603.357422\n",
      "\n",
      "Epoch Step: 751 Loss: 0.970342 Tokens per Sec: 13270.911133\n",
      "\n",
      "Epoch Step: 801 Loss: 1.064123 Tokens per Sec: 13610.592773\n",
      "\n",
      "Epoch Step: 851 Loss: 1.002511 Tokens per Sec: 13268.244141\n",
      "\n",
      "Epoch Step: 901 Loss: 0.969029 Tokens per Sec: 13179.882812\n",
      "\n",
      "Epoch Step: 951 Loss: 1.063717 Tokens per Sec: 13018.654297\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.071571 Tokens per Sec: 13119.354492\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.040450 Tokens per Sec: 12823.558594\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.003187 Tokens per Sec: 13106.270508\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.287992 Tokens per Sec: 12706.232422\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.102478 Tokens per Sec: 13104.883789\n",
      "\n",
      "Epoch Step: 1251 Loss: 0.866283 Tokens per Sec: 14066.350586\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.060545 Tokens per Sec: 12801.784180\n",
      "\n",
      "Epoch Step: 1351 Loss: 0.998347 Tokens per Sec: 12515.512695\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.209127 Tokens per Sec: 12289.878906\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.136338 Tokens per Sec: 13008.177734\n",
      "\n",
      "Epoch Step: 1501 Loss: 0.987469 Tokens per Sec: 13756.259766\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.049972 Tokens per Sec: 13482.541992\n",
      "\n",
      "Epoch Step: 1601 Loss: 0.995851 Tokens per Sec: 13120.954102\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.047646 Tokens per Sec: 13890.726562\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.081715 Tokens per Sec: 13958.159180\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.102823 Tokens per Sec: 14295.554688\n",
      "\n",
      "Epoch Step: 1801 Loss: 0.958989 Tokens per Sec: 13472.529297\n",
      "\n",
      "Epoch Step: 1851 Loss: 0.881812 Tokens per Sec: 13230.405273\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.129874 Tokens per Sec: 13074.623047\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.028957 Tokens per Sec: 13151.985352\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.205173 Tokens per Sec: 13494.961914\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.168617 Tokens per Sec: 13438.521484\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.331753 Tokens per Sec: 13335.511719\n",
      "\n",
      "Epoch Step: 2151 Loss: 0.884555 Tokens per Sec: 13445.149414\n",
      "\n",
      "Epoch Step: 1 Loss: 0.512658 Tokens per Sec: 10926.917969\n",
      "\n",
      "tensor(0.5871, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 0.982705 Tokens per Sec: 2713.604492\n",
      "\n",
      "Epoch Step: 51 Loss: 1.062933 Tokens per Sec: 13727.001953\n",
      "\n",
      "Epoch Step: 101 Loss: 1.067733 Tokens per Sec: 13535.881836\n",
      "\n",
      "Epoch Step: 151 Loss: 1.126034 Tokens per Sec: 13631.869141\n",
      "\n",
      "Epoch Step: 201 Loss: 1.057312 Tokens per Sec: 13071.170898\n",
      "\n",
      "Epoch Step: 251 Loss: 1.087616 Tokens per Sec: 13340.085938\n",
      "\n",
      "Epoch Step: 301 Loss: 0.981595 Tokens per Sec: 13204.841797\n",
      "\n",
      "Epoch Step: 351 Loss: 1.007653 Tokens per Sec: 13500.018555\n",
      "\n",
      "Epoch Step: 401 Loss: 1.125514 Tokens per Sec: 13078.688477\n",
      "\n",
      "Epoch Step: 451 Loss: 0.930056 Tokens per Sec: 13083.568359\n",
      "\n",
      "Epoch Step: 501 Loss: 1.024417 Tokens per Sec: 12802.549805\n",
      "\n",
      "Epoch Step: 551 Loss: 0.786385 Tokens per Sec: 13594.349609\n",
      "\n",
      "Epoch Step: 601 Loss: 0.819561 Tokens per Sec: 13144.520508\n",
      "\n",
      "Epoch Step: 651 Loss: 0.839815 Tokens per Sec: 13334.771484\n",
      "\n",
      "Epoch Step: 701 Loss: 1.097006 Tokens per Sec: 13200.042969\n",
      "\n",
      "Epoch Step: 751 Loss: 1.081615 Tokens per Sec: 13363.363281\n",
      "\n",
      "Epoch Step: 801 Loss: 1.222541 Tokens per Sec: 13317.725586\n",
      "\n",
      "Epoch Step: 851 Loss: 1.151554 Tokens per Sec: 13179.246094\n",
      "\n",
      "Epoch Step: 901 Loss: 0.995811 Tokens per Sec: 13495.493164\n",
      "\n",
      "Epoch Step: 951 Loss: 0.742300 Tokens per Sec: 13492.313477\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.050143 Tokens per Sec: 13046.088867\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.022357 Tokens per Sec: 12668.469727\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.081702 Tokens per Sec: 12736.578125\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.042787 Tokens per Sec: 13576.432617\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.110868 Tokens per Sec: 13202.400391\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.191443 Tokens per Sec: 12880.142578\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.021888 Tokens per Sec: 13518.117188\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.126120 Tokens per Sec: 12805.287109\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.056542 Tokens per Sec: 13400.318359\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.213529 Tokens per Sec: 13652.050781\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.336079 Tokens per Sec: 12674.129883\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.037287 Tokens per Sec: 12708.359375\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.150414 Tokens per Sec: 12154.429688\n",
      "\n",
      "Epoch Step: 1651 Loss: 0.958504 Tokens per Sec: 13543.733398\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.293004 Tokens per Sec: 14029.006836\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.139021 Tokens per Sec: 13761.590820\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.087201 Tokens per Sec: 13726.752930\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.128100 Tokens per Sec: 13668.700195\n",
      "\n",
      "Epoch Step: 1901 Loss: 0.892720 Tokens per Sec: 13541.116211\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.140899 Tokens per Sec: 13805.083008\n",
      "\n",
      "Epoch Step: 2001 Loss: 0.921322 Tokens per Sec: 13370.710938\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.145918 Tokens per Sec: 13289.791992\n",
      "\n",
      "Epoch Step: 2101 Loss: 0.964257 Tokens per Sec: 13447.563477\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.151154 Tokens per Sec: 13409.459961\n",
      "\n",
      "Epoch Step: 1 Loss: 0.511857 Tokens per Sec: 10708.748047\n",
      "\n",
      "tensor(0.5778, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 0.879424 Tokens per Sec: 2695.501221\n",
      "\n",
      "Epoch Step: 51 Loss: 1.026526 Tokens per Sec: 13430.062500\n",
      "\n",
      "Epoch Step: 101 Loss: 1.097847 Tokens per Sec: 13281.341797\n",
      "\n",
      "Epoch Step: 151 Loss: 0.869856 Tokens per Sec: 13002.826172\n",
      "\n",
      "Epoch Step: 201 Loss: 0.937856 Tokens per Sec: 13322.828125\n",
      "\n",
      "Epoch Step: 251 Loss: 0.989137 Tokens per Sec: 13339.475586\n",
      "\n",
      "Epoch Step: 301 Loss: 0.770787 Tokens per Sec: 13009.974609\n",
      "\n",
      "Epoch Step: 351 Loss: 1.080768 Tokens per Sec: 12959.448242\n",
      "\n",
      "Epoch Step: 401 Loss: 1.153981 Tokens per Sec: 13087.664062\n",
      "\n",
      "Epoch Step: 451 Loss: 1.020458 Tokens per Sec: 13178.192383\n",
      "\n",
      "Epoch Step: 501 Loss: 1.243628 Tokens per Sec: 12813.745117\n",
      "\n",
      "Epoch Step: 551 Loss: 0.918890 Tokens per Sec: 13460.730469\n",
      "\n",
      "Epoch Step: 601 Loss: 1.181695 Tokens per Sec: 13535.327148\n",
      "\n",
      "Epoch Step: 651 Loss: 0.860654 Tokens per Sec: 13206.568359\n",
      "\n",
      "Epoch Step: 701 Loss: 0.947556 Tokens per Sec: 13454.983398\n",
      "\n",
      "Epoch Step: 751 Loss: 0.958754 Tokens per Sec: 12918.889648\n",
      "\n",
      "Epoch Step: 801 Loss: 0.911691 Tokens per Sec: 13028.578125\n",
      "\n",
      "Epoch Step: 851 Loss: 1.073653 Tokens per Sec: 13231.248047\n",
      "\n",
      "Epoch Step: 901 Loss: 0.833597 Tokens per Sec: 12998.499023\n",
      "\n",
      "Epoch Step: 951 Loss: 1.252749 Tokens per Sec: 13307.437500\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.076101 Tokens per Sec: 13597.576172\n",
      "\n",
      "Epoch Step: 1051 Loss: 0.973353 Tokens per Sec: 13157.175781\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.053875 Tokens per Sec: 13222.248047\n",
      "\n",
      "Epoch Step: 1151 Loss: 0.973883 Tokens per Sec: 13514.962891\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.060381 Tokens per Sec: 12757.282227\n",
      "\n",
      "Epoch Step: 1251 Loss: 0.743450 Tokens per Sec: 13089.932617\n",
      "\n",
      "Epoch Step: 1301 Loss: 0.993855 Tokens per Sec: 13365.213867\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.003661 Tokens per Sec: 12862.690430\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.277562 Tokens per Sec: 13092.249023\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.102681 Tokens per Sec: 13020.925781\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.381067 Tokens per Sec: 13218.881836\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.049705 Tokens per Sec: 13149.615234\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.041379 Tokens per Sec: 13425.158203\n",
      "\n",
      "Epoch Step: 1651 Loss: 0.995250 Tokens per Sec: 12910.972656\n",
      "\n",
      "Epoch Step: 1701 Loss: 0.997661 Tokens per Sec: 12447.921875\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.227684 Tokens per Sec: 11951.884766\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.088433 Tokens per Sec: 12887.568359\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.232472 Tokens per Sec: 13687.464844\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.083204 Tokens per Sec: 13852.753906\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.034555 Tokens per Sec: 13762.468750\n",
      "\n",
      "Epoch Step: 2001 Loss: 0.944116 Tokens per Sec: 13836.214844\n",
      "\n",
      "Epoch Step: 2051 Loss: 0.959866 Tokens per Sec: 13701.839844\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.130431 Tokens per Sec: 13988.889648\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.216370 Tokens per Sec: 13482.809570\n",
      "\n",
      "Epoch Step: 1 Loss: 0.496896 Tokens per Sec: 11509.162109\n",
      "\n",
      "tensor(0.5713, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 0.924635 Tokens per Sec: 2798.654785\n",
      "\n",
      "Epoch Step: 51 Loss: 1.129970 Tokens per Sec: 13082.553711\n",
      "\n",
      "Epoch Step: 101 Loss: 0.995527 Tokens per Sec: 13260.523438\n",
      "\n",
      "Epoch Step: 151 Loss: 0.988529 Tokens per Sec: 13357.815430\n",
      "\n",
      "Epoch Step: 201 Loss: 1.058675 Tokens per Sec: 13321.510742\n",
      "\n",
      "Epoch Step: 251 Loss: 0.955936 Tokens per Sec: 13334.758789\n",
      "\n",
      "Epoch Step: 301 Loss: 0.903349 Tokens per Sec: 13326.392578\n",
      "\n",
      "Epoch Step: 351 Loss: 0.896628 Tokens per Sec: 12943.367188\n",
      "\n",
      "Epoch Step: 401 Loss: 0.920472 Tokens per Sec: 13204.693359\n",
      "\n",
      "Epoch Step: 451 Loss: 1.034765 Tokens per Sec: 12753.337891\n",
      "\n",
      "Epoch Step: 501 Loss: 0.711215 Tokens per Sec: 12985.217773\n",
      "\n",
      "Epoch Step: 551 Loss: 1.162595 Tokens per Sec: 13041.916016\n",
      "\n",
      "Epoch Step: 601 Loss: 1.117998 Tokens per Sec: 13158.672852\n",
      "\n",
      "Epoch Step: 651 Loss: 1.112935 Tokens per Sec: 13351.341797\n",
      "\n",
      "Epoch Step: 701 Loss: 0.926948 Tokens per Sec: 13377.375000\n",
      "\n",
      "Epoch Step: 751 Loss: 0.954019 Tokens per Sec: 13273.411133\n",
      "\n",
      "Epoch Step: 801 Loss: 1.065922 Tokens per Sec: 12744.742188\n",
      "\n",
      "Epoch Step: 851 Loss: 1.195133 Tokens per Sec: 13297.374023\n",
      "\n",
      "Epoch Step: 901 Loss: 0.941076 Tokens per Sec: 12798.312500\n",
      "\n",
      "Epoch Step: 951 Loss: 1.167496 Tokens per Sec: 13528.998047\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.040175 Tokens per Sec: 13132.979492\n",
      "\n",
      "Epoch Step: 1051 Loss: 0.908666 Tokens per Sec: 13135.703125\n",
      "\n",
      "Epoch Step: 1101 Loss: 0.964028 Tokens per Sec: 13106.460938\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.132426 Tokens per Sec: 12491.949219\n",
      "\n",
      "Epoch Step: 1201 Loss: 0.950378 Tokens per Sec: 12759.138672\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.175361 Tokens per Sec: 13254.177734\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.331482 Tokens per Sec: 13034.715820\n",
      "\n",
      "Epoch Step: 1351 Loss: 0.909186 Tokens per Sec: 13044.533203\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.096997 Tokens per Sec: 13486.403320\n",
      "\n",
      "Epoch Step: 1451 Loss: 0.962614 Tokens per Sec: 13110.833008\n",
      "\n",
      "Epoch Step: 1501 Loss: 0.940984 Tokens per Sec: 12990.978516\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.003144 Tokens per Sec: 13160.427734\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.369141 Tokens per Sec: 13038.790039\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.030984 Tokens per Sec: 13203.684570\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.055114 Tokens per Sec: 13466.570312\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.113293 Tokens per Sec: 13831.664062\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.160418 Tokens per Sec: 12762.449219\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.066143 Tokens per Sec: 12274.245117\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.097227 Tokens per Sec: 12939.963867\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.138702 Tokens per Sec: 12623.310547\n",
      "\n",
      "Epoch Step: 2001 Loss: 0.957034 Tokens per Sec: 13468.792969\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.160872 Tokens per Sec: 13584.724609\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.186814 Tokens per Sec: 13742.833008\n",
      "\n",
      "Epoch Step: 2151 Loss: 0.947287 Tokens per Sec: 13603.256836\n",
      "\n",
      "Epoch Step: 1 Loss: 0.498247 Tokens per Sec: 11527.729492\n",
      "\n",
      "tensor(0.5680, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 0.956460 Tokens per Sec: 2741.303955\n",
      "\n",
      "Epoch Step: 51 Loss: 1.091924 Tokens per Sec: 14017.837891\n",
      "\n",
      "Epoch Step: 101 Loss: 0.929600 Tokens per Sec: 13269.079102\n",
      "\n",
      "Epoch Step: 151 Loss: 1.064081 Tokens per Sec: 13348.486328\n",
      "\n",
      "Epoch Step: 201 Loss: 0.936182 Tokens per Sec: 13299.064453\n",
      "\n",
      "Epoch Step: 251 Loss: 0.961709 Tokens per Sec: 13210.039062\n",
      "\n",
      "Epoch Step: 301 Loss: 0.922108 Tokens per Sec: 12717.152344\n",
      "\n",
      "Epoch Step: 351 Loss: 1.040242 Tokens per Sec: 13262.770508\n",
      "\n",
      "Epoch Step: 401 Loss: 0.846001 Tokens per Sec: 13247.270508\n",
      "\n",
      "Epoch Step: 451 Loss: 0.906050 Tokens per Sec: 13183.822266\n",
      "\n",
      "Epoch Step: 501 Loss: 1.150002 Tokens per Sec: 13357.178711\n",
      "\n",
      "Epoch Step: 551 Loss: 0.996367 Tokens per Sec: 13534.422852\n",
      "\n",
      "Epoch Step: 601 Loss: 0.869647 Tokens per Sec: 13193.780273\n",
      "\n",
      "Epoch Step: 651 Loss: 0.815585 Tokens per Sec: 13257.437500\n",
      "\n",
      "Epoch Step: 701 Loss: 1.148001 Tokens per Sec: 13281.048828\n",
      "\n",
      "Epoch Step: 751 Loss: 1.011958 Tokens per Sec: 13523.693359\n",
      "\n",
      "Epoch Step: 801 Loss: 1.031905 Tokens per Sec: 12997.055664\n",
      "\n",
      "Epoch Step: 851 Loss: 1.012877 Tokens per Sec: 13267.818359\n",
      "\n",
      "Epoch Step: 901 Loss: 1.146697 Tokens per Sec: 13330.301758\n",
      "\n",
      "Epoch Step: 951 Loss: 0.817963 Tokens per Sec: 13219.596680\n",
      "\n",
      "Epoch Step: 1001 Loss: 0.973186 Tokens per Sec: 13325.501953\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.055664 Tokens per Sec: 13639.782227\n",
      "\n",
      "Epoch Step: 1101 Loss: 0.825580 Tokens per Sec: 13423.829102\n",
      "\n",
      "Epoch Step: 1151 Loss: 0.991311 Tokens per Sec: 13234.606445\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.114881 Tokens per Sec: 13201.891602\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.022297 Tokens per Sec: 13274.895508\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.142925 Tokens per Sec: 12987.700195\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.096859 Tokens per Sec: 13201.381836\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.025362 Tokens per Sec: 13099.301758\n",
      "\n",
      "Epoch Step: 1451 Loss: 0.948728 Tokens per Sec: 13371.899414\n",
      "\n",
      "Epoch Step: 1501 Loss: 0.805492 Tokens per Sec: 13264.000000\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.084371 Tokens per Sec: 13149.370117\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.092230 Tokens per Sec: 13474.568359\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.191428 Tokens per Sec: 13060.917969\n",
      "\n",
      "Epoch Step: 1701 Loss: 0.923079 Tokens per Sec: 13278.263672\n",
      "\n",
      "Epoch Step: 1751 Loss: 0.921920 Tokens per Sec: 13372.370117\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.144963 Tokens per Sec: 13383.812500\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.055675 Tokens per Sec: 13339.747070\n",
      "\n",
      "Epoch Step: 1901 Loss: 0.968028 Tokens per Sec: 13501.047852\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.147490 Tokens per Sec: 13349.667969\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.017596 Tokens per Sec: 12978.189453\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.246037 Tokens per Sec: 12322.585938\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.052420 Tokens per Sec: 12431.299805\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.238606 Tokens per Sec: 12729.763672\n",
      "\n",
      "Epoch Step: 1 Loss: 0.506324 Tokens per Sec: 11885.861328\n",
      "\n",
      "tensor(0.5643, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 0.879350 Tokens per Sec: 2263.431641\n",
      "\n",
      "Epoch Step: 51 Loss: 1.048542 Tokens per Sec: 13228.745117\n",
      "\n",
      "Epoch Step: 101 Loss: 0.989108 Tokens per Sec: 12912.041016\n",
      "\n",
      "Epoch Step: 151 Loss: 1.006405 Tokens per Sec: 13534.894531\n",
      "\n",
      "Epoch Step: 201 Loss: 1.164408 Tokens per Sec: 13631.996094\n",
      "\n",
      "Epoch Step: 251 Loss: 0.868873 Tokens per Sec: 13161.640625\n",
      "\n",
      "Epoch Step: 301 Loss: 0.913707 Tokens per Sec: 13438.488281\n",
      "\n",
      "Epoch Step: 351 Loss: 0.950723 Tokens per Sec: 13295.032227\n",
      "\n",
      "Epoch Step: 401 Loss: 1.038701 Tokens per Sec: 12899.191406\n",
      "\n",
      "Epoch Step: 451 Loss: 0.960398 Tokens per Sec: 13208.242188\n",
      "\n",
      "Epoch Step: 501 Loss: 0.840566 Tokens per Sec: 13166.414062\n",
      "\n",
      "Epoch Step: 551 Loss: 1.066412 Tokens per Sec: 13662.938477\n",
      "\n",
      "Epoch Step: 601 Loss: 1.130803 Tokens per Sec: 13479.484375\n",
      "\n",
      "Epoch Step: 651 Loss: 1.088611 Tokens per Sec: 13479.254883\n",
      "\n",
      "Epoch Step: 701 Loss: 0.948568 Tokens per Sec: 13117.562500\n",
      "\n",
      "Epoch Step: 751 Loss: 0.997116 Tokens per Sec: 13563.788086\n",
      "\n",
      "Epoch Step: 801 Loss: 1.035830 Tokens per Sec: 13220.352539\n",
      "\n",
      "Epoch Step: 851 Loss: 1.075501 Tokens per Sec: 13342.043945\n",
      "\n",
      "Epoch Step: 901 Loss: 0.882249 Tokens per Sec: 13198.459961\n",
      "\n",
      "Epoch Step: 951 Loss: 1.035492 Tokens per Sec: 13235.042969\n",
      "\n",
      "Epoch Step: 1001 Loss: 0.887691 Tokens per Sec: 12958.678711\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.063092 Tokens per Sec: 12921.791016\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.064698 Tokens per Sec: 12787.622070\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.169634 Tokens per Sec: 13196.344727\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.053830 Tokens per Sec: 13298.646484\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.042577 Tokens per Sec: 13272.543945\n",
      "\n",
      "Epoch Step: 1301 Loss: 0.829805 Tokens per Sec: 12952.003906\n",
      "\n",
      "Epoch Step: 1351 Loss: 0.986538 Tokens per Sec: 13287.050781\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.079914 Tokens per Sec: 13390.129883\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.007759 Tokens per Sec: 13251.690430\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.112540 Tokens per Sec: 13277.553711\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.008831 Tokens per Sec: 13369.939453\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.136158 Tokens per Sec: 13278.364258\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.102914 Tokens per Sec: 13192.775391\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.066822 Tokens per Sec: 13323.352539\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.251919 Tokens per Sec: 13236.851562\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.125111 Tokens per Sec: 13069.929688\n",
      "\n",
      "Epoch Step: 1851 Loss: 0.983109 Tokens per Sec: 13501.791016\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.076447 Tokens per Sec: 13098.891602\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.032043 Tokens per Sec: 12845.262695\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.307517 Tokens per Sec: 13135.440430\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.036944 Tokens per Sec: 13593.615234\n",
      "\n",
      "Epoch Step: 2101 Loss: 0.986694 Tokens per Sec: 13120.038086\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.060996 Tokens per Sec: 12741.963867\n",
      "\n",
      "Epoch Step: 1 Loss: 0.483091 Tokens per Sec: 10682.446289\n",
      "\n",
      "tensor(0.5548, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.146143 Tokens per Sec: 2290.002686\n",
      "\n",
      "Epoch Step: 51 Loss: 0.972477 Tokens per Sec: 12686.294922\n",
      "\n",
      "Epoch Step: 101 Loss: 0.889713 Tokens per Sec: 12129.757812\n",
      "\n",
      "Epoch Step: 151 Loss: 1.012644 Tokens per Sec: 13580.311523\n",
      "\n",
      "Epoch Step: 201 Loss: 0.872088 Tokens per Sec: 13865.423828\n",
      "\n",
      "Epoch Step: 251 Loss: 0.865969 Tokens per Sec: 14153.059570\n",
      "\n",
      "Epoch Step: 301 Loss: 0.887622 Tokens per Sec: 14097.084961\n",
      "\n",
      "Epoch Step: 351 Loss: 0.963496 Tokens per Sec: 14051.918945\n",
      "\n",
      "Epoch Step: 401 Loss: 0.993351 Tokens per Sec: 13457.930664\n",
      "\n",
      "Epoch Step: 451 Loss: 0.925073 Tokens per Sec: 13782.883789\n",
      "\n",
      "Epoch Step: 501 Loss: 1.052101 Tokens per Sec: 13255.181641\n",
      "\n",
      "Epoch Step: 551 Loss: 1.209868 Tokens per Sec: 13214.207031\n",
      "\n",
      "Epoch Step: 601 Loss: 0.890610 Tokens per Sec: 13225.778320\n",
      "\n",
      "Epoch Step: 651 Loss: 1.166876 Tokens per Sec: 13507.676758\n",
      "\n",
      "Epoch Step: 701 Loss: 0.918902 Tokens per Sec: 13431.509766\n",
      "\n",
      "Epoch Step: 751 Loss: 0.851917 Tokens per Sec: 13072.335938\n",
      "\n",
      "Epoch Step: 801 Loss: 0.901304 Tokens per Sec: 13470.055664\n",
      "\n",
      "Epoch Step: 851 Loss: 1.013024 Tokens per Sec: 13434.373047\n",
      "\n",
      "Epoch Step: 901 Loss: 0.856466 Tokens per Sec: 13476.496094\n",
      "\n",
      "Epoch Step: 951 Loss: 0.972813 Tokens per Sec: 13288.822266\n",
      "\n",
      "Epoch Step: 1001 Loss: 0.896500 Tokens per Sec: 13389.301758\n",
      "\n",
      "Epoch Step: 1051 Loss: 0.964662 Tokens per Sec: 13365.302734\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.140568 Tokens per Sec: 13035.489258\n",
      "\n",
      "Epoch Step: 1151 Loss: 0.965053 Tokens per Sec: 13066.392578\n",
      "\n",
      "Epoch Step: 1201 Loss: 0.942723 Tokens per Sec: 12725.716797\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.140151 Tokens per Sec: 13274.419922\n",
      "\n",
      "Epoch Step: 1301 Loss: 0.927758 Tokens per Sec: 12977.903320\n",
      "\n",
      "Epoch Step: 1351 Loss: 0.955973 Tokens per Sec: 13091.666992\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.026006 Tokens per Sec: 12694.895508\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.197516 Tokens per Sec: 13250.117188\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.059358 Tokens per Sec: 13439.189453\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.068672 Tokens per Sec: 13192.986328\n",
      "\n",
      "Epoch Step: 1601 Loss: 0.803135 Tokens per Sec: 13230.326172\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.157274 Tokens per Sec: 13079.226562\n",
      "\n",
      "Epoch Step: 1701 Loss: 0.839365 Tokens per Sec: 13116.664062\n",
      "\n",
      "Epoch Step: 1751 Loss: 0.903817 Tokens per Sec: 13408.638672\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.001172 Tokens per Sec: 13378.236328\n",
      "\n",
      "Epoch Step: 1851 Loss: 0.977401 Tokens per Sec: 13136.601562\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.117780 Tokens per Sec: 13008.331055\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.038222 Tokens per Sec: 13115.457031\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.134701 Tokens per Sec: 12920.925781\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.221886 Tokens per Sec: 13058.119141\n",
      "\n",
      "Epoch Step: 2101 Loss: 0.759569 Tokens per Sec: 13409.435547\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.055377 Tokens per Sec: 13472.671875\n",
      "\n",
      "Epoch Step: 1 Loss: 0.482108 Tokens per Sec: 11693.598633\n",
      "\n",
      "tensor(0.5535, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 0.765533 Tokens per Sec: 2755.668701\n",
      "\n",
      "Epoch Step: 51 Loss: 1.076536 Tokens per Sec: 13495.096680\n",
      "\n",
      "Epoch Step: 101 Loss: 1.166598 Tokens per Sec: 12711.753906\n",
      "\n",
      "Epoch Step: 151 Loss: 1.034857 Tokens per Sec: 12263.352539\n",
      "\n",
      "Epoch Step: 201 Loss: 0.998230 Tokens per Sec: 12623.183594\n",
      "\n",
      "Epoch Step: 251 Loss: 0.956275 Tokens per Sec: 12309.569336\n",
      "\n",
      "Epoch Step: 301 Loss: 0.959249 Tokens per Sec: 13024.655273\n",
      "\n",
      "Epoch Step: 351 Loss: 0.797244 Tokens per Sec: 13725.962891\n",
      "\n",
      "Epoch Step: 401 Loss: 0.995945 Tokens per Sec: 13498.312500\n",
      "\n",
      "Epoch Step: 451 Loss: 1.075233 Tokens per Sec: 12866.992188\n",
      "\n",
      "Epoch Step: 501 Loss: 1.029062 Tokens per Sec: 13386.969727\n",
      "\n",
      "Epoch Step: 551 Loss: 1.204891 Tokens per Sec: 13375.641602\n",
      "\n",
      "Epoch Step: 601 Loss: 0.965056 Tokens per Sec: 13428.119141\n",
      "\n",
      "Epoch Step: 651 Loss: 0.842981 Tokens per Sec: 13420.186523\n",
      "\n",
      "Epoch Step: 701 Loss: 1.121547 Tokens per Sec: 13592.956055\n",
      "\n",
      "Epoch Step: 751 Loss: 0.962748 Tokens per Sec: 13428.379883\n",
      "\n",
      "Epoch Step: 801 Loss: 0.951602 Tokens per Sec: 13388.538086\n",
      "\n",
      "Epoch Step: 851 Loss: 0.977783 Tokens per Sec: 12997.555664\n",
      "\n",
      "Epoch Step: 901 Loss: 1.232832 Tokens per Sec: 13367.231445\n",
      "\n",
      "Epoch Step: 951 Loss: 1.010926 Tokens per Sec: 13324.118164\n",
      "\n",
      "Epoch Step: 1001 Loss: 0.946359 Tokens per Sec: 13194.112305\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.143268 Tokens per Sec: 13287.522461\n",
      "\n",
      "Epoch Step: 1101 Loss: 0.907176 Tokens per Sec: 13153.893555\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.115093 Tokens per Sec: 13240.909180\n",
      "\n",
      "Epoch Step: 1201 Loss: 0.915177 Tokens per Sec: 13021.825195\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.118350 Tokens per Sec: 12870.839844\n",
      "\n",
      "Epoch Step: 1301 Loss: 0.905475 Tokens per Sec: 13318.049805\n",
      "\n",
      "Epoch Step: 1351 Loss: 0.874201 Tokens per Sec: 13302.261719\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.011143 Tokens per Sec: 13197.157227\n",
      "\n",
      "Epoch Step: 1451 Loss: 0.919912 Tokens per Sec: 13063.811523\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.187513 Tokens per Sec: 13657.083984\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.058138 Tokens per Sec: 13332.789062\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.050494 Tokens per Sec: 12670.909180\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.325897 Tokens per Sec: 13145.043945\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.003368 Tokens per Sec: 13095.726562\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.105857 Tokens per Sec: 13024.451172\n",
      "\n",
      "Epoch Step: 1801 Loss: 0.935027 Tokens per Sec: 13482.525391\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.002518 Tokens per Sec: 13198.656250\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.037880 Tokens per Sec: 12971.200195\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.013394 Tokens per Sec: 13085.866211\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.040384 Tokens per Sec: 12906.678711\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.141078 Tokens per Sec: 13150.593750\n",
      "\n",
      "Epoch Step: 2101 Loss: 0.797879 Tokens per Sec: 13374.388672\n",
      "\n",
      "Epoch Step: 2151 Loss: 0.979359 Tokens per Sec: 13081.656250\n",
      "\n",
      "Epoch Step: 1 Loss: 0.471332 Tokens per Sec: 11119.186523\n",
      "\n",
      "tensor(0.5497, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 0.995244 Tokens per Sec: 2841.396729\n",
      "\n",
      "Epoch Step: 51 Loss: 0.960208 Tokens per Sec: 13628.988281\n",
      "\n",
      "Epoch Step: 101 Loss: 0.906776 Tokens per Sec: 13172.831055\n",
      "\n",
      "Epoch Step: 151 Loss: 1.095033 Tokens per Sec: 13297.831055\n",
      "\n",
      "Epoch Step: 201 Loss: 0.986775 Tokens per Sec: 13319.865234\n",
      "\n",
      "Epoch Step: 251 Loss: 0.830020 Tokens per Sec: 13725.789062\n",
      "\n",
      "Epoch Step: 301 Loss: 0.858701 Tokens per Sec: 12819.742188\n",
      "\n",
      "Epoch Step: 351 Loss: 0.785676 Tokens per Sec: 12322.229492\n",
      "\n",
      "Epoch Step: 401 Loss: 1.198294 Tokens per Sec: 12482.174805\n",
      "\n",
      "Epoch Step: 451 Loss: 1.068415 Tokens per Sec: 12162.624023\n",
      "\n",
      "Epoch Step: 501 Loss: 1.053855 Tokens per Sec: 13304.888672\n",
      "\n",
      "Epoch Step: 551 Loss: 1.062883 Tokens per Sec: 13355.845703\n",
      "\n",
      "Epoch Step: 601 Loss: 0.885050 Tokens per Sec: 13904.495117\n",
      "\n",
      "Epoch Step: 651 Loss: 0.994866 Tokens per Sec: 13700.366211\n",
      "\n",
      "Epoch Step: 701 Loss: 1.020311 Tokens per Sec: 13926.769531\n",
      "\n",
      "Epoch Step: 751 Loss: 0.684251 Tokens per Sec: 13855.711914\n",
      "\n",
      "Epoch Step: 801 Loss: 1.091464 Tokens per Sec: 13141.826172\n",
      "\n",
      "Epoch Step: 851 Loss: 1.006568 Tokens per Sec: 13127.701172\n",
      "\n",
      "Epoch Step: 901 Loss: 0.865348 Tokens per Sec: 13468.196289\n",
      "\n",
      "Epoch Step: 951 Loss: 1.282295 Tokens per Sec: 13408.603516\n",
      "\n",
      "Epoch Step: 1001 Loss: 0.842921 Tokens per Sec: 13366.133789\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.016263 Tokens per Sec: 13113.880859\n",
      "\n",
      "Epoch Step: 1101 Loss: 0.934363 Tokens per Sec: 13303.706055\n",
      "\n",
      "Epoch Step: 1151 Loss: 0.931731 Tokens per Sec: 13384.978516\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.225138 Tokens per Sec: 13315.279297\n",
      "\n",
      "Epoch Step: 1251 Loss: 0.932829 Tokens per Sec: 13301.646484\n",
      "\n",
      "Epoch Step: 1301 Loss: 0.980848 Tokens per Sec: 13510.598633\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.156265 Tokens per Sec: 13510.483398\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.032506 Tokens per Sec: 13050.305664\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.051483 Tokens per Sec: 13300.289062\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.102268 Tokens per Sec: 13212.676758\n",
      "\n",
      "Epoch Step: 1551 Loss: 0.952016 Tokens per Sec: 13119.586914\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.088190 Tokens per Sec: 13549.161133\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.185014 Tokens per Sec: 13452.022461\n",
      "\n",
      "Epoch Step: 1701 Loss: 0.955275 Tokens per Sec: 13062.878906\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.048819 Tokens per Sec: 13296.310547\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.062671 Tokens per Sec: 13478.728516\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.135219 Tokens per Sec: 13318.416992\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.037352 Tokens per Sec: 13398.276367\n",
      "\n",
      "Epoch Step: 1951 Loss: 0.910188 Tokens per Sec: 13796.523438\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.202265 Tokens per Sec: 13468.458008\n",
      "\n",
      "Epoch Step: 2051 Loss: 0.925775 Tokens per Sec: 13506.736328\n",
      "\n",
      "Epoch Step: 2101 Loss: 0.963073 Tokens per Sec: 13190.344727\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.093668 Tokens per Sec: 13533.444336\n",
      "\n",
      "Epoch Step: 1 Loss: 0.490208 Tokens per Sec: 11416.577148\n",
      "\n",
      "tensor(0.5500, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.020546 Tokens per Sec: 2670.753662\n",
      "\n",
      "Epoch Step: 51 Loss: 0.825530 Tokens per Sec: 13395.280273\n",
      "\n",
      "Epoch Step: 101 Loss: 1.075936 Tokens per Sec: 13071.394531\n",
      "\n",
      "Epoch Step: 151 Loss: 1.013609 Tokens per Sec: 13243.914062\n",
      "\n",
      "Epoch Step: 201 Loss: 0.997148 Tokens per Sec: 13124.393555\n",
      "\n",
      "Epoch Step: 251 Loss: 0.722106 Tokens per Sec: 13522.820312\n",
      "\n",
      "Epoch Step: 301 Loss: 0.961069 Tokens per Sec: 13182.128906\n",
      "\n",
      "Epoch Step: 351 Loss: 0.955190 Tokens per Sec: 13707.546875\n",
      "\n",
      "Epoch Step: 401 Loss: 0.960075 Tokens per Sec: 13369.860352\n",
      "\n",
      "Epoch Step: 451 Loss: 0.921376 Tokens per Sec: 13238.408203\n",
      "\n",
      "Epoch Step: 501 Loss: 1.103077 Tokens per Sec: 12338.841797\n",
      "\n",
      "Epoch Step: 551 Loss: 1.044849 Tokens per Sec: 12628.998047\n",
      "\n",
      "Epoch Step: 601 Loss: 0.919910 Tokens per Sec: 12319.526367\n",
      "\n",
      "Epoch Step: 651 Loss: 0.977956 Tokens per Sec: 13310.434570\n",
      "\n",
      "Epoch Step: 701 Loss: 1.098488 Tokens per Sec: 13094.411133\n",
      "\n",
      "Epoch Step: 751 Loss: 0.936959 Tokens per Sec: 13418.295898\n",
      "\n",
      "Epoch Step: 801 Loss: 0.913851 Tokens per Sec: 13636.877930\n",
      "\n",
      "Epoch Step: 851 Loss: 0.859036 Tokens per Sec: 13772.231445\n",
      "\n",
      "Epoch Step: 901 Loss: 0.931204 Tokens per Sec: 13893.203125\n",
      "\n",
      "Epoch Step: 951 Loss: 0.857870 Tokens per Sec: 13668.456055\n",
      "\n",
      "Epoch Step: 1001 Loss: 0.898262 Tokens per Sec: 13310.390625\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.047844 Tokens per Sec: 13051.670898\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.196413 Tokens per Sec: 13598.154297\n",
      "\n",
      "Epoch Step: 1151 Loss: 0.827932 Tokens per Sec: 13240.173828\n",
      "\n",
      "Epoch Step: 1201 Loss: 0.769545 Tokens per Sec: 13428.144531\n",
      "\n",
      "Epoch Step: 1251 Loss: 0.977917 Tokens per Sec: 13243.635742\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.110638 Tokens per Sec: 13248.627930\n",
      "\n",
      "Epoch Step: 1351 Loss: 0.995281 Tokens per Sec: 13169.114258\n",
      "\n",
      "Epoch Step: 1401 Loss: 0.929045 Tokens per Sec: 12670.515625\n",
      "\n",
      "Epoch Step: 1451 Loss: 0.898770 Tokens per Sec: 12842.162109\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.112931 Tokens per Sec: 13288.483398\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.137768 Tokens per Sec: 13122.329102\n",
      "\n",
      "Epoch Step: 1601 Loss: 1.132742 Tokens per Sec: 12899.831055\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.089200 Tokens per Sec: 12567.245117\n",
      "\n",
      "Epoch Step: 1701 Loss: 0.881644 Tokens per Sec: 13310.986328\n",
      "\n",
      "Epoch Step: 1751 Loss: 0.826312 Tokens per Sec: 12856.432617\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.101691 Tokens per Sec: 13354.779297\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.271379 Tokens per Sec: 13269.504883\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.031499 Tokens per Sec: 12992.346680\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.063390 Tokens per Sec: 13105.274414\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.045215 Tokens per Sec: 13466.391602\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.126117 Tokens per Sec: 13182.971680\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.028905 Tokens per Sec: 13379.740234\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.034494 Tokens per Sec: 13420.447266\n",
      "\n",
      "Epoch Step: 1 Loss: 0.467123 Tokens per Sec: 11036.152344\n",
      "\n",
      "tensor(0.5372, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 0.891566 Tokens per Sec: 2886.605957\n",
      "\n",
      "Epoch Step: 51 Loss: 1.015665 Tokens per Sec: 13710.951172\n",
      "\n",
      "Epoch Step: 101 Loss: 0.766109 Tokens per Sec: 13293.742188\n",
      "\n",
      "Epoch Step: 151 Loss: 0.929059 Tokens per Sec: 13432.262695\n",
      "\n",
      "Epoch Step: 201 Loss: 1.118565 Tokens per Sec: 13413.301758\n",
      "\n",
      "Epoch Step: 251 Loss: 0.840226 Tokens per Sec: 13408.476562\n",
      "\n",
      "Epoch Step: 301 Loss: 1.006468 Tokens per Sec: 13595.684570\n",
      "\n",
      "Epoch Step: 351 Loss: 1.058063 Tokens per Sec: 13205.750977\n",
      "\n",
      "Epoch Step: 401 Loss: 0.943058 Tokens per Sec: 13084.949219\n",
      "\n",
      "Epoch Step: 451 Loss: 1.109133 Tokens per Sec: 13224.750000\n",
      "\n",
      "Epoch Step: 501 Loss: 1.163355 Tokens per Sec: 13019.025391\n",
      "\n",
      "Epoch Step: 551 Loss: 0.897126 Tokens per Sec: 12981.455078\n",
      "\n",
      "Epoch Step: 601 Loss: 1.105242 Tokens per Sec: 13509.937500\n",
      "\n",
      "Epoch Step: 651 Loss: 0.846723 Tokens per Sec: 12776.156250\n",
      "\n",
      "Epoch Step: 701 Loss: 0.975864 Tokens per Sec: 12831.083984\n",
      "\n",
      "Epoch Step: 751 Loss: 1.130880 Tokens per Sec: 12604.787109\n",
      "\n",
      "Epoch Step: 801 Loss: 0.967190 Tokens per Sec: 12518.372070\n",
      "\n",
      "Epoch Step: 851 Loss: 0.987782 Tokens per Sec: 13757.213867\n",
      "\n",
      "Epoch Step: 901 Loss: 0.841960 Tokens per Sec: 13993.572266\n",
      "\n",
      "Epoch Step: 951 Loss: 0.947334 Tokens per Sec: 14017.092773\n",
      "\n",
      "Epoch Step: 1001 Loss: 0.888813 Tokens per Sec: 14221.897461\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.033722 Tokens per Sec: 13909.673828\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.171020 Tokens per Sec: 13873.004883\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.102134 Tokens per Sec: 13660.461914\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.019908 Tokens per Sec: 13619.287109\n",
      "\n",
      "Epoch Step: 1251 Loss: 0.938298 Tokens per Sec: 12858.591797\n",
      "\n",
      "Epoch Step: 1301 Loss: 0.948013 Tokens per Sec: 13455.004883\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.042878 Tokens per Sec: 13165.404297\n",
      "\n",
      "Epoch Step: 1401 Loss: 1.108935 Tokens per Sec: 12912.068359\n",
      "\n",
      "Epoch Step: 1451 Loss: 0.952230 Tokens per Sec: 13433.671875\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.199812 Tokens per Sec: 13162.193359\n",
      "\n",
      "Epoch Step: 1551 Loss: 0.959470 Tokens per Sec: 13126.340820\n",
      "\n",
      "Epoch Step: 1601 Loss: 0.994222 Tokens per Sec: 13029.906250\n",
      "\n",
      "Epoch Step: 1651 Loss: 0.986431 Tokens per Sec: 12972.127930\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.127609 Tokens per Sec: 13546.483398\n",
      "\n",
      "Epoch Step: 1751 Loss: 1.154600 Tokens per Sec: 12541.378906\n",
      "\n",
      "Epoch Step: 1801 Loss: 0.977745 Tokens per Sec: 13259.673828\n",
      "\n",
      "Epoch Step: 1851 Loss: 1.036603 Tokens per Sec: 13097.914062\n",
      "\n",
      "Epoch Step: 1901 Loss: 0.977439 Tokens per Sec: 12958.105469\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.006630 Tokens per Sec: 13432.366211\n",
      "\n",
      "Epoch Step: 2001 Loss: 0.969273 Tokens per Sec: 13538.529297\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.033357 Tokens per Sec: 13203.219727\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.191279 Tokens per Sec: 13166.488281\n",
      "\n",
      "Epoch Step: 2151 Loss: 1.148102 Tokens per Sec: 13479.800781\n",
      "\n",
      "Epoch Step: 1 Loss: 0.471258 Tokens per Sec: 11483.624023\n",
      "\n",
      "tensor(0.5394, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 0.995284 Tokens per Sec: 2737.010010\n",
      "\n",
      "Epoch Step: 51 Loss: 0.953074 Tokens per Sec: 13268.773438\n",
      "\n",
      "Epoch Step: 101 Loss: 0.875806 Tokens per Sec: 12954.470703\n",
      "\n",
      "Epoch Step: 151 Loss: 0.905117 Tokens per Sec: 13134.380859\n",
      "\n",
      "Epoch Step: 201 Loss: 0.813733 Tokens per Sec: 12828.101562\n",
      "\n",
      "Epoch Step: 251 Loss: 0.840043 Tokens per Sec: 13390.404297\n",
      "\n",
      "Epoch Step: 301 Loss: 0.956297 Tokens per Sec: 13160.921875\n",
      "\n",
      "Epoch Step: 351 Loss: 0.985031 Tokens per Sec: 13280.721680\n",
      "\n",
      "Epoch Step: 401 Loss: 0.917566 Tokens per Sec: 13248.509766\n",
      "\n",
      "Epoch Step: 451 Loss: 1.052382 Tokens per Sec: 13257.375000\n",
      "\n",
      "Epoch Step: 501 Loss: 0.804401 Tokens per Sec: 13348.960938\n",
      "\n",
      "Epoch Step: 551 Loss: 1.038516 Tokens per Sec: 13485.897461\n",
      "\n",
      "Epoch Step: 601 Loss: 1.080135 Tokens per Sec: 13017.431641\n",
      "\n",
      "Epoch Step: 651 Loss: 0.946171 Tokens per Sec: 13403.583984\n",
      "\n",
      "Epoch Step: 701 Loss: 0.821267 Tokens per Sec: 13518.512695\n",
      "\n",
      "Epoch Step: 751 Loss: 1.002907 Tokens per Sec: 13219.927734\n",
      "\n",
      "Epoch Step: 801 Loss: 0.933386 Tokens per Sec: 12764.760742\n",
      "\n",
      "Epoch Step: 851 Loss: 0.871447 Tokens per Sec: 12855.628906\n",
      "\n",
      "Epoch Step: 901 Loss: 0.808017 Tokens per Sec: 12147.526367\n",
      "\n",
      "Epoch Step: 951 Loss: 1.173634 Tokens per Sec: 12898.350586\n",
      "\n",
      "Epoch Step: 1001 Loss: 0.988813 Tokens per Sec: 13048.320312\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.068993 Tokens per Sec: 12941.457031\n",
      "\n",
      "Epoch Step: 1101 Loss: 1.094170 Tokens per Sec: 12465.175781\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.022003 Tokens per Sec: 13503.249023\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.097643 Tokens per Sec: 13028.664062\n",
      "\n",
      "Epoch Step: 1251 Loss: 1.053424 Tokens per Sec: 13524.975586\n",
      "\n",
      "Epoch Step: 1301 Loss: 1.012652 Tokens per Sec: 14064.015625\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.157517 Tokens per Sec: 13476.661133\n",
      "\n",
      "Epoch Step: 1401 Loss: 0.904530 Tokens per Sec: 13135.573242\n",
      "\n",
      "Epoch Step: 1451 Loss: 0.953134 Tokens per Sec: 12962.699219\n",
      "\n",
      "Epoch Step: 1501 Loss: 0.913671 Tokens per Sec: 13469.826172\n",
      "\n",
      "Epoch Step: 1551 Loss: 1.183773 Tokens per Sec: 13096.041992\n",
      "\n",
      "Epoch Step: 1601 Loss: 0.870799 Tokens per Sec: 13136.698242\n",
      "\n",
      "Epoch Step: 1651 Loss: 1.278675 Tokens per Sec: 12906.492188\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.039781 Tokens per Sec: 13076.659180\n",
      "\n",
      "Epoch Step: 1751 Loss: 0.959587 Tokens per Sec: 13814.498047\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.017045 Tokens per Sec: 13206.562500\n",
      "\n",
      "Epoch Step: 1851 Loss: 0.998516 Tokens per Sec: 13245.730469\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.040276 Tokens per Sec: 13391.789062\n",
      "\n",
      "Epoch Step: 1951 Loss: 1.079671 Tokens per Sec: 13553.498047\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.108317 Tokens per Sec: 13208.958984\n",
      "\n",
      "Epoch Step: 2051 Loss: 0.986850 Tokens per Sec: 13058.076172\n",
      "\n",
      "Epoch Step: 2101 Loss: 0.846633 Tokens per Sec: 13296.854492\n",
      "\n",
      "Epoch Step: 2151 Loss: 0.901824 Tokens per Sec: 13121.088867\n",
      "\n",
      "Epoch Step: 1 Loss: 0.465386 Tokens per Sec: 10662.254883\n",
      "\n",
      "tensor(0.5334, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.074035 Tokens per Sec: 2493.884521\n",
      "\n",
      "Epoch Step: 51 Loss: 0.928141 Tokens per Sec: 12407.650391\n",
      "\n",
      "Epoch Step: 101 Loss: 0.980654 Tokens per Sec: 13381.871094\n",
      "\n",
      "Epoch Step: 151 Loss: 0.966354 Tokens per Sec: 13340.770508\n",
      "\n",
      "Epoch Step: 201 Loss: 1.058055 Tokens per Sec: 12982.502930\n",
      "\n",
      "Epoch Step: 251 Loss: 1.067143 Tokens per Sec: 13001.319336\n",
      "\n",
      "Epoch Step: 301 Loss: 1.035335 Tokens per Sec: 13466.237305\n",
      "\n",
      "Epoch Step: 351 Loss: 0.858439 Tokens per Sec: 13579.068359\n",
      "\n",
      "Epoch Step: 401 Loss: 1.019466 Tokens per Sec: 13394.231445\n",
      "\n",
      "Epoch Step: 451 Loss: 0.876755 Tokens per Sec: 13242.823242\n",
      "\n",
      "Epoch Step: 501 Loss: 0.921408 Tokens per Sec: 13542.278320\n",
      "\n",
      "Epoch Step: 551 Loss: 0.708071 Tokens per Sec: 13489.557617\n",
      "\n",
      "Epoch Step: 601 Loss: 1.049459 Tokens per Sec: 13226.136719\n",
      "\n",
      "Epoch Step: 651 Loss: 0.866768 Tokens per Sec: 13080.262695\n",
      "\n",
      "Epoch Step: 701 Loss: 0.934689 Tokens per Sec: 13479.890625\n",
      "\n",
      "Epoch Step: 751 Loss: 0.892600 Tokens per Sec: 13237.812500\n",
      "\n",
      "Epoch Step: 801 Loss: 0.924198 Tokens per Sec: 12770.985352\n",
      "\n",
      "Epoch Step: 851 Loss: 1.002069 Tokens per Sec: 13073.722656\n",
      "\n",
      "Epoch Step: 901 Loss: 0.949585 Tokens per Sec: 13171.083008\n",
      "\n",
      "Epoch Step: 951 Loss: 0.993730 Tokens per Sec: 13446.367188\n",
      "\n",
      "Epoch Step: 1001 Loss: 1.110024 Tokens per Sec: 12963.410156\n",
      "\n",
      "Epoch Step: 1051 Loss: 0.930301 Tokens per Sec: 12681.970703\n",
      "\n",
      "Epoch Step: 1101 Loss: 0.998564 Tokens per Sec: 12474.705078\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.135928 Tokens per Sec: 12854.495117\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.216652 Tokens per Sec: 13840.224609\n",
      "\n",
      "Epoch Step: 1251 Loss: 0.782018 Tokens per Sec: 13090.355469\n",
      "\n",
      "Epoch Step: 1301 Loss: 0.845377 Tokens per Sec: 13892.571289\n",
      "\n",
      "Epoch Step: 1351 Loss: 1.152756 Tokens per Sec: 13759.730469\n",
      "\n",
      "Epoch Step: 1401 Loss: 0.872047 Tokens per Sec: 14019.240234\n",
      "\n",
      "Epoch Step: 1451 Loss: 1.177328 Tokens per Sec: 14085.961914\n",
      "\n",
      "Epoch Step: 1501 Loss: 1.041257 Tokens per Sec: 13593.704102\n",
      "\n",
      "Epoch Step: 1551 Loss: 0.966368 Tokens per Sec: 13433.312500\n",
      "\n",
      "Epoch Step: 1601 Loss: 0.997161 Tokens per Sec: 12998.136719\n",
      "\n",
      "Epoch Step: 1651 Loss: 0.958400 Tokens per Sec: 13288.002930\n",
      "\n",
      "Epoch Step: 1701 Loss: 1.125303 Tokens per Sec: 13106.351562\n",
      "\n",
      "Epoch Step: 1751 Loss: 0.921913 Tokens per Sec: 13193.841797\n",
      "\n",
      "Epoch Step: 1801 Loss: 1.170780 Tokens per Sec: 12778.964844\n",
      "\n",
      "Epoch Step: 1851 Loss: 0.810214 Tokens per Sec: 13110.750000\n",
      "\n",
      "Epoch Step: 1901 Loss: 1.012872 Tokens per Sec: 13226.089844\n",
      "\n",
      "Epoch Step: 1951 Loss: 0.897171 Tokens per Sec: 13366.812500\n",
      "\n",
      "Epoch Step: 2001 Loss: 1.014100 Tokens per Sec: 13268.435547\n",
      "\n",
      "Epoch Step: 2051 Loss: 1.060358 Tokens per Sec: 13079.885742\n",
      "\n",
      "Epoch Step: 2101 Loss: 1.046499 Tokens per Sec: 12668.888672\n",
      "\n",
      "Epoch Step: 2151 Loss: 0.863366 Tokens per Sec: 13384.104492\n",
      "\n",
      "Epoch Step: 1 Loss: 0.476856 Tokens per Sec: 11707.370117\n",
      "\n",
      "tensor(0.5351, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 0.823809 Tokens per Sec: 2131.038574\n",
      "\n",
      "Epoch Step: 51 Loss: 1.069086 Tokens per Sec: 13447.373047\n",
      "\n",
      "Epoch Step: 101 Loss: 1.031364 Tokens per Sec: 13453.779297\n",
      "\n",
      "Epoch Step: 151 Loss: 0.684639 Tokens per Sec: 13184.644531\n",
      "\n",
      "Epoch Step: 201 Loss: 0.972768 Tokens per Sec: 13125.950195\n",
      "\n",
      "Epoch Step: 251 Loss: 0.971824 Tokens per Sec: 12974.536133\n",
      "\n",
      "Epoch Step: 301 Loss: 0.908237 Tokens per Sec: 13177.058594\n",
      "\n",
      "Epoch Step: 351 Loss: 0.862806 Tokens per Sec: 13293.649414\n",
      "\n",
      "Epoch Step: 401 Loss: 0.980903 Tokens per Sec: 13234.844727\n",
      "\n",
      "Epoch Step: 451 Loss: 0.919452 Tokens per Sec: 13040.650391\n",
      "\n",
      "Epoch Step: 501 Loss: 1.028620 Tokens per Sec: 13128.026367\n",
      "\n",
      "Epoch Step: 551 Loss: 0.948936 Tokens per Sec: 12574.040039\n",
      "\n",
      "Epoch Step: 601 Loss: 0.986020 Tokens per Sec: 13214.540039\n",
      "\n",
      "Epoch Step: 651 Loss: 0.910303 Tokens per Sec: 13199.987305\n",
      "\n",
      "Epoch Step: 701 Loss: 0.906294 Tokens per Sec: 12778.519531\n",
      "\n",
      "Epoch Step: 751 Loss: 0.722920 Tokens per Sec: 13025.275391\n",
      "\n",
      "Epoch Step: 801 Loss: 1.049383 Tokens per Sec: 13023.889648\n",
      "\n",
      "Epoch Step: 851 Loss: 0.988891 Tokens per Sec: 12988.804688\n",
      "\n",
      "Epoch Step: 901 Loss: 1.156142 Tokens per Sec: 13470.330078\n",
      "\n",
      "Epoch Step: 951 Loss: 0.953178 Tokens per Sec: 13184.469727\n",
      "\n",
      "Epoch Step: 1001 Loss: 0.918403 Tokens per Sec: 13269.959961\n",
      "\n",
      "Epoch Step: 1051 Loss: 1.092060 Tokens per Sec: 12817.114258\n",
      "\n",
      "Epoch Step: 1101 Loss: 0.977106 Tokens per Sec: 13340.359375\n",
      "\n",
      "Epoch Step: 1151 Loss: 1.085581 Tokens per Sec: 13594.272461\n",
      "\n",
      "Epoch Step: 1201 Loss: 1.163023 Tokens per Sec: 12517.264648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "devices = [0]\n",
    "model = make_model(len(SRC.vocab), len(TGT.vocab), N=6)\n",
    "model.cuda(devices[0])\n",
    "pad_idx = TGT.vocab.stoi[\"<blank>\"]\n",
    "criterion = LabelSmoothing(size=len(TGT.vocab), padding_idx=pad_idx, smoothing=0.1)\n",
    "BATCH_SIZE = 2048\n",
    "train_iter = MyIterator(train, batch_size=BATCH_SIZE, repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)), device=torch.device(devices[0]),\n",
    "                        batch_size_fn=batch_size_fn, train=True)\n",
    "valid_iter = MyIterator(val, batch_size=BATCH_SIZE, repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)), device=torch.device(devices[0]),\n",
    "                        batch_size_fn=batch_size_fn, train=False)\n",
    "\n",
    "model_opt = NoamOpt(model.src_embed[0].d_model, 1, 2000,\n",
    "        torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "\n",
    "loss_compute_train = SimpleLossCompute(model.generator, criterion, model_opt)\n",
    "loss_compute_val = SimpleLossCompute(model.generator, criterion, None)\n",
    "\n",
    "# learnable concat\n",
    "val_epoch_loss_f = open('val_epoch_lc.loss', 'a+')\n",
    "for epoch in range(1000):\n",
    "    model.train()\n",
    "    train_log_f = open('train_lc.log', 'a+')\n",
    "    train_step_loss_f = open('train_lc.loss', 'a+')\n",
    "    run_epoch((rebatch(pad_idx, b) for b in train_iter), \n",
    "              model, \n",
    "              loss_compute_train,\n",
    "              train_log_f,\n",
    "              train_step_loss_f)\n",
    "    model.eval()\n",
    "    val_log_f = open('val_lc.log', 'a+')\n",
    "    val_step_loss_f = open('val_lc.loss', 'a+')\n",
    "    loss = run_epoch((rebatch(pad_idx, b) for b in valid_iter), \n",
    "                      model, \n",
    "                      loss_compute_val,\n",
    "                      val_log_f,\n",
    "                      val_step_loss_f)\n",
    "    val_epoch_loss_f.write(\"%f\\n\" % (loss))\n",
    "    val_epoch_loss_f.flush()\n",
    "    torch.save(model.state_dict(), f'./lc_weights/lc_{str(epoch)}.pth')\n",
    "    print(loss)\n",
    "val_epoch_loss_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d33336-1637-4fa3-bed5-aa1e8709766d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c576baf6-9efc-47e3-811b-ad986a73eae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4dfd4d-b048-4fe7-9825-67f539474e18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
